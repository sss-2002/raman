import streamlit as st
import numpy as np
import pandas as pd
import re
import itertools
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix
import seaborn as sns
from scipy import sparse
from scipy.sparse.linalg import spsolve
from scipy.signal import savgol_filter, medfilt
from scipy.fft import fft, ifft
from statsmodels.nonparametric.smoothers_lowess import lowess
import pywt
from sklearn.linear_model import LinearRegression  # ç”¨äºMSC


# äºŒé˜¶å·®åˆ†(D2)å‡½æ•°
def D2(sdata):
    """
    è®¡ç®—äºŒé˜¶å·®åˆ†ï¼Œä¿æŒè¾“å‡ºå°ºå¯¸ä¸è¾“å…¥ç›¸åŒ
    å‚æ•°:
        sdata: è¾“å…¥å…‰è°±æ•°æ® (n_samples, n_features)
    è¿”å›:
        äºŒé˜¶å·®åˆ†ç»“æœï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = sdata.shape[0]
    col = sdata.shape[1]
    D2_result = np.zeros((row, col))
    for i in range(row):
        tem = np.diff(sdata[i], 2)
        temp = tem.tolist()
        # å¡«å……æœ€åä¸¤ä¸ªå…ƒç´ ä»¥ä¿æŒä¸è¾“å…¥ç›¸åŒçš„å°ºå¯¸
        temp.append(temp[-1])
        temp.append(temp[-1])
        D2_result[i] = temp
    return D2_result


# LPèŒƒæ•°å½’ä¸€åŒ–å‡½æ•°
def LPnorm(arr, ord):
    """
    å¯¹æ•°ç»„è¿›è¡ŒLpèŒƒæ•°å½’ä¸€åŒ–
    
    å‚æ•°:
        arr: è¾“å…¥æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(row, col)
        ord: èŒƒæ•°é˜¶æ•°
        
    è¿”å›:
        å½’ä¸€åŒ–åçš„æ•°ç»„ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = arr.shape[0]
    col = arr.shape[1]
    Lpdata = np.zeros((row, col))
    for i in range(row):
        Lp = np.linalg.norm(arr[i,:], ord)
        if Lp != 0:
            Lpdata[i,:] = arr[i,:] / Lp
        else:
            Lpdata[i,:] = arr[i,:]
    return Lpdata


# MaMinormå½’ä¸€åŒ–å‡½æ•°
def MaMinorm(Oarr):
    """
    å¯¹æ•°ç»„è¿›è¡ŒMa-Minormå½’ä¸€åŒ–å¤„ç†
    å°†æ•°æ®æ ‡å‡†åŒ–åˆ°[-5, 5]èŒƒå›´
    
    å‚æ•°:
        Oarr: è¾“å…¥æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(row, col)
        
    è¿”å›:
        å½’ä¸€åŒ–åçš„æ•°ç»„ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = Oarr.shape[0]
    col = Oarr.shape[1]
    MMarr = np.zeros((row, col))
    permax = np.ones((1, col))
    for i in range(row):
        diff = np.max(Oarr[i]) - np.min(Oarr[i])
        if diff != 0:
            MMarr[i] = ((Oarr[i] - permax*np.min(Oarr[i]))/ diff)*10 - 5
        else:
            MMarr[i] = Oarr[i] - permax * np.min(Oarr[i])
    return MMarr


# æ ‡å‡†åŒ–å‡½æ•°ï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰
def standardization(Datamat):
    """
    å°†æ•°æ®æ ‡å‡†åŒ–ï¼Œå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1
    
    å‚æ•°:
        Datamat: è¾“å…¥æ•°æ®
        
    è¿”å›:
        æ ‡å‡†åŒ–åçš„æ•°æ®
    """
    mu = np.average(Datamat)
    sigma = np.std(Datamat)
    if sigma != 0:
        normDatamat = (Datamat - mu) / sigma
    else:
        normDatamat = Datamat - mu
    return normDatamat


def plotst(Data):
    """
    å¯¹æ•°æ®çš„æ¯ä¸€è¡Œè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†
    
    å‚æ•°:
        Data: è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º(row, col)
        
    è¿”å›:
        æ ‡å‡†åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = Data.shape[0]
    col = Data.shape[1]
    st_Data = np.zeros((row, col))
    for i in range(row):
        st_Data[i] = standardization(Data[i])
    return st_Data


# MSCï¼ˆå¤šå…ƒæ•£å°„æ ¡æ­£ï¼‰å‡½æ•°
def MSC(sdata):
    """
    å¤šå…ƒæ•£å°„æ ¡æ­£(MSC)ç®—æ³•å®ç°
    
    å‚æ•°:
        sdata: è¾“å…¥å…‰è°±æ•°æ®ï¼Œå½¢çŠ¶ä¸º(n_samples, n_features)
        
    è¿”å›:
        æ ¡æ­£åçš„å…‰è°±æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    n = sdata.shape[0]  # æ ·æœ¬æ•°é‡
    k = np.zeros(sdata.shape[0])  # æ–œç‡
    b = np.zeros(sdata.shape[0])  # æˆªè·
 
    # è®¡ç®—å¹³å‡å…‰è°±ä½œä¸ºå‚è€ƒ
    M = np.mean(sdata, axis=0)
 
    # å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œçº¿æ€§å›å½’ï¼Œè®¡ç®—æ–œç‡å’Œæˆªè·
    for i in range(n):
        y = sdata[i, :].reshape(-1, 1)  # å½“å‰æ ·æœ¬å…‰è°±
        M_reshaped = M.reshape(-1, 1)   # å¹³å‡å…‰è°±ï¼Œé‡å¡‘ä¸ºäºŒç»´æ•°ç»„
        model = LinearRegression()
        model.fit(M_reshaped, y)
        k[i] = model.coef_  # æ–œç‡
        b[i] = model.intercept_  # æˆªè·
    
    # åº”ç”¨MSCæ ¡æ­£
    spec_msc = np.zeros_like(sdata)
    for i in range(n):
        # å°†æ–œç‡å’Œæˆªè·æ‰©å±•åˆ°ä¸å…‰è°±é•¿åº¦åŒ¹é…
        bb = np.repeat(b[i], sdata.shape[1])
        kk = np.repeat(k[i], sdata.shape[1])
        # åº”ç”¨æ ¡æ­£å…¬å¼ï¼š(åŸå§‹å…‰è°± - æˆªè·) / æ–œç‡
        spec_msc[i, :] = (sdata[i, :] - bb) / kk
    
    return spec_msc


# å¡å°”æ›¼æ»¤æ³¢ç®—æ³•å®ç°
def Kalman(z, R):
    """
    å•å˜é‡å¡å°”æ›¼æ»¤æ³¢
    
    å‚æ•°:
        z: è¾“å…¥ä¿¡å·
        R: æµ‹é‡å™ªå£°æ–¹å·®
    
    è¿”å›:
        æ»¤æ³¢åçš„ä¿¡å·
    """
    n_iter = len(z)
    sz = (n_iter,)  # æ•°ç»„å¤§å°

    Q = 1e-5  # è¿‡ç¨‹æ–¹å·®

    # åˆ†é…æ•°ç»„ç©ºé—´
    xhat = np.zeros(sz)      # åéªŒä¼°è®¡
    P = np.zeros(sz)         # åéªŒè¯¯å·®ä¼°è®¡
    xhatminus = np.zeros(sz) # å…ˆéªŒä¼°è®¡
    Pminus = np.zeros(sz)    # å…ˆéªŒè¯¯å·®ä¼°è®¡
    K = np.zeros(sz)         # å¡å°”æ›¼å¢ç›Š

    # åˆå§‹çŒœæµ‹
    xhat[0] = 0.0
    P[0] = 1.0

    for k in range(1, n_iter):
        # æ—¶é—´æ›´æ–°
        xhatminus[k] = xhat[k-1]  # X(k|k-1) = AX(k-1|k-1) + BU(k) + W(k), A=1, BU(k)=0
        Pminus[k] = P[k-1] + Q    # P(k|k-1) = AP(k-1|k-1)A' + Q(k), A=1

        # æµ‹é‡æ›´æ–°
        K[k] = Pminus[k] / (Pminus[k] + R)  # Kg(k) = P(k|k-1)H'/[HP(k|k-1)H' + R], H=1
        xhat[k] = xhatminus[k] + K[k] * (z[k] - xhatminus[k])  # X(k|k)æ›´æ–°
        P[k] = (1 - K[k]) * Pminus[k]  # P(k|k)æ›´æ–°

    return xhat

def KalmanF(xd, R):
    """
    å¯¹å¤šç»´æ•°æ®åº”ç”¨å¡å°”æ›¼æ»¤æ³¢
    
    å‚æ•°:
        xd: è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º(n_samples, n_points)
        R: æµ‹é‡å™ªå£°æ–¹å·®
    
    è¿”å›:
        æ»¤æ³¢åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = xd.shape[0]
    col = xd.shape[1]
    Fxd = np.zeros((row, col))
    for i in range(row):
        Fxd[i] = Kalman(xd[i], R)
    return Fxd


# IModPoly: improved modified multi-polynomial fit method
def IModPoly(wavenumbers, originalRaman, polyorder, max_iter=100, tolerance=0.005):
    """
    æ”¹è¿›çš„å¤šé¡¹å¼æ‹ŸåˆåŸºçº¿æ ¡æ­£

    å‚æ•°:
        wavenumbers: æ‹‰æ›¼ä½ç§»(cm^-1)çš„ä¸€ç»´æ•°ç»„
        originalRaman: åŸå§‹æ‹‰æ›¼å…‰è°±ï¼Œå½¢çŠ¶ä¸º(n_samples, n_points)
        polyorder: å¤šé¡¹å¼é˜¶æ•°
        max_iter: æœ€å¤§è¿­ä»£æ¬¡æ•° (é»˜è®¤100)
        tolerance: æ”¶æ•›å®¹å·® (é»˜è®¤0.005)

    è¿”å›:
        æ ¡æ­£åçš„å…‰è°±ï¼Œå½¢çŠ¶ä¸originalRamanç›¸åŒ
    """
    row, col = originalRaman.shape
    corrected = np.zeros((row, col))

    for j in range(row):
        prev_spectrum = originalRaman[j]
        curr_spectrum = prev_spectrum.copy()
        prev_std = 0
        converged = False
        iteration = 1

        while not converged and iteration <= max_iter:
            # å¤šé¡¹å¼æ‹Ÿåˆ
            coeffs = np.polyfit(wavenumbers, curr_spectrum, polyorder)
            fitted = np.polyval(coeffs, wavenumbers)
            residual = curr_spectrum - fitted
            curr_std = np.std(residual)

            # å…‰è°±ä¿®æ­£
            if iteration == 1:
                # é¦–æ¬¡è¿­ä»£ï¼šå»é™¤æ˜æ˜¾å³°
                mask = prev_spectrum > (fitted + curr_std)
                curr_spectrum[mask] = fitted[mask] + curr_std
            else:
                # åç»­è¿­ä»£ï¼šé‡å»ºæ¨¡å‹
                mask = prev_spectrum < (fitted + curr_std)
                curr_spectrum = np.where(mask, prev_spectrum, fitted + curr_std)

            # æ£€æŸ¥æ”¶æ•›æ¡ä»¶
            relative_change = abs((curr_std - prev_std) / curr_std) if curr_std != 0 else 0
            converged = relative_change < tolerance

            prev_spectrum = curr_spectrum
            prev_std = curr_std
            iteration += 1

        corrected[j] = originalRaman[j] - fitted

    return corrected


# ç§»åŠ¨çª—å£å¹³å‡ï¼ˆMWAï¼‰æ»¤æ³¢ç®—æ³•
def MWA(arr, n=6, it=1, mode="full"):
    row = arr.shape[0]
    col = arr.shape[1]
    average = np.zeros((row, col))
    ns = []
    for _ in range(it):
        ns.append(n)
        n -= 2
    for i in range(row):
        average[i] = arr[i].copy()
        nn = ns.copy()
        for _ in range(it):
            n = nn.pop()
            if n > 1:
                tmp = np.convolve(average[i], np.ones((n,)) / n, mode=mode)
                for j in range(1, n):
                    tmp[j - 1] = tmp[j - 1] * n / j
                    tmp[-j] = tmp[-j] * n / j
                j = int(n / 2)
                k = n - j - 1
                average[i] = tmp[j:-k]
    return average


# æ”¹è¿›çš„éå¯¹ç§°åŠ æƒæƒ©ç½šæœ€å°äºŒä¹˜åŸºçº¿æ ¡å‡†ç®—æ³•
def baseline_als(y, lam, p, niter=10, tol=1e-6):
    """
    æ”¹è¿›çš„AsLSç®—æ³•

    å‚æ•°:
        y: è¾“å…¥å…‰è°± (n_samples, n_points)
        lam: å¹³æ»‘ç³»æ•° (å…¸å‹å€¼1e5-1e12)
        p: éå¯¹ç§°ç³»æ•° (0-1, å…¸å‹å€¼0.001-0.1)
        niter: æœ€å¤§è¿­ä»£æ¬¡æ•°
        tol: æ”¶æ•›é˜ˆå€¼

    è¿”å›:
        åŸºçº¿æ ¡æ­£åçš„å…‰è°±
    """
    if np.any(np.isnan(y)):
        raise ValueError("è¾“å…¥æ•°æ®åŒ…å«NaNå€¼")

    y = np.asarray(y, dtype=np.float64)
    L = y.shape[1]
    D = sparse.csc_matrix(np.diff(np.eye(L), 2))
    result = np.zeros_like(y)

    for j in range(y.shape[0]):
        w = np.ones(L)
        y_curr = y[j].copy()

        for _ in range(niter):
            W = sparse.spdiags(w, 0, L, L)
            Z = W + lam * D.dot(D.transpose())
            z = spsolve(Z, w * y_curr)

            # æ£€æŸ¥æ”¶æ•›
            if np.max(np.abs(z - y_curr)) < tol:
                break

            w = p * (y[j] > z) + (1 - p) * (y[j] < z)
            y_curr = z

        result[j] = y[j] - z

    return result


# åŠ¨æ€æ—¶é—´è§„æ•´(DTW)ç®—æ³•
class DTW:
    def __init__(self, dist_method='euclidean'):
        self.dist_method = dist_method
        
    def distance(self, x, y):
        if self.dist_method == 'euclidean':
            return np.linalg.norm(x - y)
        elif self.dist_method == 'manhattan':
            return np.sum(np.abs(x - y))
        else:
            return np.linalg.norm(x - y)
            
    def __call__(self, reference, query):
        n = len(reference)
        m = len(query)
        dtw_matrix = np.zeros((n + 1, m + 1))
        dtw_matrix[:, :] = np.inf
        dtw_matrix[0, 0] = 0
        
        for i in range(1, n + 1):
            for j in range(1, m + 1):
                cost = self.distance(reference[i-1], query[j-1])
                dtw_matrix[i, j] = cost + min(
                    dtw_matrix[i-1, j],    # æ’å…¥
                    dtw_matrix[i, j-1],    # åˆ é™¤
                    dtw_matrix[i-1, j-1]   # åŒ¹é…
                )
        
        # å›æº¯è·¯å¾„
        i, j = n, m
        path = []
        while i > 0 or j > 0:
            path.append((i-1, j-1))
            if i == 0:
                j -= 1
            elif j == 0:
                i -= 1
            else:
                min_val = min(dtw_matrix[i-1, j], dtw_matrix[i, j-1], dtw_matrix[i-1, j-1])
                if min_val == dtw_matrix[i-1, j-1]:
                    i -= 1
                    j -= 1
                elif min_val == dtw_matrix[i-1, j]:
                    i -= 1
                else:
                    j -= 1
        
        return path[::-1], dtw_matrix[n, m]


# æŒ¤å‹å’Œ sigmoid ç›¸å…³å‡½æ•°
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def squashing(x):
    return 1 / (1 + np.exp(-x))

def i_squashing(x):
    return 1 / (1 + np.exp(-0.5 * x))

def i_sigmoid(x, maxn=10):
    return 1 / (1 + np.exp(-x / maxn))


# sgolayfiltæ»¤æ³¢å™¨å®ç°
def SGfilter(Intensity, point, degree):  # è¾“å…¥å‡ä¸ºè¡Œ
    """
    Savitzky-Golayæ»¤æ³¢å™¨å®ç°
    
    å‚æ•°:
        Intensity: è¾“å…¥å…‰è°±æ•°æ® (n_samples, n_features)
        point: çª—å£å¤§å°
        degree: å¤šé¡¹å¼é˜¶æ•°
        
    è¿”å›:
        æ»¤æ³¢åçš„å…‰è°±æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    Row = Intensity.shape[0]
    col = Intensity.shape[1]
    sgsmooth = np.zeros((Row, col))
    for i in range(Row):
        sgsmooth[i] = savgol_filter(Intensity[i], point, degree)
    return sgsmooth


def main():
    # æœ€ä¼˜å…ˆåˆå§‹åŒ–session state
    if 'show_arrangements' not in st.session_state:
        st.session_state.show_arrangements = False
    
    # åˆå§‹åŒ–æµ‹è¯•ç›¸å…³çš„sessionçŠ¶æ€å˜é‡
    test_states = {
        'k_value': 5,               # é»˜è®¤kå€¼
        'test_results': None,       # å­˜å‚¨æµ‹è¯•ç»“æœ
        'labels': None,             # å­˜å‚¨æ ·æœ¬æ ‡ç­¾
        'train_indices': None,      # è®­ç»ƒé›†ç´¢å¼•
        'test_indices': None        # æµ‹è¯•é›†ç´¢å¼•
    }
    
    # åˆå§‹åŒ–å…¶ä»–å¿…è¦çš„sessionçŠ¶æ€å˜é‡
    other_states = {
        'raw_data': None,
        'processed_data': None,
        'peaks': None,
        'train_test_split_ratio': 0.8,
        'arrangement_results': [],
        'selected_arrangement': None,
        'arrangement_details': {},
        'algorithm_permutations': [],  # å­˜å‚¨ç®—æ³•æ’åˆ—ç»„åˆ
        'current_algorithms': {},       # å­˜å‚¨å½“å‰é€‰æ‹©çš„ç®—æ³•
        'filtered_perms': [],           # å­˜å‚¨ç­›é€‰åçš„æ’åˆ—æ–¹æ¡ˆ
        'selected_perm_idx': 0          # å­˜å‚¨å½“å‰é€‰ä¸­çš„æ’åˆ—ç´¢å¼•
    }
    
    # åˆå¹¶æ‰€æœ‰çŠ¶æ€å˜é‡å¹¶åˆå§‹åŒ–
    all_states = {**test_states,** other_states}
    for key, value in all_states.items():
        if key not in st.session_state:
            st.session_state[key] = value

    # è®¾ç½®é¡µé¢ï¼šç´§å‡‘å¸ƒå±€
    st.set_page_config(layout="wide", page_icon="ğŸ”¬", page_title="æ’åˆ—é¢„å¤„ç†æ¨¡å‹")
    # å…¨å±€æ ·å¼è°ƒæ•´ï¼šç´§å‡‘å­—ä½“å’Œé—´è·
    st.markdown("""
        <style>
        /* å…¨å±€å­—ä½“ç¼©å°ï¼Œé—´è·ç´§å‡‘ */
        body {font-size: 0.85rem !important;}
        .css-1v0mbdj {padding: 0.5rem 1rem !important;} /* å®¹å™¨å†…è¾¹è· */
        .css-1d391kg {padding: 0.3rem 0 !important;} /* æ ‡é¢˜é—´è· */
        .css-1x8cf1d {line-height: 1.2 !important;} /* æ–‡æœ¬è¡Œé«˜ */
        .css-12ttj6m {margin-bottom: 0.5rem !important;} /* ç»„ä»¶åº•éƒ¨é—´è· */
        .css-1n543e5 {height: 220px !important;} /* å›¾è¡¨é«˜åº¦ç¼©å° */
        .css-1b3298e {gap: 0.5rem !important;} /* åˆ—é—´è· */
        .css-16huue1 {padding: 0.3rem 0.8rem !important;} /* æŒ‰é’®å†…è¾¹è· */
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸŒŒ æ’åˆ—é¢„å¤„ç†æ¨¡å‹")
     
     
    # ===== ç®—æ³•å®ç° =====
    def polynomial_fit(wavenumbers, spectra, polyorder):
        """å¤šé¡¹å¼æ‹ŸåˆåŸºçº¿æ ¡æ­£"""
        baseline = np.zeros_like(spectra)
        for i in range(spectra.shape[1]):
            coeffs = np.polyfit(wavenumbers, spectra[:, i], deg=polyorder)
            baseline[:, i] = np.polyval(coeffs, wavenumbers)
        return spectra - baseline  # æ‰£é™¤åŸºçº¿
    
    def modpoly(wavenumbers, spectra, k):
        """Modified Polynomial (ModPoly) åŸºçº¿æ ¡æ­£"""
        baseline = np.zeros_like(spectra)
        n_points = len(wavenumbers)
        for i in range(spectra.shape[1]):
            y = spectra[:, i].copy()
            for _ in range(k):
                coeffs = np.polyfit(wavenumbers, y, deg=5)
                fitted = np.polyval(coeffs, wavenumbers)
                mask = y < fitted
                y[~mask] = fitted[~mask]
            baseline[:, i] = y
        return spectra - baseline
    
    def pls(spectra, lam):
        """Penalized Least Squares (PLS) åŸºçº¿æ ¡æ­£"""
        n_points = spectra.shape[0]
        baseline = np.zeros_like(spectra)
        D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(n_points, n_points-2))
        D = lam * D.dot(D.transpose())
        for i in range(spectra.shape[1]):
            y = spectra[:, i]
            A = sparse.eye(n_points) + D
            baseline[:, i] = spsolve(A, y)
        return spectra - baseline
    
    def airpls(spectra, lam, max_iter=15, threshold=0.001):
        """Adaptive Iteratively Reweighted Penalized Least Squares (airPLS) åŸºçº¿æ ¡æ­£"""
        n_points = spectra.shape[0]
        baseline = np.zeros_like(spectra)
        D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(n_points, n_points-2))
        D = lam * D.dot(D.transpose())
        for i in range(spectra.shape[1]):
            y = spectra[:, i]
            w = np.ones(n_points)
            baseline_i = np.zeros(n_points)
            for j in range(max_iter):
                W = sparse.diags(w, 0)
                Z = W + D
                b = spsolve(Z, W * y)
                d = y - b
                neg_mask = d < 0
                w[neg_mask] = np.exp(j * np.abs(d[neg_mask]) / np.std(d[neg_mask]))
                w[~neg_mask] = 0
                if j > 0:
                    diff = np.sum(np.abs(b - baseline_i)) / np.sum(np.abs(baseline_i)) if np.sum(np.abs(baseline_i)) > 0 else 0
                    if diff < threshold:
                        break
                baseline_i = b
            baseline[:, i] = baseline_i
        return spectra - baseline
    
    def dtw_squashing(x, l, k1, k2):
        """åŠ¨æ€æ—¶é—´è§„æ•´(DTW)æŒ¤å‹ç®—æ³•"""
        n_samples, n_features = x.shape
        result = np.zeros_like(x)
        reference = np.mean(x, axis=1)  # ä½¿ç”¨å¹³å‡å…‰è°±ä½œä¸ºå‚è€ƒ
        dtw = DTW()
        
        for i in range(n_features):
            spectrum = x[:, i]
            path, cost = dtw(reference, spectrum)
            squashed = np.zeros_like(spectrum)
            for ref_idx, spec_idx in path:
                squashed[ref_idx] += spectrum[spec_idx]
            unique_ref_indices = np.unique([p[0] for p in path])
            for idx in unique_ref_indices:
                count = sum(1 for p in path if p[0] == idx)
                squashed[idx] /= count
            if k1 == "T":
                max_slope = l
                for j in range(1, len(path)):
                    ref_diff = path[j][0] - path[j-1][0]
                    spec_diff = path[j][1] - path[j-1][1]
                    if ref_diff != 0:
                        slope = abs(spec_diff / ref_diff)
                        if slope > max_slope:
                            squashed[path[j][0]] = (squashed[path[j][0]] + squashed[path[j-1][0]]) / 2
            if k2 == "T":
                ref_map_count = {}
                for ref_idx, _ in path:
                    ref_map_count[ref_idx] = ref_map_count.get(ref_idx, 0) + 1
                for ref_idx, count in ref_map_count.items():
                    if count > l:
                        window = min(l, len(spectrum))
                        start = max(0, ref_idx - window//2)
                        end = min(n_samples, ref_idx + window//2 + 1)
                        squashed[ref_idx] = np.mean(spectrum[start:end])
            if l > 1:
                for j in range(n_samples):
                    start = max(0, j - l)
                    end = min(n_samples, j + l + 1)
                    squashed[j] = np.mean(squashed[start:end])
            result[:, i] = squashed
        return result
    
    # ç”Ÿæˆæ’åˆ—æ—¶ä¸åŒ…å«ç¼–å·
    def generate_permutations(algorithms):
        """ç”Ÿæˆå®Œæ•´çš„ç®—æ³•æ’åˆ—ç»„åˆï¼Œæ’åˆ—åç§°ä¸åŒ…å«ç¼–å·"""
        # ä¸ºå››ç§ç®—æ³•åˆ†é…ç¼–å·1-4ï¼ˆäºŒé˜¶å·®åˆ†å½’ç±»åˆ°åŸºçº¿æ ¡å‡†ä¸­ï¼‰
        algorithm_list = [
            (1, "åŸºçº¿æ ¡å‡†", algorithms['baseline']),
            (2, "ç¼©æ”¾", algorithms['scaling']),
            (3, "æ»¤æ³¢", algorithms['filtering']),
            (4, "æŒ¤å‹", algorithms['squashing'])
        ]
        
        all_permutations = []
        
        # 0. æ·»åŠ "æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"é€‰é¡¹ï¼ˆ1ç§ï¼‰
        all_permutations.append([])  # ç©ºåˆ—è¡¨è¡¨ç¤ºä¸ä½¿ç”¨ä»»ä½•ç®—æ³•
        
        # 1. ç”Ÿæˆä½¿ç”¨1ç§ç®—æ³•çš„æ’åˆ—
        for algo in algorithm_list:
            if algo[2] != "æ— ":  # åªåŒ…å«å·²é€‰æ‹©çš„ç®—æ³•
                all_permutations.append([algo])
        
        # 2. ç”Ÿæˆä½¿ç”¨2ç§ç®—æ³•çš„æ’åˆ—
        for perm in itertools.permutations(algorithm_list, 2):
            # ç¡®ä¿ä¸¤ç§ç®—æ³•éƒ½å·²é€‰æ‹©
            if perm[0][2] != "æ— " and perm[1][2] != "æ— ":
                all_permutations.append(list(perm))
        
        # 3. ç”Ÿæˆä½¿ç”¨3ç§ç®—æ³•çš„æ’åˆ—
        for perm in itertools.permutations(algorithm_list, 3):
            # ç¡®ä¿ä¸‰ç§ç®—æ³•éƒ½å·²é€‰æ‹©
            if perm[0][2] != "æ— " and perm[1][2] != "æ— " and perm[2][2] != "æ— ":
                all_permutations.append(list(perm))
        
        # 4. ç”Ÿæˆä½¿ç”¨4ç§ç®—æ³•çš„æ’åˆ—
        for perm in itertools.permutations(algorithm_list, 4):
            # ç¡®ä¿å››ç§ç®—æ³•éƒ½å·²é€‰æ‹©
            if (perm[0][2] != "æ— " and perm[1][2] != "æ— " and 
                perm[2][2] != "æ— " and perm[3][2] != "æ— "):
                all_permutations.append(list(perm))
        
        # æ ¼å¼åŒ–æ’åˆ—ç»“æœï¼Œç¡®ä¿æ¯ç§æ’åˆ—éƒ½æœ‰first_step_typeï¼Œä¸”åç§°ä¸åŒ…å«ç¼–å·
        formatted_perms = []
        for i, perm in enumerate(all_permutations):
            # åˆå§‹åŒ–é»˜è®¤å€¼ï¼Œç¡®ä¿å±æ€§å­˜åœ¨
            perm_dict = {
                "name": "",
                "order": [],
                "details": perm,
                "count": len(perm),
                "first_step_type": "æœªçŸ¥"  # é»˜è®¤å€¼ï¼Œç¡®ä¿å±æ€§å­˜åœ¨
            }
            
            if not perm:  # æ— é¢„å¤„ç†æƒ…å†µ
                perm_dict["name"] = "æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"
                perm_dict["first_step_type"] = "æ— é¢„å¤„ç†"
            else:
                # è·å–ç¬¬ä¸€æ­¥ç®—æ³•çš„ç±»å‹åç§°
                first_step_type = perm[0][1] if perm and len(perm) > 0 else "æœªçŸ¥"
                perm_dict["first_step_type"] = first_step_type
                
                # ç”Ÿæˆæ’åˆ—åç§°ï¼Œä¸åŒ…å«ç¼–å·
                perm_details = []
                for step in perm:
                    perm_details.append(f"{step[0]}.{step[1]}({step[2]})")
                perm_dict["name"] = " â†’ ".join(perm_details)
                perm_dict["order"] = [step[0] for step in perm]
            
            formatted_perms.append(perm_dict)
        
        return formatted_perms
    
    # ===== åˆ†ç±»ç®—æ³•å®ç° =====
    def knn_classify(train_data, train_labels, test_data, k=5):
        """Kè¿‘é‚»åˆ†ç±»ç®—æ³•å®ç°"""
        # è½¬ç½®æ•°æ®ä»¥é€‚åº”æ ·æœ¬æ•°Ã—ç‰¹å¾æ•°çš„æ ¼å¼
        train_data = train_data.T
        test_data = test_data.T
        
        predictions = []
        for test_sample in test_data:
            # è®¡ç®—ä¸æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„æ¬§æ°è·ç¦»
            distances = np.sqrt(np.sum((train_data - test_sample) **2, axis=1))
            # è·å–æœ€è¿‘çš„kä¸ªæ ·æœ¬çš„ç´¢å¼•
            k_indices = np.argsort(distances)[:k]
            # è·å–è¿™äº›æ ·æœ¬çš„æ ‡ç­¾
            k_nearest_labels = [train_labels[i] for i in k_indices]
            # å¤šæ•°æŠ•ç¥¨å†³å®šé¢„æµ‹æ ‡ç­¾
            most_common = np.bincount(k_nearest_labels).argmax()
            predictions.append(most_common)
        return np.array(predictions)
    
    # ===== é¢„å¤„ç†ç±» =====
    class Preprocessor:
        def __init__(self):
            self.BASELINE_ALGORITHMS = {
                "SD": self._sd_baseline,
                "FD": self._fd_baseline,
                "å¤šé¡¹å¼æ‹Ÿåˆ": polynomial_fit,
                "ModPoly": modpoly,
                "I-ModPoly": IModPoly,  # é›†æˆIModPolyç®—æ³•
                "PLS": pls,
                "AsLS": baseline_als,  # ä½¿ç”¨æ”¹è¿›çš„AsLSç®—æ³•
                "airPLS": airpls,
                "äºŒé˜¶å·®åˆ†(D2)": self.d2  # å°†äºŒé˜¶å·®åˆ†å½’ç±»åˆ°åŸºçº¿æ ¡å‡†ä¸­
            }
            self.FILTERING_ALGORITHMS = {
                "Savitzky-Golay": self.savitzky_golay,
                "sgolayfiltæ»¤æ³¢å™¨": self.sgolay_filter_custom,  # æ·»åŠ è‡ªå®šä¹‰SGæ»¤æ³¢å™¨
                "ä¸­å€¼æ»¤æ³¢(MF)": self.median_filter,
                "ç§»åŠ¨å¹³å‡(MAF)": self.moving_average,
                "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰": self.mwa_filter,  # æ·»åŠ MWAç®—æ³•
                "å¡å°”æ›¼æ»¤æ³¢": self.kalman_filter,  # æ·»åŠ å¡å°”æ›¼æ»¤æ³¢ç®—æ³•
                "Lowess": self.lowess_filter,
                "FFT": self.fft_filter,
                "å°æ³¢å˜æ¢(DWT)": self.wavelet_filter
            }
            
            self.SCALING_ALGORITHMS = {
                "Peak-Norm": self.peak_norm,
                "SNV": self.snv,
                "MSC": self.msc,  # ä½¿ç”¨æ–°çš„MSCå®ç°
                "M-M-Norm": self.mm_norm,
                "L-èŒƒæ•°": self.l_norm,  # ä½¿ç”¨LPnormå‡½æ•°å®ç°
                "Ma-Minorm": self.ma_minorm,  # æ·»åŠ Ma-Minormå½’ä¸€åŒ–
                "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)": self.standardize  # æ·»åŠ æ ‡å‡†åŒ–ç®—æ³•
            }
            
            self.SQUASHING_ALGORITHMS = {
                "SigmoidæŒ¤å‹": sigmoid,
                "æ”¹è¿›çš„SigmoidæŒ¤å‹": i_sigmoid,
                "é€»è¾‘å‡½æ•°": squashing,
                "æ”¹è¿›çš„é€»è¾‘å‡½æ•°": i_squashing,
                "DTWæŒ¤å‹": dtw_squashing
            }
    
        def process(self, wavenumbers, data, 
                    baseline_method="æ— ", baseline_params=None,
                    squashing_method="æ— ", squashing_params=None,
                    filtering_method="æ— ", filtering_params=None,
                    scaling_method="æ— ", scaling_params=None,
                    algorithm_order=None):
            """æ‰§è¡Œé¢„å¤„ç†æµç¨‹ï¼Œæ”¯æŒæŒ‡å®šç®—æ³•é¡ºåºï¼Œç©ºé¡ºåºè¡¨ç¤ºè¿”å›åŸå§‹æ•°æ®"""
            if baseline_params is None: baseline_params = {}
            if squashing_params is None: squashing_params = {}
            if filtering_params is None: filtering_params = {}
            if scaling_params is None: scaling_params = {}
                
            # å¦‚æœç®—æ³•é¡ºåºä¸ºç©ºï¼ˆæ— é¢„å¤„ç†ï¼‰ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
            if algorithm_order is not None and len(algorithm_order) == 0:
                return data.copy(), ["æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"]
                
            y_processed = data.copy()
            method_name = []
            
            # å¦‚æœæŒ‡å®šäº†ç®—æ³•é¡ºåºï¼Œåˆ™æŒ‰é¡ºåºæ‰§è¡Œ
            if algorithm_order is not None and len(algorithm_order) > 0:
                # æ ¹æ®ç®—æ³•ç¼–å·æ˜ å°„åˆ°å¯¹åº”çš„å¤„ç†æ­¥éª¤
                step_mapping = {
                    1: ("baseline", baseline_method, baseline_params),
                    2: ("scaling", scaling_method, scaling_params),
                    3: ("filtering", filtering_method, filtering_params),
                    4: ("squashing", squashing_method, squashing_params)
                }
                # æŒ‰æŒ‡å®šé¡ºåºåˆ›å»ºæ­¥éª¤åˆ—è¡¨
                steps = [step_mapping[order] for order in algorithm_order]
            else:
                # é»˜è®¤é¡ºåºï¼šåŸºçº¿ â†’ æŒ¤å‹ â†’ æ»¤æ³¢ â†’ ç¼©æ”¾ï¼ˆåªæ‰§è¡Œå·²é€‰æ‹©çš„æ–¹æ³•ï¼‰
                steps = []
                if baseline_method != "æ— ":
                    steps.append(("baseline", baseline_method, baseline_params))
                if squashing_method != "æ— ":
                    steps.append(("squashing", squashing_method, squashing_params))
                if filtering_method != "æ— ":
                    steps.append(("filtering", filtering_method, filtering_params))
                if scaling_method != "æ— ":
                    steps.append(("scaling", scaling_method, scaling_params))
    
            # æŒ‰é¡ºåºæ‰§è¡Œé¢„å¤„ç†æ­¥éª¤
            for step_type, method, params in steps:
                if method == "æ— ":
                    continue
                    
                try:
                    if step_type == "baseline":
                        algorithm_func = self.BASELINE_ALGORITHMS[method]
                        if method in ["å¤šé¡¹å¼æ‹Ÿåˆ", "ModPoly", "I-ModPoly"]:
                            y_processed = algorithm_func(wavenumbers, y_processed,** params)
                        elif method in ["PLS"]:
                            y_processed = algorithm_func(y_processed, **params)
                        elif method == "AsLS":
                            # é€‚é…æ”¹è¿›çš„AsLSç®—æ³•å‚æ•°
                            y_processed = algorithm_func(y_processed,** params)
                        elif method == "airPLS":
                            y_processed = algorithm_func(y_processed, **params)
                        elif method == "äºŒé˜¶å·®åˆ†(D2)":  # å¤„ç†äºŒé˜¶å·®åˆ†
                            y_processed = algorithm_func(y_processed)
                        else:  # SDã€FD æ— é¢å¤–å‚æ•°
                            y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}({', '.join([f'{k}={v}' for k, v in params.items()])})")
                            
                    elif step_type == "squashing":
                        algorithm_func = self.SQUASHING_ALGORITHMS[method]
                        if method == "æ”¹è¿›çš„SigmoidæŒ¤å‹":
                            y_processed = algorithm_func(y_processed, maxn=10)
                            method_name.append(f"{method}(maxn=10)")
                        elif method == "æ”¹è¿›çš„é€»è¾‘å‡½æ•°":
                            m = params.get("m", 10)
                            y_processed = algorithm_func(y_processed)
                            method_name.append(f"{method}(m={m})")
                        elif method == "DTWæŒ¤å‹":
                            l = params.get("l", 1)
                            k1 = params.get("k1", "T")
                            k2 = params.get("k2", "T")
                            y_processed = algorithm_func(y_processed, l=l, k1=k1, k2=k2)
                            method_name.append(f"DTWæŒ¤å‹(l={l}, k1={k1}, k2={k2})")
                        else:
                            y_processed = algorithm_func(y_processed)
                            method_name.append(method)
                            
                    elif step_type == "filtering":
                        algorithm_func = self.FILTERING_ALGORITHMS[method]
                        y_processed = algorithm_func(y_processed,** params)
                        params_str = ', '.join([f'{k}={v}' for k, v in params.items()])
                        method_name.append(f"{method}({params_str})")
                        
                    elif step_type == "scaling":
                        algorithm_func = self.SCALING_ALGORITHMS[method]
                        y_processed = algorithm_func(y_processed, **params)
                        params_str = ', '.join([f'{k}={v}' for k, v in params.items()])
                        method_name.append(f"{method}({params_str})")
                        
                except Exception as e:
                    raise ValueError(f"{step_type}å¤„ç†å¤±è´¥: {str(e)}")
    
            return y_processed, method_name
         
        def _sd_baseline(self, spectra):
            return spectra - np.min(spectra, axis=0)
        
        def _fd_baseline(self, spectra):
            return spectra - np.percentile(spectra, 5, axis=0)
    
        # ===== æ»¤æ³¢ç®—æ³•å®ç° =====
        def savitzky_golay(self, spectra, k, w):
            return savgol_filter(spectra, w, k, axis=0)
        
        # è‡ªå®šä¹‰sgolayfiltæ»¤æ³¢å™¨çš„å°è£…
        def sgolay_filter_custom(self, spectra, point, degree):
            """ä½¿ç”¨è‡ªå®šä¹‰çš„SGfilterå‡½æ•°è¿›è¡Œæ»¤æ³¢"""
            # ç¡®ä¿è¾“å…¥æ•°æ®å½¢çŠ¶ä¸SGfilterè¦æ±‚ä¸€è‡´
            if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
                filtered = SGfilter(spectra.T, point, degree)
                return filtered.T  # è½¬å›åŸå§‹å½¢çŠ¶
            else:
                return SGfilter(spectra, point, degree)
        
        def median_filter(self, spectra, k, w):
            return medfilt(spectra, kernel_size=(w, 1))
        
        def moving_average(self, spectra, k, w):
            kernel = np.ones(w) / w
            return np.apply_along_axis(lambda x: np.convolve(x, kernel, mode='same'), 0, spectra)
        
        # æ·»åŠ MWAæ»¤æ³¢æ–¹æ³•çš„å°è£…
        def mwa_filter(self, spectra, n=6, it=1, mode="full"):
            return MWA(spectra, n=n, it=it, mode=mode)
        
        # æ·»åŠ å¡å°”æ›¼æ»¤æ³¢æ–¹æ³•çš„å°è£…
        def kalman_filter(self, spectra, R=0.1):
            return KalmanF(spectra, R)
        
        def lowess_filter(self, spectra, frac):
            result = np.zeros_like(spectra)
            for i in range(spectra.shape[1]):
                smoothed = lowess(spectra[:, i], np.arange(len(spectra)), frac=frac, it=0)
                result[:, i] = smoothed[:, 1]
            return result
        
        def fft_filter(self, spectra, cutoff):
            fft_result = fft(spectra, axis=0)
            frequencies = np.fft.fftfreq(spectra.shape[0])
            filter_mask = np.abs(frequencies) < cutoff
            fft_result[~filter_mask, :] = 0
            return np.real(ifft(fft_result, axis=0))
        
        def wavelet_filter(self, spectra, threshold):
            coeffs = pywt.wavedec(spectra, 'db4', axis=0)
            coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]
            return pywt.waverec(coeffs, 'db4', axis=0)
        
        # ===== ç¼©æ”¾ç®—æ³•å®ç° =====
        def peak_norm(self, spectra):
            return spectra / np.max(spectra, axis=0)
        
        def snv(self, spectra):
            mean = np.mean(spectra, axis=0)
            std = np.std(spectra, axis=0)
            return (spectra - mean) / std
        
        def msc(self, spectra):
            """ä½¿ç”¨æ–°çš„MSCå‡½æ•°å®ç°å¤šå…ƒæ•£å°„æ ¡æ­£"""
            # æ³¨æ„ï¼šè¾“å…¥æ•°æ®å½¢çŠ¶éœ€è¦ä¸MSCå‡½æ•°è¦æ±‚ä¸€è‡´ (n_samples, n_features)
            # å¦‚æœå½“å‰æ•°æ®å½¢çŠ¶ä¸º(n_features, n_samples)ï¼Œéœ€è¦å…ˆè½¬ç½®
            if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œè¯´æ˜éœ€è¦è½¬ç½®
                corrected = MSC(spectra.T)  # è½¬ç½®åå¤„ç†
                return corrected.T  # è½¬å›åŸå§‹å½¢çŠ¶
            else:
                return MSC(spectra)
        
        def mm_norm(self, spectra):
            min_vals = np.min(spectra, axis=0)
            max_vals = np.max(spectra, axis=0)
            return (spectra - min_vals) / (max_vals - min_vals)
        
        def l_norm(self, spectra, p):
            """ä½¿ç”¨LPnormå‡½æ•°å®ç°L-èŒƒæ•°å½’ä¸€åŒ–"""
            if p == "æ— ç©·å¤§":
                return LPnorm(spectra, np.inf)
            else:
                p_val = float(p)
                return LPnorm(spectra, p_val)
        
        def ma_minorm(self, spectra):
            """ä½¿ç”¨MaMinormå‡½æ•°å®ç°å½’ä¸€åŒ–"""
            return MaMinorm(spectra)
        
        # æ ‡å‡†åŒ–ç®—æ³•å®ç°ï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰
        def standardize(self, spectra):
            """ä½¿ç”¨plotstå‡½æ•°å®ç°æ ‡å‡†åŒ–å¤„ç†"""
            # å¤„ç†æ•°æ®å½¢çŠ¶é€‚é…
            if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
                standardized = plotst(spectra.T)  # è½¬ç½®åå¤„ç†
                return standardized.T  # è½¬å›åŸå§‹å½¢çŠ¶
            else:
                return plotst(spectra)
        
        # äºŒé˜¶å·®åˆ†æ–¹æ³•çš„å°è£…ï¼ˆå½’ç±»åˆ°åŸºçº¿æ ¡å‡†ï¼‰
        def d2(self, spectra):
            """ä½¿ç”¨D2å‡½æ•°å®ç°äºŒé˜¶å·®åˆ†è®¡ç®—"""
            # å¤„ç†æ•°æ®å½¢çŠ¶é€‚é…
            if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
                diff_result = D2(spectra.T)  # è½¬ç½®åå¤„ç†
                return diff_result.T  # è½¬å›åŸå§‹å½¢çŠ¶
            else:
                return D2(spectra)
    
    # ===== æ–‡ä»¶å¤„ç†ç±» =====
    class FileHandler:
        def load_data(self, wavenumber_file, data_file, lines, much):
            wavenumbers = np.loadtxt(wavenumber_file).ravel()
            return wavenumbers, self._getfromone(data_file, lines, much).T 
        
        def _getfromone(self, file, lines, much):
            numb = re.compile(r"-?\d+(?:\.\d+)?")
            ret = np.zeros((lines, much), dtype=float)
            content = file.getvalue().decode("utf-8")
            lines_list = content.splitlines()
            con = 0
            
            for line in lines_list:
                if con >= much:
                    break
                    
                li = numb.findall(line)
                for i in range(min(lines, len(li))):
                    ret[i][con] = float(li[i])
                con += 1
                
            return ret
        
        def export_data(self, filename, data):
            with open(filename, "w") as f:
                for line in data.T:  # è½¬ç½®å›åŸå§‹æ ¼å¼
                    f.write("\t".join(map(str, line)) + "\n")
    
    # åˆ›å»ºå¤„ç†å™¨å®ä¾‹
    file_handler = FileHandler()
    preprocessor = Preprocessor()
    
    # åˆ›å»ºä¸‰åˆ—ä¸»å¸ƒå±€
    col_left, col_mid, col_right = st.columns([1.2, 2.8, 1.1])
    
    # ===== å·¦ä¾§ï¼šæ•°æ®ç®¡ç† =====
    with col_left:
        with st.expander("ğŸ“ æ•°æ®ç®¡ç†", expanded=True):
            # ç´§å‡‘æ’åˆ—ä¸Šä¼ ç»„ä»¶
            wavenumber_file = st.file_uploader("ä¸Šä¼ æ³¢æ•°æ–‡ä»¶", type=['txt'], label_visibility="collapsed", key="wn_file")
            st.caption("æ³¢æ•°æ–‡ä»¶(.txt)")
            uploaded_file = st.file_uploader("ä¸Šä¼ å…‰è°±æ•°æ®æ–‡ä»¶", type=['txt'], label_visibility="collapsed", key="spec_file")
            st.caption("å…‰è°±æ•°æ®æ–‡ä»¶(.txt)")
            
            # ç´§å‡‘æ ‡ç­¾è¾“å…¥
            st.subheader("æ ·æœ¬æ ‡ç­¾", divider="gray")
            num_classes = st.number_input("ç±»åˆ«æ•°é‡", min_value=1, value=2, step=1, key="num_cls")
            labels_input = st.text_input(
                "æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼Œä¸å…‰è°±é¡ºåºä¸€è‡´ï¼‰", 
                placeholder="ä¾‹ï¼š0,0,1,1",
                key="labels_in"
            )
            
            # æ•°æ®å‚æ•°ï¼ˆæ¨ªå‘æ’åˆ—æ›´ç´§å‡‘ï¼‰
            param_col1, param_col2 = st.columns(2)
            with param_col1:
                lines = st.number_input("å…‰è°±æ¡æ•°", min_value=1, value=1, key="spec_lines")
            with param_col2:
                much = st.number_input("æ•°æ®ç‚¹æ•°", min_value=1, value=2000, key="data_pts")

            # è®­ç»ƒæµ‹è¯•æ¯”ä¾‹
            train_test_ratio = st.slider(
               "è®­ç»ƒé›†æ¯”ä¾‹",
               min_value=0.1,
               max_value=0.9,
               value=0.8,
               step=0.1,
               format="%.1f",
               key="train_ratio"
            )
            st.session_state.train_test_split_ratio = train_test_ratio
    
            # æ•°æ®åŠ è½½é€»è¾‘
            if uploaded_file and wavenumber_file:
                try:
                    st.session_state.raw_data = file_handler.load_data(
                        wavenumber_file, uploaded_file, lines, much
                    )
                    
                    # å¤„ç†æ ‡ç­¾
                    if labels_input:
                        try:
                            labels = np.array([int(l.strip()) for l in labels_input.split(',')])
                            if len(labels) == st.session_state.raw_data[1].shape[1]:
                                st.session_state.labels = labels
                                n_samples = len(labels)
                                train_size = int(n_samples * train_test_ratio)
                                indices = np.random.permutation(n_samples)
                                st.session_state.train_indices = indices[:train_size]
                                st.session_state.test_indices = indices[train_size:]
                                st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{lines}æ¡å…‰è°±ï¼Œ{len(np.unique(labels))}ç±»")
                            else:
                                st.warning(f"âš ï¸ æ ‡ç­¾æ•°({len(labels)})â‰ å…‰è°±æ•°({st.session_state.raw_data[1].shape[1]})")
                                st.session_state.labels = None
                        except Exception as e:
                            st.warning(f"âš ï¸ æ ‡ç­¾æ ¼å¼é”™è¯¯: {str(e)}")
                            st.session_state.labels = None
                    else:
                        st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{lines}æ¡å…‰è°±ï¼Œ{much}ä¸ªç‚¹")
                        st.warning("âš ï¸ è¯·è¾“å…¥æ ·æœ¬æ ‡ç­¾ä»¥è¿›è¡Œåˆ†ç±»æµ‹è¯•")
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        
        # ç³»ç»Ÿä¿¡æ¯ï¼ˆç´§å‡‘æ˜¾ç¤ºï¼‰
        if st.session_state.get('raw_data'):
            wavenumbers, y = st.session_state.raw_data
            st.info(f"ğŸ“Š æ•°æ®ç»´åº¦: {y.shape[1]}æ¡ Ã— {y.shape[0]}ç‚¹")
            st.info(f"ğŸ”¢ è®­ç»ƒé›†:{train_test_ratio:.1f} | æµ‹è¯•é›†:{1-train_test_ratio:.1f}")
            if st.session_state.get('labels') is not None:
                class_counts = np.bincount(st.session_state.labels)
                st.info(f"ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ: {', '.join([f'ç±»{i}:{count}ä¸ª' for i, count in enumerate(class_counts) if count>0])}")
            if st.session_state.get('process_method'):
                st.success(f"ğŸ› ï¸ å¤„ç†æµç¨‹: {st.session_state.process_method}")
        
        # ä½¿ç”¨è¯´æ˜ï¼ˆç²¾ç®€ï¼‰
        with st.expander("â„¹ï¸ ä½¿ç”¨æŒ‡å—", expanded=False):
            st.markdown("""
            1. ä¸Šä¼ æ³¢æ•°+å…‰è°±æ–‡ä»¶  
            2. è®¾ç½®æ ‡ç­¾å’Œæ•°æ®å‚æ•°  
            3. å³ä¾§é€‰æ‹©é¢„å¤„ç†æ–¹æ³•  
            4. ç‚¹å‡»"æ˜¾ç¤ºæ’åˆ—"ç”Ÿæˆæ–¹æ¡ˆ  
            5. é€‰æ‹©kå€¼åç‚¹å‡»"æµ‹è¯•"  
            6. ä¸­é—´æŸ¥çœ‹ç»“æœå¹¶å¯¼å‡º
            """)
     
    # ===== ä¸­é—´ï¼šå…‰è°±å¯è§†åŒ–ä¸ç»“æœå¯¼å‡º =====
    with col_mid:
        st.subheader("ğŸ“ˆ å…‰è°±å¯è§†åŒ–", divider="gray")
        
        # 1. åŸå§‹å…‰è°±åŒºåŸŸ
        st.subheader("åŸå§‹å…‰è°±", divider="gray")
        # ç¬¬ä¸€å±‚åˆ—ï¼ˆå…è®¸ï¼‰
        spec_cols = st.columns(2)
        with spec_cols[0]:
            if st.session_state.get('raw_data'):
                wavenumbers, y = st.session_state.raw_data
                idx1 = 0 if y.shape[1] > 0 else 0
                raw_data1 = pd.DataFrame({"åŸå§‹å…‰è°±1": y[:, idx1]}, index=wavenumbers)
                st.line_chart(raw_data1, height=200)
            else:
                st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ç­‰å¾…åŠ è½½åŸå§‹æ•°æ®</div>', unsafe_allow_html=True)
        
        with spec_cols[1]:
            if st.session_state.get('raw_data') and y.shape[1] > 1:
                idx2 = 1
                raw_data2 = pd.DataFrame({"åŸå§‹å…‰è°±2": y[:, idx2]}, index=wavenumbers)
                st.line_chart(raw_data2, height=200)
            elif st.session_state.get('raw_data'):
                st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ä»…1æ¡åŸå§‹å…‰è°±</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ç­‰å¾…åŠ è½½åŸå§‹æ•°æ®</div>', unsafe_allow_html=True)
            
            # å¯é€‰ï¼šæ˜¾ç¤ºæ›´å¤šåŸå§‹å…‰è°±ï¼ˆä¸ä½¿ç”¨æ·±å±‚åµŒå¥—ï¼‰
            if st.session_state.get('raw_data') and y.shape[1] > 2:
                with st.expander("æŸ¥çœ‹æ›´å¤šåŸå§‹å…‰è°±", expanded=False):
                    # ä»…ä½¿ç”¨ä¸€å±‚åˆ—
                    more_spec = st.columns(2)
                    for i in range(2, min(y.shape[1], 6), 2):
                        with more_spec[0]:
                            if i < y.shape[1]:
                                data = pd.DataFrame({f"åŸå§‹å…‰è°±{i+1}": y[:, i]}, index=wavenumbers)
                                st.line_chart(data, height=150)
                        with more_spec[1]:
                            if i+1 < y.shape[1]:
                                data = pd.DataFrame({f"åŸå§‹å…‰è°±{i+2}": y[:, i+1]}, index=wavenumbers)
                                st.line_chart(data, height=150)
            
        # 2. å¤„ç†ç»“æœå±•ç¤º
        if st.session_state.get('selected_arrangement'):
            st.subheader("ğŸ” é¢„å¤„ç†ç»“æœ", divider="gray")
            selected_arr = st.session_state.selected_arrangement
            arr_data = st.session_state.arrangement_details[selected_arr]['data']
            arr_method = st.session_state.arrangement_details[selected_arr]['method']
            arr_order = st.session_state.arrangement_details[selected_arr].get('order', [])
            
            # å¤„ç†ä¿¡æ¯ï¼ˆç´§å‡‘æ˜¾ç¤ºï¼‰
            st.caption(f"å¤„ç†æ–¹æ³•: {arr_method} | æ‰§è¡Œé¡ºåº: {arr_order if arr_order else 'æ— é¢„å¤„ç†'}")
            
            # é¢„å¤„ç†åå…‰è°±ï¼ˆä»…ä¸€å±‚åˆ—ï¼‰
            st.subheader("é¢„å¤„ç†åå…‰è°±", divider="gray")
            proc_cols = st.columns(2)
            with proc_cols[0]:
                idx1 = 0 if arr_data.shape[1] > 0 else 0
                proc_data1 = pd.DataFrame({"é¢„å¤„ç†å1": arr_data[:, idx1]}, index=wavenumbers)
                st.line_chart(proc_data1, height=200)
            with proc_cols[1]:
                if arr_data.shape[1] > 1:
                    idx2 = 1
                    proc_data2 = pd.DataFrame({"é¢„å¤„ç†å2": arr_data[:, idx2]}, index=wavenumbers)
                    st.line_chart(proc_data2, height=200)
                else:
                    st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ä»…1æ¡é¢„å¤„ç†å…‰è°±</div>', unsafe_allow_html=True)
            
            # kå€¼æ›²çº¿ï¼ˆä»…ä¸€å±‚åˆ—ï¼‰
            if arr_order:
                st.subheader("kå€¼æ›²çº¿", divider="gray")
                k_cols = st.columns(2)
                with k_cols[0]:
                    k_vals1 = np.abs(arr_data[:, 0] / (y[:, 0] + 1e-8)) if y.shape[1] > 0 else np.array([])
                    k_data1 = pd.DataFrame({"kå€¼1": k_vals1}, index=wavenumbers)
                    st.line_chart(k_data1, height=200)
                with k_cols[1]:
                    if y.shape[1] > 1:
                        k_vals2 = np.abs(arr_data[:, 1] / (y[:, 1] + 1e-8))
                        k_data2 = pd.DataFrame({"kå€¼2": k_vals2}, index=wavenumbers)
                        st.line_chart(k_data2, height=200)
                    else:
                        st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ä»…1æ¡kå€¼æ›²çº¿</div>', unsafe_allow_html=True)
            else:
                st.info("â„¹ï¸ æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰ï¼Œä¸æ˜¾ç¤ºkå€¼æ›²çº¿")
            
            # åŸå§‹ä¸å¤„ç†åå¯¹æ¯”ï¼ˆä»…ä¸€å±‚åˆ—ï¼‰
            st.subheader("åŸå§‹vsé¢„å¤„ç†å¯¹æ¯”", divider="gray")
            comp_cols = st.columns(2)
            with comp_cols[0]:
                if y.shape[1] > 0:
                    comp_data1 = pd.DataFrame({
                        "åŸå§‹": y[:, 0],
                        "é¢„å¤„ç†å": arr_data[:, 0]
                    }, index=wavenumbers)
                    st.line_chart(comp_data1, height=200)
            with comp_cols[1]:
                if y.shape[1] > 1:
                    comp_data2 = pd.DataFrame({
                        "åŸå§‹": y[:, 1],
                        "é¢„å¤„ç†å": arr_data[:, 1]
                    }, index=wavenumbers)
                    st.line_chart(comp_data2, height=200)
                else:
                    st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ä»…1æ¡å¯¹æ¯”æ›²çº¿</div>', unsafe_allow_html=True)
            
            # æµ‹è¯•ç»“æœ
            if st.session_state.get('test_results') is not None:
                st.subheader("ğŸ“Š åˆ†ç±»æµ‹è¯•ç»“æœ", divider="gray")
                results = st.session_state.test_results
                
                # æŒ‡æ ‡ï¼ˆä»…ä¸€å±‚åˆ—ï¼‰
                metrics_cols = st.columns(2)
                with metrics_cols[0]:
                    st.metric("å‡†ç¡®ç‡", f"{results['accuracy']:.4f}", delta=None)
                with metrics_cols[1]:
                    st.metric("å¡å¸•ç³»æ•°", f"{results['kappa']:.4f}", delta=None)
                
                # æ··æ·†çŸ©é˜µ
                st.subheader("æ··æ·†çŸ©é˜µ", divider="gray")
                fig, ax = plt.subplots(figsize=(5, 4))
                sns.heatmap(results['confusion_matrix'], annot=True, fmt='d', cmap='Blues', ax=ax, annot_kws={"size": 8})
                ax.set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=8)
                ax.set_ylabel('çœŸå®æ ‡ç­¾', fontsize=8)
                ax.set_title('æ··æ·†çŸ©é˜µ', fontsize=10)
                plt.xticks(fontsize=7)
                plt.yticks(fontsize=7)
                st.pyplot(fig, use_container_width=True)
        else:
            # æœªé€‰æ‹©æ’åˆ—æ—¶çš„æç¤º
            st.info("â„¹ï¸ è¯·åœ¨å³ä¾§é€‰æ‹©é¢„å¤„ç†æ–¹æ³•å¹¶åº”ç”¨æ’åˆ—æ–¹æ¡ˆ")
            
        # ç»“æœå¯¼å‡º
        if st.session_state.arrangement_results or st.session_state.get('processed_data'):
            st.subheader("ğŸ’¾ ç»“æœå¯¼å‡º", divider="gray")
            # ä»…ä¸€å±‚åˆ—
            export_cols = st.columns([3, 1])
            with export_cols[0]:
                export_name = st.text_input("å¯¼å‡ºæ–‡ä»¶å", "processed_spectra.txt", key="export_name")
            with export_cols[1]:
                st.markdown("<br>", unsafe_allow_html=True)  # å‚ç›´å¯¹é½
                if st.button("å¯¼å‡º", type="secondary", key="export_btn"):
                    try:
                        if st.session_state.selected_arrangement:
                            arr_data = st.session_state.arrangement_details[st.session_state.selected_arrangement]['data']
                            file_handler.export_data(export_name, arr_data)
                        else:
                            wavenumbers, y_processed = st.session_state.processed_data
                            file_handler.export_data(export_name, y_processed)
                        st.success(f"âœ… å·²å¯¼å‡ºåˆ° {export_name}")
                    except Exception as e:
                        st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
        else:
            st.markdown('<div style="border:1px dashed #ccc; height:80px; display:flex; align-items:center; justify-content:center;">å¤„ç†å®Œæˆåå¯å¯¼å‡ºç»“æœ</div>', unsafe_allow_html=True)

    
    # ===== å³ä¾§ï¼šé¢„å¤„ç†è®¾ç½® + æ’åˆ—æ–¹æ¡ˆé€‰æ‹© + æµ‹è¯•åŠŸèƒ½ =====
    with col_right:
        with st.expander("âš™ï¸ é¢„å¤„ç†è®¾ç½®", expanded=True):
            # 1. åŸºçº¿æ ¡å‡†ï¼ˆåŒ…å«äºŒé˜¶å·®åˆ†ï¼‰
            st.subheader("åŸºçº¿æ ¡å‡†", divider="gray")
            baseline_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "SD", "FD", "å¤šé¡¹å¼æ‹Ÿåˆ", "ModPoly", "I-ModPoly", "PLS", "AsLS", "airPLS", "äºŒé˜¶å·®åˆ†(D2)"],
                key="baseline_method",
                label_visibility="collapsed"
            )
    
            # åŸºçº¿å‚æ•°
            baseline_params = {}
            if baseline_method != "æ— ":
                if baseline_method == "å¤šé¡¹å¼æ‹Ÿåˆ":
                    polyorder = st.slider("é˜¶æ•°k", 3, 6, 5, key="polyorder", label_visibility="collapsed")
                    baseline_params["polyorder"] = polyorder
                    st.caption(f"é˜¶æ•°: {polyorder}")
                elif baseline_method == "ModPoly":
                    k = st.slider("å‚æ•°k", 4, 10, 10, key="k_mod", label_visibility="collapsed")
                    baseline_params["k"] = k
                    st.caption(f"k: {k}")
                elif baseline_method == "I-ModPoly":  # IModPolyå‚æ•°è®¾ç½®
                    polyorder = st.slider("å¤šé¡¹å¼é˜¶æ•°", 3, 7, 5, key="imod_polyorder", label_visibility="collapsed")
                    max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 50, 200, 100, key="imod_maxiter", label_visibility="collapsed")
                    tolerance = st.slider("æ”¶æ•›å®¹å·®", 0.001, 0.01, 0.005, key="imod_tol", label_visibility="collapsed")
                    baseline_params["polyorder"] = polyorder
                    baseline_params["max_iter"] = max_iter
                    baseline_params["tolerance"] = tolerance
                    st.caption(f"é˜¶æ•°: {polyorder}, è¿­ä»£: {max_iter}, å®¹å·®: {tolerance}")
                elif baseline_method == "PLS":
                    lam = st.selectbox("Î»", [10**10, 10**8, 10**7], key="lam_pls", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    st.caption(f"Î»: {lam}")
                elif baseline_method == "AsLS":
                    # ä¸ºæ”¹è¿›çš„AsLSç®—æ³•é…ç½®å‚æ•°
                    asls_cols = st.columns(2)
                    with asls_cols[0]:
                        p = st.selectbox("éå¯¹ç§°ç³»æ•°p", [0.001, 0.01, 0.1], key="p_asls", label_visibility="collapsed")
                    with asls_cols[1]:
                        lam = st.selectbox("å¹³æ»‘ç³»æ•°Î»", [10**5, 10**7, 10**9], key="lam_asls", label_visibility="collapsed")
                    # æ·»åŠ è¿­ä»£æ¬¡æ•°å’Œæ”¶æ•›é˜ˆå€¼å‚æ•°
                    niter = st.selectbox("è¿­ä»£æ¬¡æ•°", [5, 10, 15], key="niter_asls", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    baseline_params["p"] = p
                    baseline_params["niter"] = niter
                    st.caption(f"p: {p}, Î»: {lam}, è¿­ä»£æ¬¡æ•°: {niter}")
                elif baseline_method == "airPLS":
                    # ä»…ä¸€å±‚åˆ—
                    airpls_cols = st.columns(2)
                    with airpls_cols[0]:
                        lam = st.selectbox("Î»", [10**7, 10**4, 10**2], key="lam_air", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    st.caption(f"Î»: {lam}")
                elif baseline_method == "äºŒé˜¶å·®åˆ†(D2)":  # äºŒé˜¶å·®åˆ†å‚æ•°è¯´æ˜
                    st.caption("äºŒé˜¶å·®åˆ†å¯å¢å¼ºå…‰è°±ç‰¹å¾ï¼ŒæŠ‘åˆ¶åŸºçº¿æ¼‚ç§»")
    
            # 2. ç¼©æ”¾å¤„ç†
            st.subheader("ğŸ“ ç¼©æ”¾", divider="gray")
            scaling_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "Peak-Norm", "SNV", "MSC", "M-M-Norm", "L-èŒƒæ•°", "Ma-Minorm", "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)"],
                key="scaling_method",
                label_visibility="collapsed"
            )
    
            # ç¼©æ”¾å‚æ•°
            scaling_params = {}
            if scaling_method == "L-èŒƒæ•°":
                p = st.selectbox("p", ["æ— ç©·å¤§", "4", "10"], key="p_scale", label_visibility="collapsed")
                scaling_params["p"] = p
                st.caption(f"p: {p}")
            # æ ‡å‡†åŒ–ç®—æ³•ä¸éœ€è¦é¢å¤–å‚æ•°ï¼Œä½†æ·»åŠ è¯´æ˜
            elif scaling_method == "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)":
                st.caption("å°†æ•°æ®æ ‡å‡†åŒ–åˆ°å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1")
    
            # 3. æ»¤æ³¢å¤„ç†
            st.subheader("ğŸ“¶ æ»¤æ³¢", divider="gray")
            filtering_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "Savitzky-Golay", "sgolayfiltæ»¤æ³¢å™¨", "ä¸­å€¼æ»¤æ³¢(MF)", "ç§»åŠ¨å¹³å‡(MAF)", 
                 "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰", "å¡å°”æ›¼æ»¤æ³¢", "Lowess", "FFT", "å°æ³¢å˜æ¢(DWT)"],
                key="filtering_method",
                label_visibility="collapsed"
            )
    
            # æ»¤æ³¢å‚æ•°
            filtering_params = {}
            if filtering_method != "æ— ":
                if filtering_method in ["Savitzky-Golay", "sgolayfiltæ»¤æ³¢å™¨"]:
                    # ä»…ä¸€å±‚åˆ—
                    sg_cols = st.columns(2)
                    with sg_cols[0]:
                        k = st.selectbox("å¤šé¡¹å¼é˜¶æ•°", [3, 7], key="k_sg", label_visibility="collapsed")
                    with sg_cols[1]:
                        w = st.selectbox("çª—å£å¤§å°", [11, 31, 51], key="w_sg", label_visibility="collapsed")
                    filtering_params["point"] = w  # å¯¹äºsgolayfiltæ»¤æ³¢å™¨ä½¿ç”¨pointå‚æ•°å
                    filtering_params["degree"] = k  # å¯¹äºsgolayfiltæ»¤æ³¢å™¨ä½¿ç”¨degreeå‚æ•°å
                    st.caption(f"é˜¶æ•°: {k}, çª—å£: {w}")
                elif filtering_method in ["ä¸­å€¼æ»¤æ³¢(MF)", "ç§»åŠ¨å¹³å‡(MAF)"]:
                    # ä»…ä¸€å±‚åˆ—
                    mf_cols = st.columns(2)
                    with mf_cols[0]:
                        k = st.selectbox("k", [1, 3], key="k_mf", label_visibility="collapsed")
                    with mf_cols[1]:
                        w = st.selectbox("w", [7, 11], key="w_mf", label_visibility="collapsed")
                    filtering_params["k"] = k
                    filtering_params["w"] = w
                    st.caption(f"k: {k}, w: {w}")
                # MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰å‚æ•°é…ç½®
                elif filtering_method == "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰":
                    mwa_cols = st.columns(2)
                    with mwa_cols[0]:
                        n = st.selectbox("çª—å£å¤§å°n", [4, 6, 8], key="n_mwa", label_visibility="collapsed")
                    with mwa_cols[1]:
                        it = st.selectbox("è¿­ä»£æ¬¡æ•°it", [1, 2, 3], key="it_mwa", label_visibility="collapsed")
                    filtering_params["n"] = n
                    filtering_params["it"] = it
                    filtering_params["mode"] = "full"  # é»˜è®¤æ¨¡å¼
                    st.caption(f"çª—å£å¤§å°: {n}, è¿­ä»£æ¬¡æ•°: {it}")
                # å¡å°”æ›¼æ»¤æ³¢å‚æ•°é…ç½®
                elif filtering_method == "å¡å°”æ›¼æ»¤æ³¢":
                    R = st.selectbox("æµ‹é‡å™ªå£°æ–¹å·®R", [0.01, 0.1, 0.5], key="r_kalman", label_visibility="collapsed")
                    filtering_params["R"] = R
                    st.caption(f"æµ‹é‡å™ªå£°æ–¹å·®: {R}")
                elif filtering_method == "Lowess":
                    frac = st.selectbox("ç³»æ•°", [0.01, 0.03], key="frac_low", label_visibility="collapsed")
                    filtering_params["frac"] = frac
                    st.caption(f"ç³»æ•°: {frac}")
                elif filtering_method == "FFT":
                    cutoff = st.selectbox("é¢‘ç‡", [30, 50, 90], key="cutoff_fft", label_visibility="collapsed")
                    filtering_params["cutoff"] = cutoff
                    st.caption(f"é¢‘ç‡: {cutoff}")
                elif filtering_method == "å°æ³¢å˜æ¢(DWT)":
                    threshold = st.selectbox("é˜ˆå€¼", [0.1, 0.3, 0.5], key="thresh_dwt", label_visibility="collapsed")
                    filtering_params["threshold"] = threshold
                    st.caption(f"é˜ˆå€¼: {threshold}")

            # 4. æŒ¤å‹å¤„ç†ï¼ˆå½»åº•é¿å…ä¸‰å±‚åµŒå¥—ï¼‰
            st.subheader("ğŸ§ª æŒ¤å‹", divider="gray")
            squashing_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "SigmoidæŒ¤å‹", "æ”¹è¿›çš„SigmoidæŒ¤å‹", "é€»è¾‘å‡½æ•°", "æ”¹è¿›çš„é€»è¾‘å‡½æ•°", "DTWæŒ¤å‹"],
                key="squashing_method",
                label_visibility="collapsed"
            )
    
            # æŒ¤å‹å‚æ•°ï¼ˆä½¿ç”¨åˆ†ç»„è€Œéå¤šå±‚åˆ—ï¼‰
            squashing_params = {}
            if squashing_method != "æ— ":
                if squashing_method == "æ”¹è¿›çš„é€»è¾‘å‡½æ•°":
                    m = st.selectbox("m", [10, 20], key="m_squash", label_visibility="collapsed")
                    squashing_params["m"] = m
                    st.caption(f"m: {m}")
                elif squashing_method == "DTWæŒ¤å‹":
                    # ä½¿ç”¨ä¸¤è¡Œç»„ä»¶è€Œéä¸‰å±‚åˆ—
                    dtw_row1 = st.columns(2)
                    with dtw_row1[0]:
                        l = st.selectbox("l", [1, 5], key="l_dtw", label_visibility="collapsed")
                    with dtw_row1[1]:
                        k1 = st.selectbox("k1", ["T", "F"], key="k1_dtw", label_visibility="collapsed")
                    
                    # ç¬¬äºŒè¡Œå•ç‹¬æ”¾ç½®
                    k2 = st.selectbox("k2", ["T", "F"], key="k2_dtw", label_visibility="collapsed")
                    
                    squashing_params["l"] = l
                    squashing_params["k1"] = k1
                    squashing_params["k2"] = k2
                    st.caption(f"l: {l}, k1: {k1}, k2: {k2}")
                elif squashing_method == "æ”¹è¿›çš„SigmoidæŒ¤å‹":
                    st.caption("é»˜è®¤: maxn=10")
    
            
            # ä¿å­˜å½“å‰é€‰æ‹©çš„ç®—æ³•
            current_algorithms = {
                'baseline': baseline_method,
                'baseline_params': baseline_params,
                'scaling': scaling_method,
                'scaling_params': scaling_params,
                'filtering': filtering_method,
                'filtering_params': filtering_params,
                'squashing': squashing_method,
                'squashing_params': squashing_params
            }
            st.session_state.current_algorithms = current_algorithms
            
            # åº”ç”¨å¤„ç†ä¸æ¨èåº”ç”¨æŒ‰é’®
            st.subheader("æ“ä½œ", divider="gray")
            btn_cols = st.columns(2)
            with btn_cols[0]:
                if st.button("ğŸš€ åº”ç”¨å¤„ç†", type="primary", use_container_width=True, key="apply_btn"):
                    if st.session_state.raw_data is None:
                        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                    else:
                        try:
                            wavenumbers, y = st.session_state.raw_data
                            processed_data, method_name = preprocessor.process(
                                wavenumbers, y, 
                                baseline_method=baseline_method,
                                baseline_params=baseline_params,
                                squashing_method=squashing_method,
                                squashing_params=squashing_params,
                                filtering_method=filtering_method,
                                filtering_params=filtering_params,
                                scaling_method=scaling_method,
                                scaling_params=scaling_params
                            )
                            
                            arr_name = f"æ’åˆ—_{len(st.session_state.arrangement_results) + 1}"
                            st.session_state.arrangement_results.append(arr_name)
                            st.session_state.arrangement_details[arr_name] = {
                                'data': processed_data,
                                'method': " â†’ ".join(method_name),
                                'params': current_algorithms
                            }
                            st.session_state.selected_arrangement = arr_name
                            st.session_state.processed_data = (wavenumbers, processed_data)
                            st.session_state.process_method = " â†’ ".join(method_name)
                            st.success(f"âœ… å¤„ç†å®Œæˆ")
                        except Exception as e:
                            st.error(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
        
            with btn_cols[1]:
                if st.button("ğŸŒŸ æ¨èåº”ç”¨", type="primary", use_container_width=True, key="recommend_btn"):
                    if st.session_state.raw_data is None:
                        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                    else:
                        try:
                            wavenumbers, y = st.session_state.raw_data
                            recommended_params = {
                                'baseline_method': "äºŒé˜¶å·®åˆ†(D2)",  # æ¨èä½¿ç”¨äºŒé˜¶å·®åˆ†ä½œä¸ºåŸºçº¿æ ¡æ­£æ–¹æ³•
                                'baseline_params': {},
                                'scaling_method': "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)",  # æ¨èä½¿ç”¨æ–°æ·»åŠ çš„æ ‡å‡†åŒ–æ–¹æ³•
                                'scaling_params': {},
                                'filtering_method': "sgolayfiltæ»¤æ³¢å™¨",  # æ¨èä½¿ç”¨sgolayfiltæ»¤æ³¢å™¨
                                'filtering_params': {'point': 11, 'degree': 3},
                                'squashing_method': "æ”¹è¿›çš„SigmoidæŒ¤å‹",
                                'squashing_params': {}
                            }
                            
                            processed_data, method_name = preprocessor.process(
                                wavenumbers, y,** recommended_params
                            )
                            
                            arr_name = f"æ¨èæ’åˆ—_{len(st.session_state.arrangement_results) + 1}"
                            st.session_state.arrangement_results.append(arr_name)
                            st.session_state.arrangement_details[arr_name] = {
                                'data': processed_data,
                                'method': " â†’ ".join(method_name),
                                'params': recommended_params
                            }
                            st.session_state.selected_arrangement = arr_name
                            st.session_state.processed_data = (wavenumbers, processed_data)
                            st.session_state.process_method = " â†’ ".join(method_name)
                            st.success(f"âœ… æ¨èå¤„ç†å®Œæˆ")
                        except Exception as e:
                            st.error(f"âŒ æ¨èå¤±è´¥: {str(e)}")
        
            # æ˜¾ç¤ºæ’åˆ—æŒ‰é’®
            if st.button("ğŸ” æ˜¾ç¤ºæ’åˆ—", type="secondary", use_container_width=True, key="show_perm_btn"):
                st.session_state.show_arrangements = not st.session_state.show_arrangements
                
                if st.session_state.show_arrangements:
                    selected_algorithms = {
                        'baseline': baseline_method,
                        'scaling': scaling_method,
                        'filtering': filtering_method,
                        'squashing': squashing_method
                    }
                    st.session_state.algorithm_permutations = generate_permutations(selected_algorithms)
                    st.session_state.filtered_perms = st.session_state.algorithm_permutations
                    st.success(f"âœ… ç”Ÿæˆ{len(st.session_state.algorithm_permutations)}ç§æ–¹æ¡ˆ")
                else:
                    st.session_state.filtered_perms = []
                
                st.rerun()
            
            # æ’åˆ—æ–¹æ¡ˆé€‰æ‹©
            if st.session_state.show_arrangements and st.session_state.algorithm_permutations:
                st.subheader("ğŸ”„ æ’åˆ—æ–¹æ¡ˆ", divider="gray")
                
                # ç¬¬ä¸€æ­¥ç±»å‹ç­›é€‰
                try:
                    all_first_step_types = list({
                        perm.get("first_step_type", "æœªçŸ¥") 
                        for perm in st.session_state.algorithm_permutations
                    })
                    all_first_step_types.sort()
                except Exception as e:
                    st.error(f"âŒ ç­›é€‰é”™è¯¯: {str(e)}")
                    all_first_step_types = ["å…¨éƒ¨", "æ— é¢„å¤„ç†", "åŸºçº¿æ ¡å‡†", "ç¼©æ”¾", "æ»¤æ³¢", "æŒ¤å‹"]
                
                selected_first_step = st.selectbox(
                    "ç¬¬ä¸€æ­¥ç±»å‹",
                    ["å…¨éƒ¨"] + all_first_step_types,
                    key="first_step_filter",
                    label_visibility="collapsed"
                )
                
                # ç­›é€‰æ’åˆ—
                if selected_first_step == "å…¨éƒ¨":
                    st.session_state.filtered_perms = st.session_state.algorithm_permutations
                else:
                    st.session_state.filtered_perms = [
                        p for p in st.session_state.algorithm_permutations 
                        if p.get("first_step_type") == selected_first_step
                    ]
                
                # æ’åˆ—ä¸‹æ‹‰æ¡†
                if st.session_state.filtered_perms:
                    st.session_state.selected_perm_idx = st.selectbox(
                        f"é€‰æ‹©æ–¹æ¡ˆï¼ˆå…±{len(st.session_state.filtered_perms)}ç§ï¼‰",
                        range(len(st.session_state.filtered_perms)),
                        format_func=lambda x: st.session_state.filtered_perms[x].get("name", f"æ–¹æ¡ˆ{x+1}"),
                        key="perm_select",
                        label_visibility="collapsed",
                        help="é€‰æ‹©é¢„å¤„ç†ç®—æ³•é¡ºåº"
                    )
                    
                    # åº”ç”¨æ’åˆ—æŒ‰é’®
                    try:
                        selected_perm = st.session_state.filtered_perms[st.session_state.selected_perm_idx]
                        st.caption(f"å½“å‰: {selected_perm.get('name', 'æœªçŸ¥')}")
                        
                        if st.button("âœ… åº”ç”¨æ–¹æ¡ˆ", type="primary", use_container_width=True, key="apply_perm_btn"):
                            if st.session_state.raw_data is None:
                                st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                            else:
                                try:
                                    wavenumbers, y = st.session_state.raw_data
                                    algos = st.session_state.current_algorithms
                                    
                                    processed_data, method_name = preprocessor.process(
                                        wavenumbers, y, 
                                        baseline_method=algos['baseline'],
                                        baseline_params=algos['baseline_params'],
                                        squashing_method=algos['squashing'],
                                        squashing_params=algos['squashing_params'],
                                        filtering_method=algos['filtering'],
                                        filtering_params=algos['filtering_params'],
                                        scaling_method=algos['scaling'],
                                        scaling_params=algos['scaling_params'],
                                        algorithm_order=selected_perm.get('order', [])
                                    )
                                    
                                    arr_name = f"æ’åˆ—_{len(st.session_state.arrangement_results) + 1}"
                                    st.session_state.arrangement_results.append(arr_name)
                                    st.session_state.arrangement_details[arr_name] = {
                                        'data': processed_data,
                                        'method': " â†’ ".join(method_name),
                                        'order': selected_perm.get('order', []),
                                        'params': algos
                                    }
                                    st.session_state.selected_arrangement = arr_name
                                    st.session_state.processed_data = (wavenumbers, processed_data)
                                    st.session_state.process_method = " â†’ ".join(method_name)
                                    st.success(f"âœ… æ–¹æ¡ˆåº”ç”¨å®Œæˆ")
                                except Exception as e:
                                    st.error(f"âŒ åº”ç”¨å¤±è´¥: {str(e)}")
                    except Exception as e:
                        st.error(f"âŒ æ–¹æ¡ˆå¤„ç†é”™è¯¯: {str(e)}")
                else:
                    st.info("â„¹ï¸ æ— ç¬¦åˆæ¡ä»¶çš„æ–¹æ¡ˆ")
                
                # åˆ†ç±»æµ‹è¯•
                st.subheader("ğŸ“ åˆ†ç±»æµ‹è¯•", divider="gray")
                # kå€¼è¾“å…¥å’Œç¡®å®šæŒ‰é’®ï¼ˆä»…ä¸€å±‚åˆ—ï¼‰
                k_cols = st.columns([2, 1])
                with k_cols[0]:
                    k_value = st.number_input(
                        "kå€¼", 
                        min_value=1, 
                        value=st.session_state.k_value,
                        step=1,
                        key="k_input",
                        label_visibility="collapsed"
                    )
                with k_cols[1]:
                    if st.button("ç¡®å®š", type="secondary", use_container_width=True, key="k_confirm_btn"):
                        st.session_state.k_value = k_value
                        st.success(f"k={k_value}")
                
                # æµ‹è¯•æŒ‰é’®
                if st.button("æµ‹è¯•", type="primary", use_container_width=True, key="test_btn"):
                    if st.session_state.raw_data is None:
                        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                    elif st.session_state.selected_arrangement is None:
                        st.warning("âš ï¸ è¯·å…ˆåº”ç”¨æ’åˆ—æ–¹æ¡ˆ")
                    elif st.session_state.labels is None:
                        st.warning("âš ï¸ è¯·å…ˆè¾“å…¥æ ‡ç­¾")
                    elif st.session_state.train_indices is None:
                        st.warning("âš ï¸ æ— æ³•åˆ’åˆ†è®­ç»ƒé›†")
                    else:
                        try:
                            selected_arr = st.session_state.selected_arrangement
                            processed_data = st.session_state.arrangement_details[selected_arr]['data']
                            train_idx = st.session_state.train_indices
                            test_idx = st.session_state.test_indices
                            
                            train_data = processed_data[:, train_idx]
                            test_data = processed_data[:, test_idx]
                            train_labels = st.session_state.labels[train_idx]
                            test_labels = st.session_state.labels[test_idx]
                            
                            with st.spinner("æµ‹è¯•ä¸­..."):
                                predictions = knn_classify(
                                    train_data, 
                                    train_labels, 
                                    test_data, 
                                    k=st.session_state.k_value
                                )
                            
                            accuracy = accuracy_score(test_labels, predictions)
                            kappa = cohen_kappa_score(test_labels, predictions)
                            cm = confusion_matrix(test_labels, predictions)
                            
                            st.session_state.test_results = {
                                'accuracy': accuracy,
                                'kappa': kappa,
                                'confusion_matrix': cm,
                                'predictions': predictions,
                                'test_labels': test_labels
                            }
                            
                            st.success("âœ… æµ‹è¯•å®Œæˆï¼ç»“æœåœ¨ä¸­é—´é¢æ¿")
                            
                        except Exception as e:
                            st.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()
