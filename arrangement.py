import streamlit as st
import numpy as np
import pandas as pd
import re
import itertools
import matplotlib.pyplot as plt
import math
import os
from io import BytesIO
from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix
import seaborn as sns
from scipy import sparse
from scipy.sparse.linalg import spsolve
from scipy.signal import savgol_filter, medfilt
from scipy.fft import fft, ifft
from scipy.fftpack import fft as fftpack_fft, ifft as fftpack_ifft
import copy
from statsmodels.nonparametric.smoothers_lowess import lowess
import pywt
from sklearn.linear_model import LinearRegression
import scipy.signal as signal


# åŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢å‡½æ•°
def squashing(Data):
    row = Data.shape[0]
    col = Data.shape[1]
    sqData = np.zeros((row, col))
    for i in range(row):
        for j in range(col):
            sqData[i][j] = (1 - math.cos(Data[i][j] * math.pi)) / 2
    return sqData


# å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ªå‡½æ•°
def waveletlinear(arr, threshold=0.3):
    row = arr.shape[0]
    col = arr.shape[1]
    datarec = np.zeros((row, col))
    w = pywt.Wavelet('db8')
    for i in range(row):
        maxlev = pywt.dwt_max_level(col, w.dec_len)
        coeffs = pywt.wavedec(arr[i], 'db8', level=maxlev)
        for j in range(0, len(coeffs)):
            coeffs[j] = pywt.threshold(coeffs[j], threshold * max(coeffs[j]))
        datarec[i] = pywt.waverec(coeffs, 'db8')
    return datarec


# ç§»åŠ¨çª—å£ä¸­å€¼æ»¤æ³¢(MWM)å‡½æ•°
def MWM(arr, n=7, it=1):
    row = arr.shape[0]
    col = arr.shape[1]
    median = np.zeros((row, col))
    ns = []
    for _ in range(it):
        ns.append(n)
        n -= 2
    for i in range(row):
        median[i] = arr[i].copy()
        nn = ns.copy()
        for _ in range(it):
            n = nn.pop()
            if n > 1:
                tmp = signal.medfilt(median[i], n)
                median[i] = tmp
    return median


# Sigmoidå‡½æ•°
def sigmoid(X):
    row = X.shape[0]
    col = X.shape[1]
    s = np.zeros((row, col))
    for i in range(row):
        for j in range(col):
            m = 1 + np.exp(-float(X[i, j]))
            s[i, j] = (1.0 / m)
    return s


# æ”¹è¿›çš„i_sigmoidæŒ¤å‹å‡½æ•°
def i_sigmoid(X, maxn=10):
    row = X.shape[0]
    col = X.shape[1]
    s = np.zeros((row, col))
    for i in range(row):
        mi = np.min(X[i])
        diff = (np.max(X[i]) - mi) / maxn
        for j in range(col):
            t = (X[i, j] - mi) / diff - maxn / 2
            m = 1 + np.exp(-float(t))
            t = 1.0 / m
            s[i, j] = t * diff * maxn + mi
    return s


# æ”¹è¿›çš„i_squashingæŒ¤å‹å‡½æ•°
def i_squashing(Data):
    row = Data.shape[0]
    col = Data.shape[1]
    sqData = np.zeros((row, col))
    for i in range(row):
        mi = np.min(Data[i])
        diff = np.max(Data[i]) - mi
        for j in range(col):
            t = (Data[i, j] - mi) / diff if diff != 0 else 0
            m = (1 - math.cos(t * math.pi)) / 2
            sqData[i][j] = m * diff + mi
    return sqData


# äºŒé˜¶å·®åˆ†(D2)å‡½æ•°
def D2(sdata):
    row = sdata.shape[0]
    col = sdata.shape[1]
    D2_result = np.zeros((row, col))
    for i in range(row):
        tem = np.diff(sdata[i], 2)
        temp = tem.tolist()
        temp.append(temp[-1])
        temp.append(temp[-1])
        D2_result[i] = temp
    return D2_result


# LPèŒƒæ•°å½’ä¸€åŒ–å‡½æ•°
def LPnorm(arr, ord):
    row = arr.shape[0]
    col = arr.shape[1]
    Lpdata = np.zeros((row, col))
    for i in range(row):
        Lp = np.linalg.norm(arr[i, :], ord)
        if Lp != 0:
            Lpdata[i, :] = arr[i, :] / Lp
        else:
            Lpdata[i, :] = arr[i, :]
    return Lpdata


# MaMinormå½’ä¸€åŒ–å‡½æ•°
def MaMinorm(Oarr):
    row = Oarr.shape[0]
    col = Oarr.shape[1]
    MMarr = np.zeros((row, col))
    permax = np.ones((1, col))
    for i in range(row):
        diff = np.max(Oarr[i]) - np.min(Oarr[i])
        if diff != 0:
            MMarr[i] = ((Oarr[i] - permax * np.min(Oarr[i])) / diff) * 10 - 5
        else:
            MMarr[i] = Oarr[i] - permax * np.min(Oarr[i])
    return MMarr


# æ ‡å‡†åŒ–å‡½æ•°ï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰
def standardization(Datamat):
    mu = np.average(Datamat)
    sigma = np.std(Datamat)
    if sigma != 0:
        normDatamat = (Datamat - mu) / sigma
    else:
        normDatamat = Datamat - mu
    return normDatamat


# é€è¡Œæ ‡å‡†åŒ–å‡½æ•°
def plotst(Data):
    row = Data.shape[0]
    col = Data.shape[1]
    st_Data = np.zeros((row, col))
    for i in range(row):
        st_Data[i] = standardization(Data[i])
    return st_Data


# Smfftå‚…é‡Œå¶æ»¤æ³¢å‡½æ•°
def Smfft(arr, row_e=51):
    row = arr.shape[0]
    col = arr.shape[1]
    fftresult = np.zeros((row, col))
    for i in range(row):
        sfft = fftpack_fft(arr[i])
        row_s = len(arr[i])
        sfftn = copy.deepcopy(sfft)
        sfftn[row_e:row_s - row_e] = 0
        result = fftpack_ifft(sfftn)
        real_r = np.real(result)
        fftresult[i] = real_r
    return fftresult


# å¤šå…ƒæ•£å°„æ ¡æ­£(MSC)å‡½æ•°
def MSC(sdata):
    n = sdata.shape[0]
    k = np.zeros(sdata.shape[0])
    b = np.zeros(sdata.shape[0])
    M = np.mean(sdata, axis=0)

    for i in range(n):
        y = sdata[i, :].reshape(-1, 1)
        M_reshaped = M.reshape(-1, 1)
        model = LinearRegression()
        model.fit(M_reshaped, y)
        k[i] = model.coef_
        b[i] = model.intercept_

    spec_msc = np.zeros_like(sdata)
    for i in range(n):
        bb = np.repeat(b[i], sdata.shape[1])
        kk = np.repeat(k[i], sdata.shape[1])
        spec_msc[i, :] = (sdata[i, :] - bb) / kk

    return spec_msc


# å¡å°”æ›¼æ»¤æ³¢ç®—æ³•
def Kalman(z, R):
    n_iter = len(z)
    sz = (n_iter,)
    Q = 1e-5

    xhat = np.zeros(sz)
    P = np.zeros(sz)
    xhatminus = np.zeros(sz)
    Pminus = np.zeros(sz)
    K = np.zeros(sz)

    xhat[0] = 0.0
    P[0] = 1.0

    for k in range(1, n_iter):
        xhatminus[k] = xhat[k - 1]
        Pminus[k] = P[k - 1] + Q

        K[k] = Pminus[k] / (Pminus[k] + R)
        xhat[k] = xhatminus[k] + K[k] * (z[k] - xhatminus[k])
        P[k] = (1 - K[k]) * Pminus[k]

    return xhat


# å¤šç»´æ•°æ®å¡å°”æ›¼æ»¤æ³¢
def KalmanF(xd, R):
    row = xd.shape[0]
    col = xd.shape[1]
    Fxd = np.zeros((row, col))
    for i in range(row):
        Fxd[i] = Kalman(xd[i], R)
    return Fxd


# æ”¹è¿›çš„å¤šé¡¹å¼æ‹ŸåˆåŸºçº¿æ ¡æ­£(IModPoly)
def IModPoly(wavenumbers, originalRaman, polyorder, max_iter=100, tolerance=0.005):
    row, col = originalRaman.shape
    corrected = np.zeros((row, col))

    for j in range(row):
        prev_spectrum = originalRaman[j]
        curr_spectrum = prev_spectrum.copy()
        prev_std = 0
        converged = False
        iteration = 1

        while not converged and iteration <= max_iter:
            coeffs = np.polyfit(wavenumbers, curr_spectrum, polyorder)
            fitted = np.polyval(coeffs, wavenumbers)
            residual = curr_spectrum - fitted
            curr_std = np.std(residual)

            if iteration == 1:
                mask = prev_spectrum > (fitted + curr_std)
                curr_spectrum[mask] = fitted[mask] + curr_std
            else:
                mask = prev_spectrum < (fitted + curr_std)
                curr_spectrum = np.where(mask, prev_spectrum, fitted + curr_std)

            relative_change = abs((curr_std - prev_std) / curr_std) if curr_std != 0 else 0
            converged = relative_change < tolerance

            prev_spectrum = curr_spectrum
            prev_std = curr_std
            iteration += 1

        corrected[j] = originalRaman[j] - fitted

    return corrected


# ç§»åŠ¨çª—å£å¹³å‡ï¼ˆMWAï¼‰æ»¤æ³¢
def MWA(arr, n=6, it=1, mode="full"):
    row = arr.shape[0]
    col = arr.shape[1]
    average = np.zeros((row, col))
    ns = []
    for _ in range(it):
        ns.append(n)
        n -= 2
    for i in range(row):
        average[i] = arr[i].copy()
        nn = ns.copy()
        for _ in range(it):
            n = nn.pop()
            if n > 1:
                tmp = np.convolve(average[i], np.ones((n,)) / n, mode=mode)
                for j in range(1, n):
                    tmp[j - 1] = tmp[j - 1] * n / j
                    tmp[-j] = tmp[-j] * n / j
                j = int(n / 2)
                k = n - j - 1
                average[i] = tmp[j:-k]
    return average


# æ”¹è¿›çš„éå¯¹ç§°åŠ æƒæƒ©ç½šæœ€å°äºŒä¹˜åŸºçº¿æ ¡å‡†(AsLS)
def baseline_als(y, lam, p, niter=10, tol=1e-6):
    if np.any(np.isnan(y)):
        raise ValueError("è¾“å…¥æ•°æ®åŒ…å«NaNå€¼")

    y = np.asarray(y, dtype=np.float64)
    L = y.shape[1]
    D = sparse.csc_matrix(np.diff(np.eye(L), 2))
    result = np.zeros_like(y)

    for j in range(y.shape[0]):
        w = np.ones(L)
        y_curr = y[j].copy()

        for _ in range(niter):
            W = sparse.spdiags(w, 0, L, L)
            Z = W + lam * D.dot(D.transpose())
            z = spsolve(Z, w * y_curr)

            if np.max(np.abs(z - y_curr)) < tol:
                break

            w = p * (y[j] > z) + (1 - p) * (y[j] < z)
            y_curr = z

        result[j] = y[j] - z

    return result


# åŠ¨æ€æ—¶é—´è§„æ•´(DTW)ç®—æ³•
class DTW:
    def __init__(self, dist_method='euclidean'):
        self.dist_method = dist_method

    def distance(self, x, y):
        if self.dist_method == 'euclidean':
            return np.linalg.norm(x - y)
        elif self.dist_method == 'manhattan':
            return np.sum(np.abs(x - y))
        else:
            return np.linalg.norm(x - y)

    def __call__(self, reference, query):
        n = len(reference)
        m = len(query)
        dtw_matrix = np.zeros((n + 1, m + 1))
        dtw_matrix[:, :] = np.inf
        dtw_matrix[0, 0] = 0

        for i in range(1, n + 1):
            for j in range(1, m + 1):
                cost = self.distance(reference[i - 1], query[j - 1])
                dtw_matrix[i, j] = cost + min(
                    dtw_matrix[i - 1, j],
                    dtw_matrix[i, j - 1],
                    dtw_matrix[i - 1, j - 1]
                )

        i, j = n, m
        path = []
        while i > 0 or j > 0:
            path.append((i - 1, j - 1))
            if i == 0:
                j -= 1
            elif j == 0:
                i -= 1
            else:
                min_val = min(dtw_matrix[i - 1, j], dtw_matrix[i, j - 1], dtw_matrix[i - 1, j - 1])
                if min_val == dtw_matrix[i - 1, j - 1]:
                    i -= 1
                    j -= 1
                elif min_val == dtw_matrix[i - 1, j]:
                    i -= 1
                else:
                    j -= 1

        return path[::-1], dtw_matrix[n, m]


# ä¼ ç»Ÿé€»è¾‘å‡½æ•°ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
def squashing_legacy(x):
    return 1 / (1 + np.exp(-x))


# Savitzky-Golayæ»¤æ³¢å™¨å®ç°
def SGfilter(Intensity, point, degree):
    Row = Intensity.shape[0]
    col = Intensity.shape[1]
    sgsmooth = np.zeros((Row, col))
    for i in range(Row):
        sgsmooth[i] = savgol_filter(Intensity[i], point, degree)
    return sgsmooth


# å¤šé¡¹å¼æ‹ŸåˆåŸºçº¿æ ¡æ­£
def polynomial_fit(wavenumbers, spectra, polyorder):
    baseline = np.zeros_like(spectra)
    for i in range(spectra.shape[1]):
        coeffs = np.polyfit(wavenumbers, spectra[:, i], deg=polyorder)
        baseline[:, i] = np.polyval(coeffs, wavenumbers)
    return spectra - baseline


# ModPolyåŸºçº¿æ ¡æ­£
def modpoly(wavenumbers, spectra, k):
    baseline = np.zeros_like(spectra)
    n_points = len(wavenumbers)
    for i in range(spectra.shape[1]):
        y = spectra[:, i].copy()
        for _ in range(k):
            coeffs = np.polyfit(wavenumbers, y, deg=5)
            fitted = np.polyval(coeffs, wavenumbers)
            mask = y < fitted
            y[~mask] = fitted[~mask]
        baseline[:, i] = y
    return spectra - baseline


# PLSåŸºçº¿æ ¡æ­£
def pls(spectra, lam):
    n_points = spectra.shape[0]
    baseline = np.zeros_like(spectra)
    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(n_points, n_points - 2))
    D = lam * D.dot(D.transpose())
    for i in range(spectra.shape[1]):
        y = spectra[:, i]
        A = sparse.eye(n_points) + D
        baseline[:, i] = spsolve(A, y)
    return spectra - baseline


# airPLSåŸºçº¿æ ¡æ­£
def airpls(spectra, lam, max_iter=15, threshold=0.001):
    n_points = spectra.shape[0]
    baseline = np.zeros_like(spectra)
    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(n_points, n_points - 2))
    D = lam * D.dot(D.transpose())
    for i in range(spectra.shape[1]):
        y = spectra[:, i]
        w = np.ones(n_points)
        baseline_i = np.zeros(n_points)
        for j in range(max_iter):
            W = sparse.diags(w, 0)
            Z = W + D
            b = spsolve(Z, W * y)
            d = y - b
            neg_mask = d < 0
            w[neg_mask] = np.exp(j * np.abs(d[neg_mask]) / np.std(d[neg_mask]))
            w[~neg_mask] = 0
            if j > 0:
                diff = np.sum(np.abs(b - baseline_i)) / np.sum(np.abs(baseline_i)) if np.sum(np.abs(baseline_i)) > 0 else 0
                if diff < threshold:
                    break
            baseline_i = b
        baseline[:, i] = baseline_i
    return spectra - baseline


# DTWæŒ¤å‹ç®—æ³•
def dtw_squashing(x, l, k1, k2):
    n_samples, n_features = x.shape
    result = np.zeros_like(x)
    reference = np.mean(x, axis=1)
    dtw = DTW()

    for i in range(n_features):
        spectrum = x[:, i]
        path, cost = dtw(reference, spectrum)
        squashed = np.zeros_like(spectrum)
        for ref_idx, spec_idx in path:
            squashed[ref_idx] += spectrum[spec_idx]
        unique_ref_indices = np.unique([p[0] for p in path])
        for idx in unique_ref_indices:
            count = sum(1 for p in path if p[0] == idx)
            squashed[idx] /= count
        if k1 == "T":
            max_slope = l
            for j in range(1, len(path)):
                ref_diff = path[j][0] - path[j - 1][0]
                spec_diff = path[j][1] - path[j - 1][1]
                if ref_diff != 0:
                    slope = abs(spec_diff / ref_diff)
                    if slope > max_slope:
                        squashed[path[j][0]] = (squashed[path[j][0]] + squashed[path[j - 1][0]]) / 2
        if k2 == "T":
            ref_map_count = {}
            for ref_idx, _ in path:
                ref_map_count[ref_idx] = ref_map_count.get(ref_idx, 0) + 1
            for ref_idx, count in ref_map_count.items():
                if count > l:
                    window = min(l, len(spectrum))
                    start = max(0, ref_idx - window // 2)
                    end = min(n_samples, ref_idx + window // 2 + 1)
                    squashed[ref_idx] = np.mean(spectrum[start:end])
        if l > 1:
            for j in range(n_samples):
                start = max(0, j - l)
                end = min(n_samples, j + l + 1)
                squashed[j] = np.mean(squashed[start:end])
        result[:, i] = squashed
    return result


# ç”Ÿæˆç®—æ³•æ’åˆ—ç»„åˆ
def generate_permutations(algorithms):
    algorithm_list = [
        (1, "åŸºçº¿æ ¡å‡†", algorithms['baseline']),
        (2, "ç¼©æ”¾", algorithms['scaling']),
        (3, "æ»¤æ³¢", algorithms['filtering']),
        (4, "æŒ¤å‹", algorithms['squashing'])
    ]

    all_permutations = []
    all_permutations.append([])

    # 1ç§ç®—æ³•æ’åˆ—
    for algo in algorithm_list:
        if algo[2] != "æ— ":
            all_permutations.append([algo])

    # 2ç§ç®—æ³•æ’åˆ—
    for perm in itertools.permutations(algorithm_list, 2):
        if perm[0][2] != "æ— " and perm[1][2] != "æ— ":
            all_permutations.append(list(perm))

    # 3ç§ç®—æ³•æ’åˆ—
    for perm in itertools.permutations(algorithm_list, 3):
        if perm[0][2] != "æ— " and perm[1][2] != "æ— " and perm[2][2] != "æ— ":
            all_permutations.append(list(perm))

    # 4ç§ç®—æ³•æ’åˆ—
    for perm in itertools.permutations(algorithm_list, 4):
        if (perm[0][2] != "æ— " and perm[1][2] != "æ— " and
                perm[2][2] != "æ— " and perm[3][2] != "æ— "):
            all_permutations.append(list(perm))

    formatted_perms = []
    for i, perm in enumerate(all_permutations):
        perm_dict = {
            "name": "",
            "order": [],
            "details": perm,
            "count": len(perm),
            "first_step_type": "æœªçŸ¥"
        }

        if not perm:
            perm_dict["name"] = "æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"
            perm_dict["first_step_type"] = "æ— é¢„å¤„ç†"
        else:
            first_step_type = perm[0][1] if perm and len(perm) > 0 else "æœªçŸ¥"
            perm_dict["first_step_type"] = first_step_type

            perm_details = []
            for step in perm:
                perm_details.append(f"{step[0]}.{step[1]}({step[2]})")
            perm_dict["name"] = " â†’ ".join(perm_details)
            perm_dict["order"] = [step[0] for step in perm]

        formatted_perms.append(perm_dict)

    return formatted_perms


# Kè¿‘é‚»åˆ†ç±»ç®—æ³•
def knn_classify(train_data, train_labels, test_data, k=5):
    train_data = train_data.T
    test_data = test_data.T

    predictions = []
    for test_sample in test_data:
        distances = np.sqrt(np.sum((train_data - test_sample) **2, axis=1))
        k_indices = np.argsort(distances)[:k]
        k_nearest_labels = [train_labels[i] for i in k_indices]
        most_common = np.bincount(k_nearest_labels).argmax()
        predictions.append(most_common)
    return np.array(predictions)


# é¢„å¤„ç†ç±»
class Preprocessor:
    def __init__(self):
        self.BASELINE_ALGORITHMS = {
            "SD": self._sd_baseline,
            "FD": self._fd_baseline,
            "å¤šé¡¹å¼æ‹Ÿåˆ": polynomial_fit,
            "ModPoly": modpoly,
            "I-ModPoly": IModPoly,
            "PLS": pls,
            "AsLS": baseline_als,
            "airPLS": airpls,
            "äºŒé˜¶å·®åˆ†(D2)": self.d2
        }
        self.FILTERING_ALGORITHMS = {
            "Savitzky-Golay": self.savitzky_golay,
            "sgolayfiltæ»¤æ³¢å™¨": self.sgolay_filter_custom,
            "ä¸­å€¼æ»¤æ³¢(MF)": self.median_filter,
            "ç§»åŠ¨å¹³å‡(MAF)": self.moving_average,
            "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰": self.mwa_filter,
            "MWMï¼ˆç§»åŠ¨çª—å£ä¸­å€¼ï¼‰": self.mwm_filter,
            "å¡å°”æ›¼æ»¤æ³¢": self.kalman_filter,
            "Lowess": self.lowess_filter,
            "FFT": self.fft_filter,
            "Smfftå‚…é‡Œå¶æ»¤æ³¢": self.smfft_filter,
            "å°æ³¢å˜æ¢(DWT)": self.wavelet_filter,
            "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª": self.wavelet_linear
        }

        self.SCALING_ALGORITHMS = {
            "Peak-Norm": self.peak_norm,
            "SNV": self.snv,
            "MSC": self.msc,
            "M-M-Norm": self.mm_norm,
            "L-èŒƒæ•°": self.l_norm,
            "Ma-Minorm": self.ma_minorm,
            "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)": self.standardize
        }

        self.SQUASHING_ALGORITHMS = {
            "SigmoidæŒ¤å‹": sigmoid,
            "æ”¹è¿›çš„SigmoidæŒ¤å‹": i_sigmoid,
            "é€»è¾‘å‡½æ•°": squashing_legacy,
            "ä½™å¼¦æŒ¤å‹(squashing)": squashing,
            "æ”¹è¿›çš„é€»è¾‘å‡½æ•°": i_squashing,
            "DTWæŒ¤å‹": dtw_squashing
        }

    def process(self, wavenumbers, data,
                baseline_method="æ— ", baseline_params=None,
                squashing_method="æ— ", squashing_params=None,
                filtering_method="æ— ", filtering_params=None,
                scaling_method="æ— ", scaling_params=None,
                algorithm_order=None):
        if baseline_params is None:
            baseline_params = {}
        if squashing_params is None:
            squashing_params = {}
        if filtering_params is None:
            filtering_params = {}
        if scaling_params is None:
            scaling_params = {}

        if algorithm_order is not None and len(algorithm_order) == 0:
            return data.copy(), ["æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"]

        y_processed = data.copy()
        method_name = []

        if algorithm_order is not None and len(algorithm_order) > 0:
            step_mapping = {
                1: ("baseline", baseline_method, baseline_params),
                2: ("scaling", scaling_method, scaling_params),
                3: ("filtering", filtering_method, filtering_params),
                4: ("squashing", squashing_method, squashing_params)
            }
            steps = [step_mapping[order] for order in algorithm_order]
        else:
            steps = []
            if baseline_method != "æ— ":
                steps.append(("baseline", baseline_method, baseline_params))
            if squashing_method != "æ— ":
                steps.append(("squashing", squashing_method, squashing_params))
            if filtering_method != "æ— ":
                steps.append(("filtering", filtering_method, filtering_params))
            if scaling_method != "æ— ":
                steps.append(("scaling", scaling_method, scaling_params))

        for step_type, method, params in steps:
            if method == "æ— ":
                continue

            try:
                if step_type == "baseline":
                    algorithm_func = self.BASELINE_ALGORITHMS[method]
                    if method in ["å¤šé¡¹å¼æ‹Ÿåˆ", "ModPoly", "I-ModPoly"]:
                        y_processed = algorithm_func(wavenumbers, y_processed,** params)
                    elif method in ["PLS"]:
                        y_processed = algorithm_func(y_processed, **params)
                    elif method == "AsLS":
                        y_processed = algorithm_func(y_processed,** params)
                    elif method == "airPLS":
                        y_processed = algorithm_func(y_processed, **params)
                    elif method == "äºŒé˜¶å·®åˆ†(D2)":
                        y_processed = algorithm_func(y_processed)
                    else:
                        y_processed = algorithm_func(y_processed)
                    method_name.append(f"{method}({', '.join([f'{k}={v}' for k, v in params.items()])})")

                elif step_type == "squashing":
                    algorithm_func = self.SQUASHING_ALGORITHMS[method]
                    if method == "æ”¹è¿›çš„SigmoidæŒ¤å‹":
                        maxn = params.get("maxn", 10)
                        y_processed = algorithm_func(y_processed, maxn=maxn)
                        method_name.append(f"{method}(maxn={maxn})")
                    elif method == "æ”¹è¿›çš„é€»è¾‘å‡½æ•°":
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    elif method == "DTWæŒ¤å‹":
                        l = params.get("l", 1)
                        k1 = params.get("k1", "T")
                        k2 = params.get("k2", "T")
                        y_processed = algorithm_func(y_processed, l=l, k1=k1, k2=k2)
                        method_name.append(f"DTWæŒ¤å‹(l={l}, k1={k1}, k2={k2})")
                    elif method == "SigmoidæŒ¤å‹":
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    elif method == "ä½™å¼¦æŒ¤å‹(squashing)":
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    else:
                        y_processed = algorithm_func(y_processed)
                        method_name.append(method)

                elif step_type == "filtering":
                    algorithm_func = self.FILTERING_ALGORITHMS[method]
                    y_processed = algorithm_func(y_processed,** params)
                    params_str = ', '.join([f'{k}={v}' for k, v in params.items()])
                    method_name.append(f"{method}({params_str})")

                    if method == "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª":
                        threshold = params.get("threshold", 0.3)
                        method_name[-1] = f"{method}(threshold={threshold})"

                elif step_type == "scaling":
                    algorithm_func = self.SCALING_ALGORITHMS[method]
                    y_processed = algorithm_func(y_processed, **params)
                    params_str = ', '.join([f'{k}={v}' for k, v in params.items()])
                    method_name.append(f"{method}({params_str})")

            except Exception as e:
                raise ValueError(f"{step_type}å¤„ç†å¤±è´¥: {str(e)}")

        return y_processed, method_name

    def _sd_baseline(self, spectra):
        return spectra - np.min(spectra, axis=0)

    def _fd_baseline(self, spectra):
        return spectra - np.percentile(spectra, 5, axis=0)

    # æ»¤æ³¢ç®—æ³•å®ç°
    def savitzky_golay(self, spectra, k, w):
        return savgol_filter(spectra, w, k, axis=0)

    def sgolay_filter_custom(self, spectra, point, degree):
        if spectra.shape[0] < spectra.shape[1]:
            filtered = SGfilter(spectra.T, point, degree)
            return filtered.T
        else:
            return SGfilter(spectra, point, degree)

    def median_filter(self, spectra, k, w):
        return medfilt(spectra, kernel_size=(w, 1))

    def moving_average(self, spectra, k, w):
        kernel = np.ones(w) / w
        return np.apply_along_axis(lambda x: np.convolve(x, kernel, mode='same'), 0, spectra)

    def mwa_filter(self, spectra, n=6, it=1, mode="full"):
        return MWA(spectra, n=n, it=it, mode=mode)

    def mwm_filter(self, spectra, n=7, it=1):
        if spectra.shape[0] < spectra.shape[1]:
            filtered = MWM(spectra.T, n=n, it=it)
            return filtered.T
        else:
            return MWM(spectra, n=n, it=it)

    def kalman_filter(self, spectra, R=0.1):
        return KalmanF(spectra, R)

    def lowess_filter(self, spectra, frac):
        result = np.zeros_like(spectra)
        for i in range(spectra.shape[1]):
            smoothed = lowess(spectra[:, i], np.arange(len(spectra)), frac=frac, it=0)
            result[:, i] = smoothed[:, 1]
        return result

    def fft_filter(self, spectra, cutoff):
        fft_result = fft(spectra, axis=0)
        frequencies = np.fft.fftfreq(spectra.shape[0])
        filter_mask = np.abs(frequencies) < cutoff
        fft_result[~filter_mask, :] = 0
        return np.real(ifft(fft_result, axis=0))

    def smfft_filter(self, spectra, row_e=51):
        if spectra.shape[0] < spectra.shape[1]:
            filtered = Smfft(spectra.T, row_e=row_e)
            return filtered.T
        else:
            return Smfft(spectra, row_e=row_e)

    def wavelet_filter(self, spectra, threshold):
        coeffs = pywt.wavedec(spectra, 'db4', axis=0)
        coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]
        return pywt.waverec(coeffs, 'db4', axis=0)

    def wavelet_linear(self, spectra, threshold=0.3):
        if spectra.shape[0] < spectra.shape[1]:
            filtered = waveletlinear(spectra.T, threshold=threshold)
            return filtered.T
        else:
            return waveletlinear(spectra, threshold=threshold)

    # ç¼©æ”¾ç®—æ³•å®ç°
    def peak_norm(self, spectra):
        return spectra / np.max(spectra, axis=0)

    def snv(self, spectra):
        mean = np.mean(spectra, axis=0)
        std = np.std(spectra, axis=0)
        return (spectra - mean) / std

    def msc(self, spectra):
        if spectra.shape[0] < spectra.shape[1]:
            corrected = MSC(spectra.T)
            return corrected.T
        else:
            return MSC(spectra)

    def mm_norm(self, spectra):
        min_vals = np.min(spectra, axis=0)
        max_vals = np.max(spectra, axis=0)
        return (spectra - min_vals) / (max_vals - min_vals)

    def l_norm(self, spectra, p):
        if p == "æ— ç©·å¤§":
            return LPnorm(spectra, np.inf)
        else:
            p_val = float(p)
            return LPnorm(spectra, p_val)

    def ma_minorm(self, spectra):
        return MaMinorm(spectra)

    def standardize(self, spectra):
        if spectra.shape[0] < spectra.shape[1]:
            standardized = plotst(spectra.T)
            return standardized.T
        else:
            return plotst(spectra)

    # äºŒé˜¶å·®åˆ†æ–¹æ³•å°è£…
    def d2(self, spectra):
        if spectra.shape[0] < spectra.shape[1]:
            diff_result = D2(spectra.T)
            return diff_result.T
        else:
            return D2(spectra)


# æ–‡ä»¶å¤„ç†ç±»ï¼ˆæ”¯æŒæ–‡ä»¶å¤¹ä¸Šä¼ ï¼‰
class FileHandler:
    def load_data_from_folder(self, uploaded_files, wavenumber_filename="wavenumbers.txt"):
        """ä»ä¸Šä¼ çš„æ–‡ä»¶å¤¹ä¸­åŠ è½½æ•°æ®ï¼Œå‡è®¾æ–‡ä»¶å¤¹åŒ…å«æ³¢æ•°æ–‡ä»¶å’Œå¤šä¸ªå…‰è°±æ–‡ä»¶"""
        try:
            # åˆ†ç¦»æ³¢æ•°æ–‡ä»¶å’Œå…‰è°±æ–‡ä»¶
            wavenumber_file = None
            spectrum_files = []
            
            for file in uploaded_files:
                if file.name == wavenumber_filename:
                    wavenumber_file = file
                elif file.name.lower().endswith('.txt'):
                    spectrum_files.append(file)
            
            if not wavenumber_file:
                raise ValueError(f"æœªæ‰¾åˆ°æ³¢æ•°æ–‡ä»¶: {wavenumber_filename}")
                
            if not spectrum_files:
                raise ValueError("æœªæ‰¾åˆ°å…‰è°±æ•°æ®æ–‡ä»¶")
            
            # è¯»å–æ³¢æ•°æ–‡ä»¶
            wavenumber_content = wavenumber_file.getvalue().decode("utf-8", errors="ignore")
            wavenumbers = np.array([float(num) for num in re.findall(r"-?\d+(?:\.\d+)?", wavenumber_content)]).ravel()
            
            # è¯»å–æ‰€æœ‰å…‰è°±æ–‡ä»¶
            spectra = []
            for file in spectrum_files:
                content = file.getvalue().decode("utf-8", errors="ignore")
                numbers = list(map(float, re.findall(r"-?\d+(?:\.\d+)?", content)))
                spectra.append(numbers)
            
            # ç¡®ä¿æ‰€æœ‰å…‰è°±é•¿åº¦ä¸€è‡´
            min_length = min(len(s) for s in spectra)
            wavenumbers = wavenumbers[:min_length]
            
            # è°ƒæ•´æ‰€æœ‰å…‰è°±é•¿åº¦
            adjusted_spectra = []
            for s in spectra:
                if len(s) > min_length:
                    adjusted_spectra.append(s[:min_length])
                else:
                    # å¦‚æœå…‰è°±å¤ªçŸ­ï¼Œç”¨0å¡«å……
                    padded = np.pad(s, (0, min_length - len(s)), mode='constant')
                    adjusted_spectra.append(padded.tolist())
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶è½¬ç½®ä¸º (æ•°æ®ç‚¹, å…‰è°±æ•°) æ ¼å¼
            data = np.array(adjusted_spectra).T
            return wavenumbers, data, len(spectrum_files)
            
        except Exception as e:
            raise ValueError(f"æ–‡ä»¶å¤¹è§£æé”™è¯¯: {str(e)}")

    def export_data(self, filename, data):
        """å¯¼å‡ºé¢„å¤„ç†åçš„æ•°æ®"""
        with open(filename, "w", encoding="utf-8") as f:
            for line in data.T:
                f.write("\t".join(map(str, line)) + "\n")


# ä¸»å‡½æ•°
def main():
    # åˆå§‹åŒ–Session State
    if 'show_arrangements' not in st.session_state:
        st.session_state.show_arrangements = False

    test_states = {
        'k_value': 5,
        'test_results': None,
        'labels': None,
        'train_indices': None,
        'test_indices': None,
        'uploaded_folder_files': None
    }

    other_states = {
        'raw_data': None,
        'processed_data': None,
        'peaks': None,
        'train_test_split_ratio': 0.8,
        'arrangement_results': [],
        'selected_arrangement': None,
        'arrangement_details': {},
        'algorithm_permutations': [],
        'current_algorithms': {},
        'filtered_perms': [],
        'selected_perm_idx': 0
    }

    all_states = {** test_states, **other_states}
    for key, value in all_states.items():
        if key not in st.session_state:
            st.session_state[key] = value

    # é¡µé¢é…ç½®
    st.set_page_config(layout="wide", page_icon="ğŸ”¬", page_title="æ’åˆ—é¢„å¤„ç†æ¨¡å‹")
    st.markdown("""
        <style>
        body {font-size: 0.85rem !important;}
        .css-1v0mbdj {padding: 0.5rem 1rem !important;}
        .css-1d391kg {padding: 0.3rem 0 !important;}
        .css-1x8cf1d {line-height: 1.2 !important;}
        .css-12ttj6m {margin-bottom: 0.5rem !important;}
        .css-1n543e5 {height: 220px !important;}
        .css-1b3298e {gap: 0.5rem !important;}
        .css-16huue1 {padding: 0.3rem 0.8rem !important;}
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸŒŒ æ’åˆ—é¢„å¤„ç†æ¨¡å‹")

    # åˆ›å»ºå¤„ç†å™¨å®ä¾‹
    file_handler = FileHandler()
    preprocessor = Preprocessor()

    # ä¸‰åˆ—å¸ƒå±€
    col_left, col_mid, col_right = st.columns([1.2, 2.8, 1.1])

    # å·¦ä¾§ï¼šæ•°æ®ç®¡ç†ï¼ˆæ–‡ä»¶å¤¹ä¸Šä¼ ï¼‰
    with col_left:
        with st.expander("ğŸ“ æ•°æ®ç®¡ç†", expanded=True):
            # æ–‡ä»¶å¤¹ä¸Šä¼ ç»„ä»¶
            st.subheader("å…‰è°±æ•°æ®æ–‡ä»¶å¤¹", divider="gray")
            uploaded_files = st.file_uploader(
                "ä¸Šä¼ åŒ…å«å…‰è°±æ•°æ®çš„æ–‡ä»¶å¤¹ï¼ˆè¯·å…ˆå‹ç¼©ä¸ºZIPï¼‰",
                type="zip",
                accept_multiple_files=False,
                key="folder_upload",
                help="åŒ…å«æ³¢æ•°æ–‡ä»¶(wavenumbers.txt)å’Œå¤šä¸ªå…‰è°±æ•°æ®æ–‡ä»¶çš„ZIPå‹ç¼©åŒ…"
            )

            # æ³¢æ•°æ–‡ä»¶åè®¾ç½®
            wavenumber_filename = st.text_input(
                "æ³¢æ•°æ–‡ä»¶å",
                "wavenumbers.txt",
                key="wavenumber_filename",
                help="æ–‡ä»¶å¤¹ä¸­åŒ…å«æ³¢æ•°æ•°æ®çš„æ–‡ä»¶å"
            )

            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶å¼•ç”¨
            if uploaded_files is not None:
                st.session_state.uploaded_folder_files = uploaded_files
                st.success(f"âœ… å·²ä¸Šä¼ æ–‡ä»¶å¤¹: {uploaded_files.name}")

            # æ ·æœ¬æ ‡ç­¾è¾“å…¥
            st.subheader("æ ·æœ¬æ ‡ç­¾", divider="gray")
            num_classes = st.number_input("ç±»åˆ«æ•°é‡", min_value=1, value=2, step=1, key="num_cls")
            labels_input = st.text_input(
                "æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼Œä¸å…‰è°±æ–‡ä»¶é¡ºåºä¸€è‡´ï¼‰",
                placeholder="ä¾‹ï¼š0,0,1,1",
                key="labels_in"
            )

            # è®­ç»ƒæµ‹è¯•æ¯”ä¾‹
            train_test_ratio = st.slider(
                "è®­ç»ƒé›†æ¯”ä¾‹",
                min_value=0.1,
                max_value=0.9,
                value=0.8,
                step=0.1,
                format="%.1f",
                key="train_ratio"
            )
            st.session_state.train_test_split_ratio = train_test_ratio

            # åŠ è½½æ•°æ®æŒ‰é’®
            if st.button("ğŸ“¥ åŠ è½½æ•°æ®", type="primary", key="load_data_btn"):
                if st.session_state.uploaded_folder_files is None:
                    st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ åŒ…å«å…‰è°±æ•°æ®çš„ZIPæ–‡ä»¶å¤¹")
                    return

                try:
                    # è§£å‹å¹¶åŠ è½½æ•°æ®
                    import zipfile
                    
                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤¹
                    import tempfile
                    with tempfile.TemporaryDirectory() as temp_dir:
                        # è§£å‹ZIPæ–‡ä»¶
                        with zipfile.ZipFile(st.session_state.uploaded_folder_files, 'r') as zip_ref:
                            zip_ref.extractall(temp_dir)
                            
                        # è·å–æ‰€æœ‰æ–‡ä»¶
                        extracted_files = []
                        for root, dirs, files in os.walk(temp_dir):
                            for file in files:
                                file_path = os.path.join(root, file)
                                # è¯»å–æ–‡ä»¶å†…å®¹
                                with open(file_path, 'rb') as f:
                                    file_content = BytesIO(f.read())
                                    file_content.name = file
                                    extracted_files.append(file_content)
                        
                        # åŠ è½½æ•°æ®
                        wavenumbers, y, num_spectra = file_handler.load_data_from_folder(
                            extracted_files,
                            wavenumber_filename=wavenumber_filename
                        )
                        
                        st.session_state.raw_data = (wavenumbers, y)

                        # æ ‡ç­¾å¤„ç†
                        if labels_input:
                            try:
                                labels = np.array([int(l.strip()) for l in labels_input.split(',')])
                                n_spectra = y.shape[1]
                                if len(labels) == n_spectra:
                                    st.session_state.labels = labels
                                    n_samples = len(labels)
                                    train_size = int(n_samples * train_test_ratio)
                                    indices = np.random.permutation(n_samples)
                                    st.session_state.train_indices = indices[:train_size]
                                    st.session_state.test_indices = indices[train_size:]
                                    st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{n_spectra}æ¡å…‰è°±ï¼Œ{len(np.unique(labels))}ç±»")
                                else:
                                    st.warning(f"âš ï¸ æ ‡ç­¾æ•°({len(labels)})â‰ å…‰è°±æ•°({n_spectra})")
                                    st.session_state.labels = None
                            except Exception as e:
                                st.warning(f"âš ï¸ æ ‡ç­¾æ ¼å¼é”™è¯¯: {str(e)}")
                                st.session_state.labels = None
                        else:
                            n_spectra = y.shape[1]
                            st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{n_spectra}æ¡å…‰è°±ï¼Œ{len(wavenumbers)}ä¸ªæ•°æ®ç‚¹")
                            st.warning("âš ï¸ è¯·è¾“å…¥æ ·æœ¬æ ‡ç­¾ä»¥è¿›è¡Œåˆ†ç±»æµ‹è¯•")
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")

        # ç³»ç»Ÿä¿¡æ¯æ˜¾ç¤º
        if st.session_state.get('raw_data'):
            wavenumbers, y = st.session_state.raw_data
            n_spectra = y.shape[1]
            n_points = y.shape[0]
            st.info(f"ğŸ“Š æ•°æ®ç»´åº¦: {n_spectra}æ¡å…‰è°± Ã— {n_points}ä¸ªæ•°æ®ç‚¹")
            st.info(f"ğŸ”¢ è®­ç»ƒé›†:{train_test_ratio:.1f} | æµ‹è¯•é›†:{1-train_test_ratio:.1f}")
            if st.session_state.get('labels') is not None:
                class_counts = np.bincount(st.session_state.labels)
                st.info(f"ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ: {', '.join([f'ç±»{i}:{count}ä¸ª' for i, count in enumerate(class_counts) if count>0])}")
            if st.session_state.get('process_method'):
                st.success(f"ğŸ› ï¸ å¤„ç†æµç¨‹: {st.session_state.process_method}")

        # ä½¿ç”¨æŒ‡å—
        with st.expander("â„¹ï¸ ä½¿ç”¨æŒ‡å—", expanded=False):
            st.markdown("""
            1. å°†å…‰è°±æ•°æ®æ–‡ä»¶å¤¹å‹ç¼©ä¸ºZIPæ ¼å¼ï¼Œéœ€åŒ…å«ï¼š
               - æ³¢æ•°æ–‡ä»¶ï¼ˆé»˜è®¤åä¸ºwavenumbers.txtï¼‰
               - å¤šä¸ªå…‰è°±æ•°æ®æ–‡ä»¶ï¼ˆTXTæ ¼å¼ï¼‰
            2. ä¸Šä¼ ZIPæ–‡ä»¶å¹¶ç‚¹å‡»"åŠ è½½æ•°æ®"æŒ‰é’®
            3. è®¾ç½®æ ·æœ¬æ ‡ç­¾ï¼ˆä¸å…‰è°±æ–‡ä»¶é¡ºåºä¸€è‡´ï¼‰
            4. å³ä¾§é€‰æ‹©é¢„å¤„ç†æ–¹æ³•å¹¶åº”ç”¨æ’åˆ—æ–¹æ¡ˆ
            5. é€‰æ‹©kå€¼åç‚¹å‡»"æµ‹è¯•"
            6. ä¸­é—´æŸ¥çœ‹ç»“æœå¹¶å¯¼å‡º
            """)

    # ä¸­é—´ï¼šå…‰è°±å¯è§†åŒ–ä¸ç»“æœå¯¼å‡º
    with col_mid:
        st.subheader("ğŸ“ˆ å…‰è°±å¯è§†åŒ–", divider="gray")

        # åŸå§‹å…‰è°±æ˜¾ç¤º
        st.subheader("åŸå§‹å…‰è°±", divider="gray")
        spec_cols = st.columns(2)
        with spec_cols[0]:
            if st.session_state.get('raw_data'):
                wavenumbers, y = st.session_state.raw_data
                idx1 = 0 if y.shape[1] > 0 else 0
                raw_data1 = pd.DataFrame({"åŸå§‹å…‰è°±1": y[:, idx1]}, index=wavenumbers)
                st.line_chart(raw_data1, height=200)
            else:
                st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ç­‰å¾…åŠ è½½åŸå§‹æ•°æ®</div>', unsafe_allow_html=True)

        with spec_cols[1]:
            if st.session_state.get('raw_data') and y.shape[1] > 1:
                idx2 = 1
                raw_data2 = pd.DataFrame({"åŸå§‹å…‰è°±2": y[:, idx2]}, index=wavenumbers)
                st.line_chart(raw_data2, height=200)
            elif st.session_state.get('raw_data'):
                st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ä»…1æ¡åŸå§‹å…‰è°±</div>', unsafe_allow_html=True)
            else:
                st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ç­‰å¾…åŠ è½½åŸå§‹æ•°æ®</div>', unsafe_allow_html=True)

        # æ›´å¤šåŸå§‹å…‰è°±
        if st.session_state.get('raw_data') and y.shape[1] > 2:
            with st.expander("æŸ¥çœ‹æ›´å¤šåŸå§‹å…‰è°±", expanded=False):
                more_spec = st.columns(2)
                for i in range(2, min(y.shape[1], 6), 2):
                    with more_spec[0]:
                        if i < y.shape[1]:
                            data = pd.DataFrame({f"åŸå§‹å…‰è°±{i+1}": y[:, i]}, index=wavenumbers)
                            st.line_chart(data, height=150)
                    with more_spec[1]:
                        if i+1 < y.shape[1]:
                            data = pd.DataFrame({f"åŸå§‹å…‰è°±{i+2}": y[:, i+1]}, index=wavenumbers)
                            st.line_chart(data, height=150)

        # é¢„å¤„ç†ç»“æœå±•ç¤º
        if st.session_state.get('selected_arrangement'):
            st.subheader("ğŸ” é¢„å¤„ç†ç»“æœ", divider="gray")
            selected_arr = st.session_state.selected_arrangement
            arr_data = st.session_state.arrangement_details[selected_arr]['data']
            arr_method = st.session_state.arrangement_details[selected_arr]['method']
            arr_order = st.session_state.arrangement_details[selected_arr].get('order', [])

            st.caption(f"å¤„ç†æ–¹æ³•: {arr_method} | æ‰§è¡Œé¡ºåº: {arr_order if arr_order else 'æ— é¢„å¤„ç†'}")

            # é¢„å¤„ç†åå…‰è°±
            st.subheader("é¢„å¤„ç†åå…‰è°±", divider="gray")
            proc_cols = st.columns(2)
            with proc_cols[0]:
                idx1 = 0 if arr_data.shape[1] > 0 else 0
                proc_data1 = pd.DataFrame({"é¢„å¤„ç†å1": arr_data[:, idx1]}, index=wavenumbers)
                st.line_chart(proc_data1, height=200)
            with proc_cols[1]:
                if arr_data.shape[1] > 1:
                    idx2 = 1
                    proc_data2 = pd.DataFrame({"é¢„å¤„ç†å2": arr_data[:, idx2]}, index=wavenumbers)
                    st.line_chart(proc_data2, height=200)
                else:
                    st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ä»…1æ¡é¢„å¤„ç†å…‰è°±</div>', unsafe_allow_html=True)

            # kå€¼æ›²çº¿
            if arr_order:
                st.subheader("kå€¼æ›²çº¿", divider="gray")
                k_cols = st.columns(2)
                with k_cols[0]:
                    k_vals1 = np.abs(arr_data[:, 0] / (y[:, 0] + 1e-8)) if y.shape[1] > 0 else np.array([])
                    k_data1 = pd.DataFrame({"kå€¼1": k_vals1}, index=wavenumbers)
                    st.line_chart(k_data1, height=200)
                with k_cols[1]:
                    if y.shape[1] > 1:
                        k_vals2 = np.abs(arr_data[:, 1] / (y[:, 1] + 1e-8))
                        k_data2 = pd.DataFrame({"kå€¼2": k_vals2}, index=wavenumbers)
                        st.line_chart(k_data2, height=200)
                    else:
                        st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ä»…1æ¡kå€¼æ›²çº¿</div>', unsafe_allow_html=True)
            else:
                st.info("â„¹ï¸ æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰ï¼Œä¸æ˜¾ç¤ºkå€¼æ›²çº¿")

            # åŸå§‹ä¸é¢„å¤„ç†å¯¹æ¯”
            st.subheader("åŸå§‹vsé¢„å¤„ç†å¯¹æ¯”", divider="gray")
            comp_cols = st.columns(2)
            with comp_cols[0]:
                if y.shape[1] > 0:
                    comp_data1 = pd.DataFrame({
                        "åŸå§‹": y[:, 0],
                        "é¢„å¤„ç†å": arr_data[:, 0]
                    }, index=wavenumbers)
                    st.line_chart(comp_data1, height=200)
            with comp_cols[1]:
                if y.shape[1] > 1:
                    comp_data2 = pd.DataFrame({
                        "åŸå§‹": y[:, 1],
                        "é¢„å¤„ç†å": arr_data[:, 1]
                    }, index=wavenumbers)
                    st.line_chart(comp_data2, height=200)
                else:
                    st.markdown('<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">ä»…1æ¡å¯¹æ¯”æ›²çº¿</div>', unsafe_allow_html=True)

            # æµ‹è¯•ç»“æœ
            if st.session_state.get('test_results') is not None:
                st.subheader("ğŸ“Š åˆ†ç±»æµ‹è¯•ç»“æœ", divider="gray")
                results = st.session_state.test_results

                # æŒ‡æ ‡æ˜¾ç¤º
                metrics_cols = st.columns(2)
                with metrics_cols[0]:
                    st.metric("å‡†ç¡®ç‡", f"{results['accuracy']:.4f}", delta=None)
                with metrics_cols[1]:
                    st.metric("å¡å¸•ç³»æ•°", f"{results['kappa']:.4f}", delta=None)

                # æ··æ·†çŸ©é˜µ
                st.subheader("æ··æ·†çŸ©é˜µ", divider="gray")
                fig, ax = plt.subplots(figsize=(5, 4))
                sns.heatmap(results['confusion_matrix'], annot=True, fmt='d', cmap='Blues', ax=ax, annot_kws={"size": 8})
                ax.set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=8)
                ax.set_ylabel('çœŸå®æ ‡ç­¾', fontsize=8)
                ax.set_title('æ··æ·†çŸ©é˜µ', fontsize=10)
                plt.xticks(fontsize=7)
                plt.yticks(fontsize=7)
                st.pyplot(fig, use_container_width=True)
        else:
            st.info("â„¹ï¸ è¯·åœ¨å³ä¾§é€‰æ‹©é¢„å¤„ç†æ–¹æ³•å¹¶åº”ç”¨æ’åˆ—æ–¹æ¡ˆ")

        # ç»“æœå¯¼å‡º
        if st.session_state.arrangement_results or st.session_state.get('processed_data'):
            st.subheader("ğŸ’¾ ç»“æœå¯¼å‡º", divider="gray")
            export_cols = st.columns([3, 1])
            with export_cols[0]:
                export_name = st.text_input("å¯¼å‡ºæ–‡ä»¶å", "processed_spectra.txt", key="export_name")
            with export_cols[1]:
                st.markdown("<br>", unsafe_allow_html=True)
                if st.button("å¯¼å‡º", type="secondary", key="export_btn"):
                    try:
                        if st.session_state.selected_arrangement:
                            arr_data = st.session_state.arrangement_details[st.session_state.selected_arrangement]['data']
                            file_handler.export_data(export_name, arr_data)
                        else:
                            wavenumbers, y_processed = st.session_state.processed_data
                            file_handler.export_data(export_name, y_processed)
                        st.success(f"âœ… å·²å¯¼å‡ºåˆ° {export_name}")
                    except Exception as e:
                        st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
        else:
            st.markdown('<div style="border:1px dashed #ccc; height:80px; display:flex; align-items:center; justify-content:center;">å¤„ç†å®Œæˆåå¯å¯¼å‡ºç»“æœ</div>', unsafe_allow_html=True)

    # å³ä¾§ï¼šé¢„å¤„ç†è®¾ç½® + æ’åˆ—æ–¹æ¡ˆ + æµ‹è¯•åŠŸèƒ½
    with col_right:
        with st.expander("âš™ï¸ é¢„å¤„ç†è®¾ç½®", expanded=True):
            # åŸºçº¿æ ¡å‡†è®¾ç½®
            st.subheader("åŸºçº¿æ ¡å‡†", divider="gray")
            baseline_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "SD", "FD", "å¤šé¡¹å¼æ‹Ÿåˆ", "ModPoly", "I-ModPoly", "PLS", "AsLS", "airPLS", "äºŒé˜¶å·®åˆ†(D2)"],
                key="baseline_method",
                label_visibility="collapsed"
            )

            baseline_params = {}
            if baseline_method != "æ— ":
                if baseline_method == "å¤šé¡¹å¼æ‹Ÿåˆ":
                    polyorder = st.slider("é˜¶æ•°k", 3, 6, 5, key="polyorder", label_visibility="collapsed")
                    baseline_params["polyorder"] = polyorder
                    st.caption(f"é˜¶æ•°: {polyorder}")
                elif baseline_method == "ModPoly":
                    k = st.slider("å‚æ•°k", 4, 10, 10, key="k_mod", label_visibility="collapsed")
                    baseline_params["k"] = k
                    st.caption(f"k: {k}")
                elif baseline_method == "I-ModPoly":
                    polyorder = st.slider("å¤šé¡¹å¼é˜¶æ•°", 3, 7, 5, key="imod_polyorder", label_visibility="collapsed")
                    max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 50, 200, 100, key="imod_maxiter", label_visibility="collapsed")
                    tolerance = st.slider("æ”¶æ•›å®¹å·®", 0.001, 0.01, 0.005, key="imod_tol", label_visibility="collapsed")
                    baseline_params["polyorder"] = polyorder
                    baseline_params["max_iter"] = max_iter
                    baseline_params["tolerance"] = tolerance
                    st.caption(f"é˜¶æ•°: {polyorder}, è¿­ä»£: {max_iter}, å®¹å·®: {tolerance}")
                elif baseline_method == "PLS":
                    lam = st.selectbox("Î»", [10**10, 10**8, 10**7], key="lam_pls", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    st.caption(f"Î»: {lam}")
                elif baseline_method == "AsLS":
                    asls_cols = st.columns(2)
                    with asls_cols[0]:
                        p = st.selectbox("éå¯¹ç§°ç³»æ•°p", [0.001, 0.01, 0.1], key="p_asls", label_visibility="collapsed")
                    with asls_cols[1]:
                        lam = st.selectbox("å¹³æ»‘ç³»æ•°Î»", [10**5, 10**7, 10**9], key="lam_asls", label_visibility="collapsed")
                    niter = st.selectbox("è¿­ä»£æ¬¡æ•°", [5, 10, 15], key="niter_asls", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    baseline_params["p"] = p
                    baseline_params["niter"] = niter
                    st.caption(f"p: {p}, Î»: {lam}, è¿­ä»£æ¬¡æ•°: {niter}")
                elif baseline_method == "airPLS":
                    airpls_cols = st.columns(2)
                    with airpls_cols[0]:
                        lam = st.selectbox("Î»", [10**7, 10**4, 10**2], key="lam_air", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    st.caption(f"Î»: {lam}")
                elif baseline_method == "äºŒé˜¶å·®åˆ†(D2)":
                    st.caption("äºŒé˜¶å·®åˆ†å¯å¢å¼ºå…‰è°±ç‰¹å¾ï¼ŒæŠ‘åˆ¶åŸºçº¿æ¼‚ç§»")

            # ç¼©æ”¾è®¾ç½®
            st.subheader("ğŸ“ ç¼©æ”¾", divider="gray")
            scaling_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "Peak-Norm", "SNV", "MSC", "M-M-Norm", "L-èŒƒæ•°", "Ma-Minorm", "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)"],
                key="scaling_method",
                label_visibility="collapsed"
            )

            scaling_params = {}
            if scaling_method == "L-èŒƒæ•°":
                p = st.selectbox("p", ["æ— ç©·å¤§", "4", "10"], key="p_scale", label_visibility="collapsed")
                scaling_params["p"] = p
                st.caption(f"p: {p}")
            elif scaling_method == "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)":
                st.caption("å°†æ•°æ®æ ‡å‡†åŒ–åˆ°å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1")

            # æ»¤æ³¢è®¾ç½®
            st.subheader("ğŸ“¶ æ»¤æ³¢", divider="gray")
            filtering_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "Savitzky-Golay", "sgolayfiltæ»¤æ³¢å™¨", "ä¸­å€¼æ»¤æ³¢(MF)", "ç§»åŠ¨å¹³å‡(MAF)",
                 "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰", "MWMï¼ˆç§»åŠ¨çª—å£ä¸­å€¼ï¼‰", "å¡å°”æ›¼æ»¤æ³¢", "Lowess", "FFT",
                 "Smfftå‚…é‡Œå¶æ»¤æ³¢", "å°æ³¢å˜æ¢(DWT)", "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª"],
                key="filtering_method",
                label_visibility="collapsed"
            )

            filtering_params = {}
            if filtering_method != "æ— ":
                if filtering_method in ["Savitzky-Golay", "sgolayfiltæ»¤æ³¢å™¨"]:
                    sg_cols = st.columns(2)
                    with sg_cols[0]:
                        k = st.selectbox("å¤šé¡¹å¼é˜¶æ•°", [3, 7], key="k_sg", label_visibility="collapsed")
                    with sg_cols[1]:
                        w = st.selectbox("çª—å£å¤§å°", [11, 31, 51], key="w_sg", label_visibility="collapsed")
                    filtering_params["point"] = w
                    filtering_params["degree"] = k
                    st.caption(f"é˜¶æ•°: {k}, çª—å£: {w}")
                elif filtering_method in ["ä¸­å€¼æ»¤æ³¢(MF)", "ç§»åŠ¨å¹³å‡(MAF)"]:
                    mf_cols = st.columns(2)
                    with mf_cols[0]:
                        k = st.selectbox("k", [1, 3], key="k_mf", label_visibility="collapsed")
                    with mf_cols[1]:
                        w = st.selectbox("w", [7, 11], key="w_mf", label_visibility="collapsed")
                    filtering_params["k"] = k
                    filtering_params["w"] = w
                    st.caption(f"k: {k}, w: {w}")
                elif filtering_method == "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰":
                    mwa_cols = st.columns(2)
                    with mwa_cols[0]:
                        n = st.selectbox("çª—å£å¤§å°n", [4, 6, 8], key="n_mwa", label_visibility="collapsed")
                    with mwa_cols[1]:
                        it = st.selectbox("è¿­ä»£æ¬¡æ•°it", [1, 2, 3], key="it_mwa", label_visibility="collapsed")
                    filtering_params["n"] = n
                    filtering_params["it"] = it
                    filtering_params["mode"] = "full"
                    st.caption(f"çª—å£å¤§å°: {n}, è¿­ä»£æ¬¡æ•°: {it}")
                elif filtering_method == "MWMï¼ˆç§»åŠ¨çª—å£ä¸­å€¼ï¼‰":
                    mwm_cols = st.columns(2)
                    with mwm_cols[0]:
                        n = st.selectbox("çª—å£å¤§å°n", [5, 7, 9], key="n_mwm", label_visibility="collapsed")
                    with mwm_cols[1]:
                        it = st.selectbox("è¿­ä»£æ¬¡æ•°it", [1, 2, 3], key="it_mwm", label_visibility="collapsed")
                    filtering_params["n"] = n
                    filtering_params["it"] = it
                    st.caption(f"çª—å£å¤§å°: {n}, è¿­ä»£æ¬¡æ•°: {it}")
                elif filtering_method == "å¡å°”æ›¼æ»¤æ³¢":
                    R = st.selectbox("æµ‹é‡å™ªå£°æ–¹å·®R", [0.01, 0.1, 0.5], key="r_kalman", label_visibility="collapsed")
                    filtering_params["R"] = R
                    st.caption(f"æµ‹é‡å™ªå£°æ–¹å·®: {R}")
                elif filtering_method == "Lowess":
                    frac = st.selectbox("ç³»æ•°", [0.01, 0.03], key="frac_low", label_visibility="collapsed")
                    filtering_params["frac"] = frac
                    st.caption(f"ç³»æ•°: {frac}")
                elif filtering_method == "FFT":
                    cutoff = st.selectbox("é¢‘ç‡", [30, 50, 90], key="cutoff_fft", label_visibility="collapsed")
                    filtering_params["cutoff"] = cutoff
                    st.caption(f"é¢‘ç‡: {cutoff}")
                elif filtering_method == "Smfftå‚…é‡Œå¶æ»¤æ³¢":
                    row_e = st.selectbox("ä¿ç•™ä½é¢‘åˆ†é‡æ•°", [31, 51, 71], key="row_e_smfft", label_visibility="collapsed")
                    filtering_params["row_e"] = row_e
                    st.caption(f"ä¿ç•™ä½é¢‘åˆ†é‡æ•°: {row_e}")
                elif filtering_method == "å°æ³¢å˜æ¢(DWT)":
                    threshold = st.selectbox("é˜ˆå€¼", [0.1, 0.3, 0.5], key="thresh_dwt", label_visibility="collapsed")
                    filtering_params["threshold"] = threshold
                    st.caption(f"é˜ˆå€¼: {threshold}")
                elif filtering_method == "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª":
                    threshold = st.selectbox("é˜ˆå€¼", [0.1, 0.3, 0.5], key="thresh_wavelet_linear", label_visibility="collapsed")
                    filtering_params["threshold"] = threshold
                    st.caption(f"é˜ˆå€¼: {threshold}")

            # æŒ¤å‹è®¾ç½®
            st.subheader("ğŸ§ª æŒ¤å‹", divider="gray")
            squashing_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "SigmoidæŒ¤å‹", "æ”¹è¿›çš„SigmoidæŒ¤å‹", "é€»è¾‘å‡½æ•°", "ä½™å¼¦æŒ¤å‹(squashing)", "æ”¹è¿›çš„é€»è¾‘å‡½æ•°", "DTWæŒ¤å‹"],
                key="squashing_method",
                label_visibility="collapsed"
            )

            squashing_params = {}
            if squashing_method != "æ— ":
                if squashing_method == "æ”¹è¿›çš„é€»è¾‘å‡½æ•°":
                    st.caption("åŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢ï¼Œæ— é¢å¤–å‚æ•°")
                elif squashing_method == "æ”¹è¿›çš„SigmoidæŒ¤å‹":
                    maxn = st.selectbox("maxn", [5, 10, 15], key="maxn_isigmoid", label_visibility="collapsed")
                    squashing_params["maxn"] = maxn
                    st.caption(f"maxn: {maxn}")
                elif squashing_method == "DTWæŒ¤å‹":
                    dtw_row1 = st.columns(2)
                    with dtw_row1[0]:
                        l = st.selectbox("l", [1, 5], key="l_dtw", label_visibility="collapsed")
                    with dtw_row1[1]:
                        k1 = st.selectbox("k1", ["T", "F"], key="k1_dtw", label_visibility="collapsed")
                    k2 = st.selectbox("k2", ["T", "F"], key="k2_dtw", label_visibility="collapsed")
                    squashing_params["l"] = l
                    squashing_params["k1"] = k1
                    squashing_params["k2"] = k2
                    st.caption(f"l: {l}, k1: {k1}, k2: {k2}")
                elif squashing_method == "SigmoidæŒ¤å‹":
                    st.caption("ä½¿ç”¨æ ‡å‡†Sigmoidå‡½æ•°ï¼Œæ— é¢å¤–å‚æ•°")
                elif squashing_method == "ä½™å¼¦æŒ¤å‹(squashing)":
                    st.caption("ä½¿ç”¨åŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢ï¼Œæ— é¢å¤–å‚æ•°")
                elif squashing_method == "é€»è¾‘å‡½æ•°":
                    st.caption("æ— é¢å¤–å‚æ•°")

            # ä¿å­˜å½“å‰ç®—æ³•é€‰æ‹©
            current_algorithms = {
                'baseline': baseline_method,
                'baseline_params': baseline_params,
                'scaling': scaling_method,
                'scaling_params': scaling_params,
                'filtering': filtering_method,
                'filtering_params': filtering_params,
                'squashing': squashing_method,
                'squashing_params': squashing_params
            }
            st.session_state.current_algorithms = current_algorithms

            # æ“ä½œæŒ‰é’®
            st.subheader("æ“ä½œ", divider="gray")
            btn_cols = st.columns(2)
            with btn_cols[0]:
                if st.button("ğŸš€ åº”ç”¨å¤„ç†", type="primary", use_container_width=True, key="apply_btn"):
                    if st.session_state.raw_data is None:
                        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                        return

                    try:
                        wavenumbers, y = st.session_state.raw_data
                        y_processed, method_name = preprocessor.process(
                            wavenumbers, y,
                            baseline_method=baseline_method,
                            baseline_params=baseline_params,
                            squashing_method=squashing_method,
                            squashing_params=squashing_params,
                            filtering_method=filtering_method,
                            filtering_params=filtering_params,
                            scaling_method=scaling_method,
                            scaling_params=scaling_params
                        )

                        st.session_state.processed_data = (wavenumbers, y_processed)
                        st.session_state.process_method = " â†’ ".join(method_name) if method_name else "æ— é¢„å¤„ç†"
                        st.success("âœ… é¢„å¤„ç†å®Œæˆ")
                    except Exception as e:
                        st.error(f"âŒ é¢„å¤„ç†å¤±è´¥: {str(e)}")

            with btn_cols[1]:
                if st.button("ğŸ”„ ç”Ÿæˆæ’åˆ—æ–¹æ¡ˆ", type="secondary", use_container_width=True, key="generate_btn"):
                    if st.session_state.raw_data is None:
                        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                        return

                    try:
                        perms = generate_permutations(current_algorithms)
                        st.session_state.algorithm_permutations = perms
                        st.session_state.filtered_perms = perms
                        st.session_state.show_arrangements = True
                        st.success(f"âœ… ç”Ÿæˆ{len(perms)}ç§æ’åˆ—æ–¹æ¡ˆ")
                    except Exception as e:
                        st.error(f"âŒ ç”Ÿæˆæ’åˆ—æ–¹æ¡ˆå¤±è´¥: {str(e)}")

        # æ’åˆ—æ–¹æ¡ˆå±•ç¤º
        if st.session_state.show_arrangements and st.session_state.algorithm_permutations:
            with st.expander(f"ğŸ“‹ æ’åˆ—æ–¹æ¡ˆ ({len(st.session_state.filtered_perms)})", expanded=True):
                # ç­›é€‰é€‰é¡¹
                first_step_filter = st.selectbox(
                    "æŒ‰ç¬¬ä¸€æ­¥ç­›é€‰",
                    ["å…¨éƒ¨", "æ— é¢„å¤„ç†", "åŸºçº¿æ ¡å‡†", "ç¼©æ”¾", "æ»¤æ³¢", "æŒ¤å‹"],
                    key="step_filter",
                    label_visibility="collapsed"
                )

                # åº”ç”¨ç­›é€‰
                if first_step_filter != "å…¨éƒ¨":
                    st.session_state.filtered_perms = [
                        p for p in st.session_state.algorithm_permutations
                        if p["first_step_type"] == first_step_filter
                    ]
                else:
                    st.session_state.filtered_perms = st.session_state.algorithm_permutations

                # æ˜¾ç¤ºæ•°é‡
                st.caption(f"æ˜¾ç¤º {len(st.session_state.filtered_perms)} ç§æ–¹æ¡ˆ")

                # æ–¹æ¡ˆé€‰æ‹©
                perm_names = [p["name"] for p in st.session_state.filtered_perms]
                selected_idx = st.selectbox(
                    "é€‰æ‹©æ–¹æ¡ˆ",
                    range(len(perm_names)),
                    format_func=lambda x: perm_names[x],
                    key="perm_select",
                    label_visibility="collapsed",
                    index=st.session_state.selected_perm_idx
                )
                st.session_state.selected_perm_idx = selected_idx

                # åº”ç”¨é€‰ä¸­çš„æ’åˆ—æ–¹æ¡ˆ
                if st.button("â–¶ï¸ åº”ç”¨é€‰ä¸­æ–¹æ¡ˆ", use_container_width=True, key="apply_perm_btn"):
                    try:
                        selected_perm = st.session_state.filtered_perms[selected_idx]
                        wavenumbers, y = st.session_state.raw_data

                        y_processed, method_name = preprocessor.process(
                            wavenumbers, y,
                            baseline_method=current_algorithms['baseline'],
                            baseline_params=current_algorithms['baseline_params'],
                            squashing_method=current_algorithms['squashing'],
                            squashing_params=current_algorithms['squashing_params'],
                            filtering_method=current_algorithms['filtering'],
                            filtering_params=current_algorithms['filtering_params'],
                            scaling_method=current_algorithms['scaling'],
                            scaling_params=current_algorithms['scaling_params'],
                            algorithm_order=selected_perm["order"]
                        )

                        method_str = " â†’ ".join(method_name) if method_name else "æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"
                        st.session_state.arrangement_details[selected_perm["name"]] = {
                            "data": y_processed,
                            "method": method_str,
                            "order": selected_perm["order"]
                        }
                        st.session_state.selected_arrangement = selected_perm["name"]
                        st.success(f"âœ… å·²åº”ç”¨: {selected_perm['name']}")
                    except Exception as e:
                        st.error(f"âŒ åº”ç”¨æ’åˆ—æ–¹æ¡ˆå¤±è´¥: {str(e)}")

        # åˆ†ç±»æµ‹è¯•åŠŸèƒ½
        if st.session_state.get('selected_arrangement') and st.session_state.get('labels') is not None:
            with st.expander("ğŸ§ª åˆ†ç±»æµ‹è¯•", expanded=True):
                st.subheader("KNNå‚æ•°", divider="gray")
                k_value = st.slider(
                    "kå€¼",
                    min_value=1,
                    max_value=15,
                    value=5,
                    step=2,
                    key="knn_k",
                    label_visibility="collapsed"
                )
                st.session_state.k_value = k_value

                if st.button("â–¶ï¸ å¼€å§‹æµ‹è¯•", type="primary", use_container_width=True, key="test_btn"):
                    try:
                        # è·å–æ•°æ®
                        wavenumbers, y = st.session_state.raw_data
                        selected_arr = st.session_state.selected_arrangement
                        processed_data = st.session_state.arrangement_details[selected_arr]['data']
                        
                        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
                        train_idx = st.session_state.train_indices
                        test_idx = st.session_state.test_indices
                        labels = st.session_state.labels

                        # ç¡®ä¿ç´¢å¼•æœ‰æ•ˆ
                        if len(train_idx) == 0 or len(test_idx) == 0:
                            st.warning("âš ï¸ è®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©ºï¼Œè¯·è°ƒæ•´è®­ç»ƒé›†æ¯”ä¾‹")
                            return

                        # æå–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
                        train_data = processed_data[:, train_idx]
                        test_data = processed_data[:, test_idx]
                        train_labels = labels[train_idx]
                        test_labels = labels[test_idx]

                        # æ‰§è¡ŒKNNåˆ†ç±»
                        predictions = knn_classify(train_data, train_labels, test_data, k=k_value)

                        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
                        accuracy = accuracy_score(test_labels, predictions)
                        kappa = cohen_kappa_score(test_labels, predictions)
                        cm = confusion_matrix(test_labels, predictions)

                        # ä¿å­˜ç»“æœ
                        st.session_state.test_results = {
                            'accuracy': accuracy,
                            'kappa': kappa,
                            'confusion_matrix': cm,
                            'predictions': predictions,
                            'test_labels': test_labels
                        }

                        st.success(f"âœ… æµ‹è¯•å®Œæˆ | å‡†ç¡®ç‡: {accuracy:.4f} | å¡å¸•ç³»æ•°: {kappa:.4f}")
                    except Exception as e:
                        st.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    main()
    
