import streamlit as st
import numpy as np
import pandas as pd
import re
import itertools
import matplotlib.pyplot as plt
import math
import zipfile
import os
from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix
import seaborn as sns
from scipy import sparse
from scipy.sparse.linalg import spsolve
from scipy.signal import savgol_filter, medfilt
from scipy.fft import fft, ifft
from scipy.fftpack import fft as fftpack_fft, ifft as fftpack_ifft
import copy
from statsmodels.nonparametric.smoothers_lowess import lowess
import pywt

class FileHandler:
    def load_data_from_zip(self, zip_file):
        """ä»å‹ç¼©åŒ…ä¸­åŠ è½½æ³¢æ•°å’Œå…‰è°±æ•°æ®ï¼Œè‡ªåŠ¨è¯†åˆ«æ•°æ®ç»´åº¦"""
        with zipfile.ZipFile(zip_file, 'r') as zf:
            # åˆ—å‡ºå‹ç¼©åŒ…ä¸­çš„æ‰€æœ‰æ–‡ä»¶
            file_list = zf.namelist()
            
            # å°è¯•è¯†åˆ«æ³¢æ•°æ–‡ä»¶å’Œå…‰è°±æ•°æ®æ–‡ä»¶
            wavenumber_files = [f for f in file_list if 'wave' in f.lower() or 'wn' in f.lower() or 'æ³¢æ•°' in f]
            data_files = [f for f in file_list if 'spec' in f.lower() or 'data' in f.lower() or 'å…‰è°±' in f]
            
            if not wavenumber_files:
                raise ValueError("å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°æ³¢æ•°æ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«'wave'ã€'wn'æˆ–'æ³¢æ•°'ï¼‰")
            if not data_files:
                raise ValueError("å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°å…‰è°±æ•°æ®æ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«'spec'ã€'data'æˆ–'å…‰è°±'ï¼‰")
            
            # å–ç¬¬ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶
            wn_file = wavenumber_files[0]
            data_file = data_files[0]
            
            # è¯»å–æ³¢æ•°æ–‡ä»¶
            with zf.open(wn_file) as f:
                wavenumbers = np.loadtxt(f).ravel()
            
            # è¯»å–å…‰è°±æ•°æ®æ–‡ä»¶
            with zf.open(data_file) as f:
                content = f.read().decode("utf-8")
                data = self._parse_data(content)
            
            return wavenumbers, data.T

    def _parse_data(self, content):
        """è§£æå…‰è°±æ•°æ®å†…å®¹ï¼Œè‡ªåŠ¨è¯†åˆ«æ•°æ®ç»´åº¦"""
        numb = re.compile(r"-?\d+(?:\.\d+)?")
        lines_list = content.splitlines()
        
        # æå–æ‰€æœ‰æ•°å­—
        all_numbers = []
        for line in lines_list:
            all_numbers.extend(numb.findall(line))
        
        # å°†æå–åˆ°çš„æ•°å­—è½¬æ¢ä¸ºæµ®åŠ¨ç±»å‹
        data = np.array([float(num) for num in all_numbers])
        
        # å‡è®¾æ¯æ¡å…‰è°±çš„ç‚¹æ•°ä¸º `much`
        n_rows = len(lines_list)
        n_cols = len(data) // n_rows if n_rows > 0 else 0
        data = data[:n_rows * n_cols]  # æˆªå–å¤šä½™çš„æ•°æ®
        return data.reshape(n_rows, n_cols)

    def export_data(self, filename, data):
        with open(filename, "w") as f:
            for line in data.T:  # è½¬ç½®å›åŸå§‹æ ¼å¼
                f.write("\t".join(map(str, line)) + "\n")
    


def main():
    # æœ€ä¼˜å…ˆåˆå§‹åŒ–session state
    if 'show_arrangements' not in st.session_state:
        st.session_state.show_arrangements = False

    # åˆå§‹åŒ–k_valueå’Œå…¶ä»–sessionçŠ¶æ€
    if 'k_value' not in st.session_state:
        st.session_state.k_value = 5  # è®¾ç½®k_valueçš„é»˜è®¤å€¼
    
    # åˆå§‹åŒ–æµ‹è¯•ç›¸å…³çš„sessionçŠ¶æ€å˜é‡
    test_states = {
        'k_value': st.session_state.k_value,  # ç°åœ¨ä»session_stateè·å–k_value
        'test_results': None,  # å­˜å‚¨æµ‹è¯•ç»“æœ
        'labels': None,  # å­˜å‚¨æ ·æœ¬æ ‡ç­¾
        'train_indices': None,  # è®­ç»ƒé›†ç´¢å¼•
        'test_indices': None  # æµ‹è¯•é›†ç´¢å¼•
    }

    # åˆå§‹åŒ–å…¶ä»–å¿…è¦çš„sessionçŠ¶æ€å˜é‡
    other_states = {
        'raw_data': None,
        'processed_data': None,
        'peaks': None,
        'train_test_split_ratio': 0.8,
        'arrangement_results': [],
        'selected_arrangement': None,
        'arrangement_details': {},
        'algorithm_permutations': [],  # å­˜å‚¨ç®—æ³•æ’åˆ—ç»„åˆ
        'current_algorithms': {},  # å­˜å‚¨å½“å‰é€‰æ‹©çš„ç®—æ³•
        'filtered_perms': [],  # å­˜å‚¨ç­›é€‰åçš„æ’åˆ—æ–¹æ¡ˆ
        'selected_perm_idx': 0  # å­˜å‚¨å½“å‰é€‰ä¸­çš„æ’åˆ—ç´¢å¼•
    }

    # åˆå¹¶æ‰€æœ‰çŠ¶æ€å˜é‡å¹¶åˆå§‹åŒ–
    all_states = {**test_states, **other_states}
    for key, value in all_states.items():
        if key not in st.session_state:
            st.session_state[key] = value
    file_handler = FileHandler()

    # è®¾ç½®é¡µé¢ï¼šç´§å‡‘å¸ƒå±€
    st.set_page_config(layout="wide", page_icon="ğŸ”¬", page_title="æ’åˆ—é¢„å¤„ç†æ¨¡å‹")
    
    # å…¨å±€æ ·å¼è°ƒæ•´ï¼šæ›´ç´§å‡‘çš„å­—ä½“å’Œé—´è·ï¼Œç¡®ä¿é¢„å¤„ç†è®¾ç½®åœ¨ä¸€è¡Œæ˜¾ç¤º
    st.markdown("""
        <style>
        body {font-size: 0.75rem !important;}
        .css-1v0mbdj {padding: 0.3rem 0.5rem !important;} 
        .css-1d391kg {padding: 0.2rem 0 !important;} 
        .css-1x8cf1d {line-height: 1.1 !important;} 
        .css-12ttj6m {margin-bottom: 0.3rem !important;} 
        .css-16huue1 {padding: 0.2rem 0.5rem !important; font-size: 0.7rem !important;} 
        h3 {font-size: 1rem !important; margin: 0.3rem 0 !important;} 
        .css-1b3298e {gap: 0.3rem !important;} 
        .stSlider, .stSelectbox, .stTextInput {margin-bottom: 0.3rem !important;} 
        .stCaption {font-size: 0.65rem !important; margin-top: -0.2rem !important;} 
        .css-1544g2n {padding: 0.2rem 0.5rem !important;} 
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸŒŒ æ’åˆ—é¢„å¤„ç†æ¨¡å‹")
    
    # é¡µé¢æ•´ä½“å¸ƒå±€ï¼šå·¦ä¾§æ•°æ®ç®¡ç†ï¼Œå³ä¾§ä¸»è¦å†…å®¹åŒº
    col_left, col_right = st.columns([1.2, 3.9])
    
    # ===== å·¦ä¾§ï¼šæ•°æ®ç®¡ç†æ¨¡å— =====
    with col_left:
        with st.expander("ğŸ“ æ•°æ®ç®¡ç†", expanded=True):
            zip_file = st.file_uploader("ä¸Šä¼ åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®çš„å‹ç¼©åŒ…", type=['zip'], key="zip_file")
            st.caption("å‹ç¼©åŒ…(.zip)éœ€åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®æ–‡ä»¶")
            
            st.subheader("æ ·æœ¬æ ‡ç­¾")
            num_classes = st.number_input("ç±»åˆ«æ•°é‡", min_value=1, value=2, step=1, key="num_cls")
            labels_input = st.text_input("æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼Œä¸å…‰è°±é¡ºåºä¸€è‡´ï¼‰", placeholder="ä¾‹ï¼š0,0,1,1", key="labels_in")
            
            st.subheader("è®­ç»ƒæµ‹è¯•åˆ’åˆ†")
            train_test_ratio = st.slider("è®­ç»ƒé›†æ¯”ä¾‹", min_value=0.1, max_value=0.9, value=0.8, step=0.1, format="%.1f", key="train_ratio")
            st.session_state.train_test_split_ratio = train_test_ratio
    
            if zip_file:
                try:
                    st.session_state.raw_data = file_handler.load_data_from_zip(zip_file)
                    
                    if labels_input:
                        try:
                            labels = np.array([int(l.strip()) for l in labels_input.split(',')])
                            if len(labels) == st.session_state.raw_data[1].shape[1]:
                                st.session_state.labels = labels
                                n_samples = len(labels)
                                train_size = int(n_samples * train_test_ratio)
                                indices = np.random.permutation(n_samples)
                                st.session_state.train_indices = indices[:train_size]
                                st.session_state.test_indices = indices[train_size:]
                                st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{st.session_state.raw_data[1].shape[1]}æ¡å…‰è°±ï¼Œ{len(np.unique(labels))}ç±»")
                            else:
                                st.warning(f"âš ï¸ æ ‡ç­¾æ•°({len(labels)})â‰ å…‰è°±æ•°({st.session_state.raw_data[1].shape[1]})")
                                st.session_state.labels = None
                        except Exception as e:
                            st.warning(f"âš ï¸ æ ‡ç­¾æ ¼å¼é”™è¯¯: {str(e)}")
                            st.session_state.labels = None
                    else:
                        st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{st.session_state.raw_data[1].shape[1]}æ¡å…‰è°±ï¼Œ{st.session_state.raw_data[1].shape[0]}ä¸ªç‚¹")
                        st.warning("âš ï¸ è¯·è¾“å…¥æ ·æœ¬æ ‡ç­¾ä»¥è¿›è¡Œåˆ†ç±»æµ‹è¯•")
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        
        if st.session_state.get('raw_data'):
            wavenumbers, y = st.session_state.raw_data
            st.info(f"ğŸ“Š æ•°æ®ç»´åº¦: {y.shape[1]}æ¡ Ã— {y.shape[0]}ç‚¹")
            st.info(f"ğŸ”¢ è®­ç»ƒé›†:{train_test_ratio:.1f} | æµ‹è¯•é›†:{1-train_test_ratio:.1f}")
            if st.session_state.get('labels') is not None:
                class_counts = np.bincount(st.session_state.labels)
                st.info(f"ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ: {', '.join([f'ç±»{i}:{count}ä¸ª' for i, count in enumerate(class_counts) if count>0])}")
            if st.session_state.get('process_method'):
                st.success(f"ğŸ› ï¸ å¤„ç†æµç¨‹: {st.session_state.process_method}")
        
        with st.expander("â„¹ï¸ ä½¿ç”¨æŒ‡å—", expanded=False):
            st.markdown("""
            1. ä¸Šä¼ åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®çš„å‹ç¼©åŒ…  
            2. è®¾ç½®æ ‡ç­¾å’Œè®­ç»ƒæµ‹è¯•æ¯”ä¾‹  
            3. å³ä¾§ä¸Šæ–¹é€‰æ‹©é¢„å¤„ç†æ–¹æ³•  
            4. ç‚¹å‡»"æ˜¾ç¤ºæ’åˆ—"ç”Ÿæˆæ–¹æ¡ˆ  
            5. é€‰æ‹©kå€¼åç‚¹å‡»"æµ‹è¯•"  
            6. æŸ¥çœ‹ç»“æœå¹¶å¯¼å‡º
            """)

    

    
if __name__ == "__main__":
    main()
