import streamlit as st
import numpy as np
import pandas as pd
import re
import itertools
import matplotlib.pyplot as plt
import math
import zipfile
import os
from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix
import seaborn as sns
from scipy import sparse
from scipy.sparse.linalg import spsolve
from scipy.signal import savgol_filter, medfilt
from scipy.fft import fft, ifft
from scipy.fftpack import fft as fftpack_fft, ifft as fftpack_ifft
import copy
from statsmodels.nonparametric.smoothers_lowess import lowess
import pywt
from sklearn.linear_model import LinearRegression  # ç”¨äºMSC
import scipy.signal as signal

# ===== ç®—æ³•å®ç° =====
def polynomial_fit(wavenumbers, spectra, polyorder):
    """å¤šé¡¹å¼æ‹ŸåˆåŸºçº¿æ ¡æ­£"""
    baseline = np.zeros_like(spectra)
    for i in range(spectra.shape[1]):
        coeffs = np.polyfit(wavenumbers, spectra[:, i], deg=polyorder)
        baseline[:, i] = np.polyval(coeffs, wavenumbers)
    return spectra - baseline  # æ‰£é™¤åŸºçº¿

def modpoly(wavenumbers, spectra, k):
    """Modified Polynomial (ModPoly) åŸºçº¿æ ¡æ­£"""
    baseline = np.zeros_like(spectra)
    n_points = len(wavenumbers)
    for i in range(spectra.shape[1]):
        y = spectra[:, i].copy()
        for _ in range(k):
            coeffs = np.polyfit(wavenumbers, y, deg=5)
            fitted = np.polyval(coeffs, wavenumbers)
            mask = y < fitted
            y[~mask] = fitted[~mask]
        baseline[:, i] = y
    return spectra - baseline

def pls(spectra, lam):
    """Penalized Least Squares (PLS) åŸºçº¿æ ¡æ­£"""
    n_points = spectra.shape[0]
    baseline = np.zeros_like(spectra)
    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(n_points, n_points - 2))
    D = lam * D.dot(D.transpose())
    for i in range(spectra.shape[1]):
        y = spectra[:, i]
        A = sparse.eye(n_points) + D
        baseline[:, i] = spsolve(A, y)
    return spectra - baseline

def airpls(spectra, lam, max_iter=15, threshold=0.001):
    """Adaptive Iteratively Reweighted Penalized Least Squares (airPLS) åŸºçº¿æ ¡æ­£"""
    n_points = spectra.shape[0]
    baseline = np.zeros_like(spectra)
    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(n_points, n_points - 2))
    D = lam * D.dot(D.transpose())
    for i in range(spectra.shape[1]):
        y = spectra[:, i]
        w = np.ones(n_points)
        baseline_i = np.zeros(n_points)
        for j in range(max_iter):
            W = sparse.diags(w, 0)
            Z = W + D
            b = spsolve(Z, W * y)
            d = y - b
            neg_mask = d < 0
            w[neg_mask] = np.exp(j * np.abs(d[neg_mask]) / np.std(d[neg_mask]))
            w[~neg_mask] = 0
            if j > 0:
                diff = np.sum(np.abs(b - baseline_i)) / np.sum(np.abs(baseline_i)) if np.sum(
                    np.abs(baseline_i)) > 0 else 0
                if diff < threshold:
                    break
            baseline_i = b
        baseline[:, i] = baseline_i
    return spectra - baseline

def dtw_squashing(x, l, k1, k2):
    """åŠ¨æ€æ—¶é—´è§„æ•´(DTW)æŒ¤å‹ç®—æ³•"""
    n_samples, n_features = x.shape
    result = np.zeros_like(x)
    reference = np.mean(x, axis=1)  # ä½¿ç”¨å¹³å‡å…‰è°±ä½œä¸ºå‚è€ƒ
    dtw = DTW()

    for i in range(n_features):
        spectrum = x[:, i]
        path, cost = dtw(reference, spectrum)
        squashed = np.zeros_like(spectrum)
        for ref_idx, spec_idx in path:
            squashed[ref_idx] += spectrum[spec_idx]
        unique_ref_indices = np.unique([p[0] for p in path])
        for idx in unique_ref_indices:
            count = sum(1 for p in path if p[0] == idx)
            squashed[idx] /= count
        if k1 == "T":
            max_slope = l
            for j in range(1, len(path)):
                ref_diff = path[j][0] - path[j - 1][0]
                spec_diff = path[j][1] - path[j - 1][1]
                if ref_diff != 0:
                    slope = abs(spec_diff / ref_diff)
                    if slope > max_slope:
                        squashed[path[j][0]] = (squashed[path[j][0]] + squashed[path[j - 1][0]]) / 2
        if k2 == "T":
            ref_map_count = {}
            for ref_idx, _ in path:
                ref_map_count[ref_idx] = ref_map_count.get(ref_idx, 0) + 1
                for ref_idx, count in ref_map_count.items():
                    if count > l:
                        window = min(l, len(spectrum))
                        start = max(0, ref_idx - window // 2)
                        end = min(n_samples, ref_idx + window // 2 + 1)
                        squashed[ref_idx] = np.mean(spectrum[start:end])
        if l > 1:
            for j in range(n_samples):
                start = max(0, j - l)
                end = min(n_samples, j + l + 1)
                squashed[j] = np.mean(squashed[start:end])
        result[:, i] = squashed
    return result

# ===== åˆ†ç±»ç®—æ³•å®ç° =====
def knn_classify(train_data, train_labels, test_data, k=5):
    """Kè¿‘é‚»åˆ†ç±»ç®—æ³•å®ç°"""
    # è½¬ç½®æ•°æ®ä»¥é€‚åº”æ ·æœ¬æ•°Ã—ç‰¹å¾æ•°çš„æ ¼å¼
    train_data = train_data.T
    test_data = test_data.T

    predictions = []
    for test_sample in test_data:
        # è®¡ç®—ä¸æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„æ¬§æ°è·ç¦»
        distances = np.sqrt(np.sum((train_data - test_sample) **2, axis=1))
        # è·å–æœ€è¿‘çš„kä¸ªæ ·æœ¬çš„ç´¢å¼•
        k_indices = np.argsort(distances)[:k]
        # è·å–è¿™äº›æ ·æœ¬çš„æ ‡ç­¾
        k_nearest_labels = [train_labels[i] for i in k_indices]
        # å¤šæ•°æŠ•ç¥¨å†³å®šé¢„æµ‹æ ‡ç­¾
        most_common = np.bincount(k_nearest_labels).argmax()
        predictions.append(most_common)
    return np.array(predictions)  

# ===== é¢„å¤„ç†ç±» =====
class Preprocessor:
    def __init__(self):
        self.BASELINE_ALGORITHMS = {
            "SD": self._sd_baseline,
            "FD": self._fd_baseline,
            "å¤šé¡¹å¼æ‹Ÿåˆ": polynomial_fit,
            "ModPoly": modpoly,
            "I-ModPoly": IModPoly,
            "PLS": pls,
            "AsLS": baseline_als,
            "airPLS": airpls,
            "äºŒé˜¶å·®åˆ†(D2)": self.d2
        }
        self.FILTERING_ALGORITHMS = {
            "Savitzky-Golay": self.savitzky_golay,
            "sgolayfiltæ»¤æ³¢å™¨": self.sgolay_filter_custom,
            "ä¸­å€¼æ»¤æ³¢(MF)": self.median_filter,
            "ç§»åŠ¨å¹³å‡(MAF)": self.moving_average,
            "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰": self.mwa_filter,
            "MWMï¼ˆç§»åŠ¨çª—å£ä¸­å€¼ï¼‰": self.mwm_filter,
            "å¡å°”æ›¼æ»¤æ³¢": self.kalman_filter,
            "Lowess": self.lowess_filter,
            "FFT": self.fft_filter,
            "Smfftå‚…é‡Œå¶æ»¤æ³¢": self.smfft_filter,
            "å°æ³¢å˜æ¢(DWT)": self.wavelet_filter,
            "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª": self.wavelet_linear
        }

        self.SCALING_ALGORITHMS = {
            "Peak-Norm": self.peak_norm,
            "SNV": self.snv,
            "MSC": self.msc,
            "M-M-Norm": self.mm_norm,
            "L-èŒƒæ•°": self.l_norm,
            "Ma-Minorm": self.ma_minorm,
            "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)": self.standardize
        }

        self.SQUASHING_ALGORITHMS = {
            "SigmoidæŒ¤å‹": sigmoid,
            "æ”¹è¿›çš„SigmoidæŒ¤å‹": i_sigmoid,
            "é€»è¾‘å‡½æ•°": squashing_legacy,
            "ä½™å¼¦æŒ¤å‹(squashing)": squashing,
            "æ”¹è¿›çš„é€»è¾‘å‡½æ•°": i_squashing,
            "DTWæŒ¤å‹": dtw_squashing
        }

    def process(self, wavenumbers, data,
                baseline_method="æ— ", baseline_params=None,
                squashing_method="æ— ", squashing_params=None,
                filtering_method="æ— ", filtering_params=None,
                scaling_method="æ— ", scaling_params=None,
                algorithm_order=None):
        """æ‰§è¡Œé¢„å¤„ç†æµç¨‹ï¼Œæ”¯æŒæŒ‡å®šç®—æ³•é¡ºåº"""
        if baseline_params is None: baseline_params = {}
        if squashing_params is None: squashing_params = {}
        if filtering_params is None: filtering_params = {}
        if scaling_params is None: scaling_params = {}

        # å¦‚æœç®—æ³•é¡ºåºä¸ºç©ºï¼Œè¿”å›åŸå§‹æ•°æ®
        if algorithm_order is not None and len(algorithm_order) == 0:
            return data.copy(), ["æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"]

        y_processed = data.copy()
        method_name = []

        # å¦‚æœæŒ‡å®šäº†ç®—æ³•é¡ºåºï¼Œåˆ™æŒ‰é¡ºåºæ‰§è¡Œ
        if algorithm_order is not None and len(algorithm_order) > 0:
            # æ ¹æ®ç®—æ³•ç¼–å·æ˜ å°„åˆ°å¯¹åº”çš„å¤„ç†æ­¥éª¤
            step_mapping = {
                1: ("baseline", baseline_method, baseline_params),
                2: ("scaling", scaling_method, scaling_params),
                3: ("filtering", filtering_method, filtering_params),
                4: ("squashing", squashing_method, squashing_params)
            }
            # æŒ‰æŒ‡å®šé¡ºåºåˆ›å»ºæ­¥éª¤åˆ—è¡¨
            steps = [step_mapping[order] for order in algorithm_order]
        else:
            # é»˜è®¤é¡ºåºï¼šåŸºçº¿ â†’ æŒ¤å‹ â†’ æ»¤æ³¢ â†’ ç¼©æ”¾
            steps = []
            if baseline_method != "æ— ":
                steps.append(("baseline", baseline_method, baseline_params))
            if squashing_method != "æ— ":
                steps.append(("squashing", squashing_method, squashing_params))
            if filtering_method != "æ— ":
                steps.append(("filtering", filtering_method, filtering_params))
            if scaling_method != "æ— ":
                steps.append(("scaling", scaling_method, scaling_params))

        # æŒ‰é¡ºåºæ‰§è¡Œé¢„å¤„ç†æ­¥éª¤
        for step_type, method, params in steps:
            if method == "æ— ":
                continue

            try:
                if step_type == "baseline":
                    algorithm_func = self.BASELINE_ALGORITHMS[method]
                    if method in ["å¤šé¡¹å¼æ‹Ÿåˆ", "ModPoly", "I-ModPoly"]:
                        y_processed = algorithm_func(wavenumbers, y_processed,** params)
                    elif method in ["PLS"]:
                        y_processed = algorithm_func(y_processed, **params)
                    elif method == "AsLS":
                        y_processed = algorithm_func(y_processed,** params)
                    elif method == "airPLS":
                        y_processed = algorithm_func(y_processed, **params)
                    elif method == "äºŒé˜¶å·®åˆ†(D2)":
                        y_processed = algorithm_func(y_processed)
                    else:  # SDã€FD æ— é¢å¤–å‚æ•°
                        y_processed = algorithm_func(y_processed)
                    method_name.append(f"{method}({', '.join([f'{k}={v}' for k, v in params.items()])})")

                elif step_type == "squashing":
                    algorithm_func = self.SQUASHING_ALGORITHMS[method]
                    if method == "æ”¹è¿›çš„SigmoidæŒ¤å‹":
                        maxn = params.get("maxn", 10)
                        y_processed = algorithm_func(y_processed, maxn=maxn)
                        method_name.append(f"{method}(maxn={maxn})")
                    elif method == "æ”¹è¿›çš„é€»è¾‘å‡½æ•°":
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    elif method == "DTWæŒ¤å‹":
                        l = params.get("l", 1)
                        k1 = params.get("k1", "T")
                        k2 = params.get("k2", "T")
                        y_processed = algorithm_func(y_processed, l=l, k1=k1, k2=k2)
                        method_name.append(f"DTWæŒ¤å‹(l={l}, k1={k1}, k2={k2})")
                    elif method == "SigmoidæŒ¤å‹":
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    elif method == "ä½™å¼¦æŒ¤å‹(squashing)":
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    else:
                        y_processed = algorithm_func(y_processed)
                        method_name.append(method)

                elif step_type == "filtering":
                    algorithm_func = self.FILTERING_ALGORITHMS[method]
                    y_processed = algorithm_func(y_processed,** params)
                    params_str = ', '.join([f'{k}={v}' for k, v in params.items()])
                    method_name.append(f"{method}({params_str})")

                    if method == "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª":
                        threshold = params.get("threshold", 0.3)
                        method_name[-1] = f"{method}(threshold={threshold})"

                elif step_type == "scaling":
                    algorithm_func = self.SCALING_ALGORITHMS[method]
                    y_processed = algorithm_func(y_processed, **params)
                    params_str = ', '.join([f'{k}={v}' for k, v in params.items()])
                    method_name.append(f"{method}({params_str})")

            except Exception as e:
                raise ValueError(f"{step_type}å¤„ç†å¤±è´¥: {str(e)}")

        return y_processed, method_name

    def _sd_baseline(self, spectra):
        return spectra - np.min(spectra, axis=0)

    def _fd_baseline(self, spectra):
        return spectra - np.percentile(spectra, 5, axis=0)

    # ===== æ»¤æ³¢ç®—æ³•å®ç° =====
    def savitzky_golay(self, spectra, window_length, polyorder):
        return savgol_filter(spectra, window_length, polyorder, axis=0)

    def sgolay_filter_custom(self, spectra, window_length, polyorder):
        if spectra.shape[0] < spectra.shape[1]:
            filtered = savgol_filter(spectra.T, window_length, polyorder, axis=0)
            return filtered.T
        else:
            return savgol_filter(spectra, window_length, polyorder, axis=0)

    def median_filter(self, spectra, k, w):
        return medfilt(spectra, kernel_size=(w, 1))

    def moving_average(self, spectra, k, w):
        kernel = np.ones(w) / w
        return np.apply_along_axis(lambda x: np.convolve(x, kernel, mode='same'), 0, spectra)

    def mwa_filter(self, spectra, n=6, it=1, mode="full"):
        return MWA(spectra, n=n, it=it, mode=mode)

    def mwm_filter(self, spectra, n=7, it=1):
        if spectra.shape[0] < spectra.shape[1]:
            filtered = MWM(spectra.T, n=n, it=it)
            return filtered.T
        else:
            return MWM(spectra, n=n, it=it)

    def kalman_filter(self, spectra, R=0.1):
        return KalmanF(spectra, R)

    def lowess_filter(self, spectra, frac):
        result = np.zeros_like(spectra)
        for i in range(spectra.shape[1]):
            smoothed = lowess(spectra[:, i], np.arange(len(spectra)), frac=frac, it=0)
            result[:, i] = smoothed[:, 1]
        return result

    def fft_filter(self, spectra, cutoff):
        fft_result = fft(spectra, axis=0)
        frequencies = np.fft.fftfreq(spectra.shape[0])
        filter_mask = np.abs(frequencies) < cutoff
        fft_result[~filter_mask, :] = 0
        return np.real(ifft(fft_result, axis=0))

    def smfft_filter(self, spectra, row_e=51):
        if spectra.shape[0] < spectra.shape[1]:
            filtered = Smfft(spectra.T, row_e=row_e)
            return filtered.T
        else:
            return Smfft(spectra, row_e=row_e)

    def wavelet_filter(self, spectra, threshold):
        coeffs = pywt.wavedec(spectra, 'db4', axis=0)
        coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]
        return pywt.waverec(coeffs, 'db4', axis=0)

    def wavelet_linear(self, spectra, threshold=0.3):
        if spectra.shape[0] < spectra.shape[1]:
            filtered = waveletlinear(spectra.T, threshold=threshold)
            return filtered.T
        else:
            return waveletlinear(spectra, threshold=threshold)

    # ===== ç¼©æ”¾ç®—æ³•å®ç° =====
    def peak_norm(self, spectra):
        return spectra / np.max(spectra, axis=0)

    def snv(self, spectra):
        mean = np.mean(spectra, axis=0)
        std = np.std(spectra, axis=0)
        return (spectra - mean) / std

    def msc(self, spectra):
        if spectra.shape[0] < spectra.shape[1]:
            corrected = MSC(spectra.T)
            return corrected.T
        else:
            return MSC(spectra)

    def mm_norm(self, spectra):
        min_vals = np.min(spectra, axis=0)
        max_vals = np.max(spectra, axis=0)
        return (spectra - min_vals) / (max_vals - min_vals)

    def l_norm(self, spectra, p):
        if p == "æ— ç©·å¤§":
            return LPnorm(spectra, np.inf)
        else:
            p_val = float(p)
            return LPnorm(spectra, p_val)

    def ma_minorm(self, spectra):
        return MaMinorm(spectra)

    def standardize(self, spectra):
        if spectra.shape[0] < spectra.shape[1]:
            standardized = plotst(spectra.T)
            return standardized.T
        else:
            return plotst(spectra)

    def d2(self, spectra):
        if spectra.shape[0] < spectra.shape[1]:
            diff_result = D2(spectra.T)
            return diff_result.T
        else:
            return D2(spectra)

# ===== æ–‡ä»¶å¤„ç†ç±» =====
class FileHandler:
    def load_data_from_zip(self, zip_file):
        with zipfile.ZipFile(zip_file, 'r') as zf:
            file_list = zf.namelist()

            wavenumber_files = [f for f in file_list if 'wave' in f.lower() or 'wn' in f.lower() or 'æ³¢æ•°' in f]
            data_files = [f for f in file_list if 'spec' in f.lower() or 'data' in f.lower() or 'å…‰è°±' in f]

            if not wavenumber_files:
                raise ValueError("å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°æ³¢æ•°æ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«'wave'ã€'wn'æˆ–'æ³¢æ•°'ï¼‰")
            if not data_files:
                raise ValueError("å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°å…‰è°±æ•°æ®æ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«'spec'ã€'data'æˆ–'å…‰è°±'ï¼‰")

            wn_file = wavenumber_files[0]
            data_file = data_files[0]

            with zf.open(wn_file) as f:
                wavenumbers = np.loadtxt(f).ravel()

            with zf.open(data_file) as f:
                content = f.read().decode("utf-8")
                data = self._parse_data(content)

            return wavenumbers, data.T

    def _parse_data(self, content):
        numb = re.compile(r"-?\d+(?:\.\d+)?")
        lines_list = content.splitlines()

        all_numbers = []
        for line in lines_list:
            all_numbers.extend(numb.findall(line))

        data = np.array([float(num) for num in all_numbers])

        n_rows = len(lines_list)
        n_cols = len(data) // n_rows if n_rows > 0 else 0

        if n_cols * n_rows != len(data):
            n_cols = len(data) // n_rows + 1
            data = data[:n_rows * n_cols]

        return data.reshape(n_rows, n_cols)

    def export_data(self, filename, data):
        with open(filename, "w") as f:
            for line in data.T:
                f.write("\t".join(map(str, line)) + "\n")

# è¾…åŠ©ç®—æ³•å‡½æ•°
def squashing(Data):
    row = Data.shape[0]
    col = Data.shape[1]
    sqData = np.zeros((row, col))
    for i in range(row):
        for j in range(col):
            sqData[i][j] = (1 - math.cos(Data[i][j] * math.pi)) / 2
    return sqData

def waveletlinear(arr, threshold=0.3):
    row = arr.shape[0]
    col = arr.shape[1]
    datarec = np.zeros((row, col))
    w = pywt.Wavelet('db8')
    for i in range(row):
        maxlev = pywt.dwt_max_level(col, w.dec_len)
        coeffs = pywt.wavedec(arr[i], 'db8', level=maxlev)
        for j in range(0, len(coeffs)):
            coeffs[j] = pywt.threshold(coeffs[j], threshold * max(coeffs[j]))
        datarec[i] = pywt.waverec(coeffs, 'db8')
    return datarec

def MWM(arr, n=7, it=1):
    row = arr.shape[0]
    col = arr.shape[1]
    median = np.zeros((row, col))
    ns = []
    for _ in range(it):
        ns.append(n)
        n -= 2
    for i in range(row):
        median[i] = arr[i].copy()
        nn = ns.copy()
        for _ in range(it):
            n = nn.pop()
            if n > 1:
                tmp = signal.medfilt(median[i], n)
                median[i] = tmp
    return median

def sigmoid(X):
    row = X.shape[0]
    col = X.shape[1]
    s = np.zeros((row, col))
    for i in range(row):
        for j in range(col):
            m = 1 + np.exp(-float(X[i, j]))
            s[i, j] = (1.0 / m)
    return s

def i_sigmoid(X, maxn=10):
    row = X.shape[0]
    col = X.shape[1]
    s = np.zeros((row, col))
    for i in range(row):
        mi = np.min(X[i])
        diff = (np.max(X[i]) - mi) / maxn
        for j in range(col):
            t = (X[i, j] - mi) / diff - maxn / 2
            m = 1 + np.exp(-float(t))
            t = 1.0 / m
            s[i, j] = t * diff * maxn + mi
    return s

def i_squashing(Data):
    row = Data.shape[0]
    col = Data.shape[1]
    sqData = np.zeros((row, col))
    for i in range(row):
        mi = np.min(Data[i])
        diff = np.max(Data[i]) - mi
        for j in range(col):
            t = (Data[i, j] - mi) / diff if diff != 0 else 0
            m = (1 - math.cos(t * math.pi)) / 2
            sqData[i][j] = m * diff + mi
    return sqData

def D2(sdata):
    row = sdata.shape[0]
    col = sdata.shape[1]
    D2_result = np.zeros((row, col))
    for i in range(row):
        tem = np.diff(sdata[i], 2)
        temp = tem.tolist()
        temp.append(temp[-1])
        temp.append(temp[-1])
        D2_result[i] = temp
    return D2_result

def LPnorm(arr, ord):
    row = arr.shape[0]
    col = arr.shape[1]
    Lpdata = np.zeros((row, col))
    for i in range(row):
        Lp = np.linalg.norm(arr[i, :], ord)
        if Lp != 0:
            Lpdata[i, :] = arr[i, :] / Lp
        else:
            Lpdata[i, :] = arr[i, :]
    return Lpdata

def MaMinorm(Oarr):
    row = Oarr.shape[0]
    col = Oarr.shape[1]
    MMarr = np.zeros((row, col))
    permax = np.ones((1, col))
    for i in range(row):
        diff = np.max(Oarr[i]) - np.min(Oarr[i])
        if diff != 0:
            MMarr[i] = ((Oarr[i] - permax * np.min(Oarr[i])) / diff) * 10 - 5
        else:
            MMarr[i] = Oarr[i] - permax * np.min(Oarr[i])
    return MMarr

def standardization(Datamat):
    mu = np.average(Datamat)
    sigma = np.std(Datamat)
    if sigma != 0:
        normDatamat = (Datamat - mu) / sigma
    else:
        normDatamat = Datamat - mu
    return normDatamat

def plotst(Data):
    row = Data.shape[0]
    col = Data.shape[1]
    st_Data = np.zeros((row, col))
    for i in range(row):
        st_Data[i] = standardization(Data[i])
    return st_Data

def Smfft(arr, row_e=51):
    row = arr.shape[0]
    col = arr.shape[1]
    fftresult = np.zeros((row, col))
    for i in range(row):
        sfft = fftpack_fft(arr[i])
        row_s = len(arr[i])
        sfftn = copy.deepcopy(sfft)
        sfftn[row_e:row_s - row_e] = 0
        result = fftpack_ifft(sfftn)
        real_r = np.real(result)
        fftresult[i] = real_r
    return fftresult

def MSC(sdata):
    n = sdata.shape[0]
    k = np.zeros(sdata.shape[0])
    b = np.zeros(sdata.shape[0])

    M = np.mean(sdata, axis=0)

    for i in range(n):
        y = sdata[i, :].reshape(-1, 1)
        M_reshaped = M.reshape(-1, 1)
        model = LinearRegression()
        model.fit(M_reshaped, y)
        k[i] = model.coef_
        b[i] = model.intercept_

    spec_msc = np.zeros_like(sdata)
    for i in range(n):
        bb = np.repeat(b[i], sdata.shape[1])
        kk = np.repeat(k[i], sdata.shape[1])
        spec_msc[i, :] = (sdata[i, :] - bb) / kk

    return spec_msc

def Kalman(z, R):
    n_iter = len(z)
    sz = (n_iter,)

    Q = 1e-5

    xhat = np.zeros(sz)
    P = np.zeros(sz)
    xhatminus = np.zeros(sz)
    Pminus = np.zeros(sz)
    K = np.zeros(sz)

    xhat[0] = 0.0
    P[0] = 1.0

    for k in range(1, n_iter):
        xhatminus[k] = xhat[k - 1]
        Pminus[k] = P[k - 1] + Q

        K[k] = Pminus[k] / (Pminus[k] + R)
        xhat[k] = xhatminus[k] + K[k] * (z[k] - xhatminus[k])
        P[k] = (1 - K[k]) * Pminus[k]

    return xhat

def KalmanF(xd, R):
    row = xd.shape[0]
    col = xd.shape[1]
    Fxd = np.zeros((row, col))
    for i in range(row):
        Fxd[i] = Kalman(xd[i], R)
    return Fxd

def IModPoly(wavenumbers, originalRaman, polyorder, max_iter=100, tolerance=0.005):
    row, col = originalRaman.shape
    corrected = np.zeros((row, col))

    for j in range(row):
        prev_spectrum = originalRaman[j]
        curr_spectrum = prev_spectrum.copy()
        prev_std = 0
        converged = False
        iteration = 1

        while not converged and iteration <= max_iter:
            coeffs = np.polyfit(wavenumbers, curr_spectrum, polyorder)
            fitted = np.polyval(coeffs, wavenumbers)
            residual = curr_spectrum - fitted
            curr_std = np.std(residual)

            if iteration == 1:
                mask = prev_spectrum > (fitted + curr_std)
                curr_spectrum[mask] = fitted[mask] + curr_std
            else:
                mask = prev_spectrum < (fitted + curr_std)
                curr_spectrum = np.where(mask, prev_spectrum, fitted + curr_std)

            relative_change = abs((curr_std - prev_std) / curr_std) if curr_std != 0 else 0
            converged = relative_change < tolerance

            prev_spectrum = curr_spectrum
            prev_std = curr_std
            iteration += 1

        corrected[j] = originalRaman[j] - fitted

    return corrected

def MWA(arr, n=6, it=1, mode="full"):
    row = arr.shape[0]
    col = arr.shape[1]
    average = np.zeros((row, col))
    ns = []
    for _ in range(it):
        ns.append(n)
        n -= 2
    for i in range(row):
        average[i] = arr[i].copy()
        nn = ns.copy()
        for _ in range(it):
            n = nn.pop()
            if n > 1:
                tmp = np.convolve(average[i], np.ones((n,)) / n, mode=mode)
                for j in range(1, n):
                    tmp[j - 1] = tmp[j - 1] * n / j
                    tmp[-j] = tmp[-j] * n / j
                j = int(n / 2)
                k = n - j - 1
                average[i] = tmp[j:-k]
    return average

def baseline_als(y, lam, p, niter=10, tol=1e-6):
    if np.any(np.isnan(y)):
        raise ValueError("è¾“å…¥æ•°æ®åŒ…å«NaNå€¼")

    y = np.asarray(y, dtype=np.float64)
    L = y.shape[1]
    D = sparse.csc_matrix(np.diff(np.eye(L), 2))
    result = np.zeros_like(y)

    for j in range(y.shape[0]):
        w = np.ones(L)
        y_curr = y[j].copy()

        for _ in range(niter):
            W = sparse.spdiags(w, 0, L, L)
            Z = W + lam * D.dot(D.transpose())
            z = spsolve(Z, w * y_curr)

            if np.max(np.abs(z - y_curr)) < tol:
                break

            w = p * (y[j] > z) + (1 - p) * (y[j] < z)
            y_curr = z

        result[j] = y[j] - z

    return result

class DTW:
    def __init__(self, dist_method='euclidean'):
        self.dist_method = dist_method

    def distance(self, x, y):
        if self.dist_method == 'euclidean':
            return np.linalg.norm(x - y)
        elif self.dist_method == 'manhattan':
            return np.sum(np.abs(x - y))
        else:
            return np.linalg.norm(x - y)

    def __call__(self, reference, query):
        n = len(reference)
        m = len(query)
        dtw_matrix = np.zeros((n + 1, m + 1))
        dtw_matrix[:, :] = np.inf
        dtw_matrix[0, 0] = 0

        for i in range(1, n + 1):
            for j in range(1, m + 1):
                cost = self.distance(reference[i - 1], query[j - 1])
                dtw_matrix[i, j] = cost + min(
                    dtw_matrix[i - 1, j],
                    dtw_matrix[i, j - 1],
                    dtw_matrix[i - 1, j - 1]
                )

        i, j = n, m
        path = []
        while i > 0 or j > 0:
            path.append((i - 1, j - 1))
            if i == 0:
                j -= 1
            elif j == 0:
                i -= 1
            else:
                min_val = min(dtw_matrix[i - 1, j], dtw_matrix[i, j - 1], dtw_matrix[i - 1, j - 1])
                if min_val == dtw_matrix[i - 1, j - 1]:
                    i -= 1
                    j -= 1
                elif min_val == dtw_matrix[i - 1, j]:
                    i -= 1
                else:
                    j -= 1

        return path[::-1], dtw_matrix[n, m]

def squashing_legacy(x):
    return 1 / (1 + np.exp(-x))

def SGfilter(Intensity, window_length,polyorder):
    Row = Intensity.shape[0]
    col = Intensity.shape[1]
    sgsmooth = np.zeros((Row, col))
    for i in range(Row):
        sgsmooth[i] = savgol_filter(Intensity[i], window_length, polyorder)
    return sgsmooth

def generate_permutations(algorithms):
    algorithm_list = [
        (1, "åŸºçº¿æ ¡å‡†", algorithms['baseline']),
        (2, "ç¼©æ”¾", algorithms['scaling']),
        (3, "æ»¤æ³¢", algorithms['filtering']),
        (4, "æŒ¤å‹", algorithms['squashing'])
    ]

    all_permutations = []
    all_permutations.append([])

    for algo in algorithm_list:
        if algo[2] != "æ— ":
            all_permutations.append([algo])

    for perm in itertools.permutations(algorithm_list, 2):
        if perm[0][2] != "æ— " and perm[1][2] != "æ— ":
            all_permutations.append(list(perm))

    for perm in itertools.permutations(algorithm_list, 3):
        if perm[0][2] != "æ— " and perm[1][2] != "æ— " and perm[2][2] != "æ— ":
            all_permutations.append(list(perm))

    for perm in itertools.permutations(algorithm_list, 4):
        if (perm[0][2] != "æ— " and perm[1][2] != "æ— " and
                perm[2][2] != "æ— " and perm[3][2] != "æ— "):
            all_permutations.append(list(perm))

    formatted_perms = []
    for i, perm in enumerate(all_permutations):
        perm_dict = {
            "name": "",
            "order": [],
            "details": perm,
            "count": len(perm),
            "first_step_type": "æœªçŸ¥"
        }

        if not perm:
            perm_dict["name"] = "æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"
            perm_dict["first_step_type"] = "æ— é¢„å¤„ç†"
        else:
            first_step_type = perm[0][1] if perm and len(perm) > 0 else "æœªçŸ¥"
            perm_dict["first_step_type"] = first_step_type

            perm_details = []
            for step in perm:
                perm_details.append(f"{step[0]}.{step[1]}({step[2]})")
            perm_dict["name"] = " â†’ ".join(perm_details)
            perm_dict["order"] = [step[0] for step in perm]

        formatted_perms.append(perm_dict)

    return formatted_perms

def main():
    # åˆå§‹åŒ–session state
    if 'show_arrangements' not in st.session_state:
        st.session_state.show_arrangements = False

    test_states = {
        'test_results': None,
        'labels': None,
        'train_indices': None,
        'test_indices': None
    }
    
    file_handler = FileHandler()
    preprocessor = Preprocessor()
    
    current_algorithms = {
        'baseline': 'æ— ',
        'baseline_params': {},
        'scaling': 'æ— ',
        'scaling_params': {},
        'filtering': 'æ— ',
        'filtering_params': {},
        'squashing': 'æ— ',
        'squashing_params': {}
    }

    st.session_state['current_algorithms'] = current_algorithms
    
    other_states = {
        'raw_data': None,
        'processed_data': None,
        'peaks': None,
        'train_test_split_ratio': 0.8,
        'arrangement_results': [],
        'selected_arrangement': None,
        'arrangement_details': {},
        'algorithm_permutations': [],
        'current_algorithms': {},
        'filtered_perms': [],
        'selected_perm_idx': 0
    }

    all_states = {**test_states, **other_states}
    for key, value in all_states.items():
        if key not in st.session_state:
            st.session_state[key] = value
    st.session_state['current_algorithms'] = current_algorithms

    # é¡µé¢è®¾ç½®
    st.set_page_config(layout="wide", page_icon="ğŸ”¬", page_title="æ’åˆ—é¢„å¤„ç†æ¨¡å‹")
    
    # ç´§å‡‘å¸ƒå±€æ ·å¼è°ƒæ•´
    st.markdown("""
        <style>
        .css-1v0mbdj {padding: 0.2rem 0.4rem !important;}
        .css-1d391kg {padding: 0.1rem 0 !important;}
        .css-12ttj6m {margin-bottom: 0.2rem !important;}
        .css-16huue1 {padding: 0.1rem 0.4rem !important; font-size: 0.8rem !important;}
        h3 {font-size: 1rem !important; margin: 0.2rem 0 !important;}
        .css-1b3298e {gap: 0.2rem !important;}
        .stSlider, .stSelectbox, .stTextInput {margin-bottom: 0.2rem !important;}
        .stCaption {font-size: 0.7rem !important; margin-top: -0.1rem !important;}
        .css-1544g2n {padding: 0.1rem 0.4rem !important;}
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸŒŒ æ’åˆ—é¢„å¤„ç†æ¨¡å‹")

    # é¡µé¢å¸ƒå±€ï¼šå·¦ä¾§æ•°æ®ç®¡ç†ï¼Œå³ä¾§ä¸»è¦å†…å®¹åŒº
    col_left, col_right = st.columns([1.2, 3.9])

    # ===== å·¦ä¾§ï¼šæ•°æ®ç®¡ç†æ¨¡å— =====
    with col_left:
        with st.expander("ğŸ“ æ•°æ®ç®¡ç†", expanded=True):
            zip_file = st.file_uploader("ä¸Šä¼ åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®çš„å‹ç¼©åŒ…", type=['zip'], key="zip_file")
            st.caption("å‹ç¼©åŒ…(.zip)éœ€åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®æ–‡ä»¶")

            st.subheader("æ ·æœ¬æ ‡ç­¾")
            num_classes = st.number_input("ç±»åˆ«æ•°é‡", min_value=1, value=2, step=1, key="num_cls")
            labels_input = st.text_input(
                "æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼Œä¸å…‰è°±é¡ºåºä¸€è‡´ï¼‰",
                placeholder="ä¾‹ï¼š0,0,1,1",
                key="labels_in"
            )

            st.subheader("è®­ç»ƒæµ‹è¯•åˆ’åˆ†")
            train_test_ratio = st.slider(
                "è®­ç»ƒé›†æ¯”ä¾‹",
                min_value=0.1,
                max_value=0.9,
                value=0.8,
                step=0.1,
                format="%.1f",
                key="train_ratio"
            )
            st.session_state.train_test_split_ratio = train_test_ratio

            if zip_file:
                try:
                    st.session_state.raw_data = file_handler.load_data_from_zip(
                        zip_file
                    )

                    if labels_input:
                        try:
                            labels = np.array([int(l.strip()) for l in labels_input.split(',')])
                            if len(labels) == st.session_state.raw_data[1].shape[1]:
                                st.session_state.labels = labels
                                n_samples = len(labels)
                                train_size = int(n_samples * train_test_ratio)
                                
                                np.random.seed(42)
                                indices = np.random.permutation(n_samples)
                                st.session_state.train_indices = indices[:train_size]
                                st.session_state.test_indices = indices[train_size:]
                                st.success(f"æ•°æ®åŠ è½½æˆåŠŸï¼æ ·æœ¬æ•°: {n_samples}, è®­ç»ƒé›†: {train_size}, æµ‹è¯•é›†: {n_samples - train_size}")
                            else:
                                st.error(f"æ ‡ç­¾æ•°é‡ä¸æ ·æœ¬æ•°é‡ä¸ç¬¦ï¼æ ‡ç­¾æ•°: {len(labels)}, æ ·æœ¬æ•°: {st.session_state.raw_data[1].shape[1]}")
                        except ValueError:
                            st.error("æ ‡ç­¾æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥é€—å·åˆ†éš”çš„æ•´æ•°")

                except Exception as e:
                    st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {str(e)}")

        # é¢„å¤„ç†å‚æ•°è®¾ç½®
        with st.expander("ğŸ”§ é¢„å¤„ç†å‚æ•°", expanded=True):
            st.subheader("åŸºçº¿æ ¡æ­£")
            baseline_method = st.selectbox(
                "é€‰æ‹©åŸºçº¿æ ¡æ­£æ–¹æ³•",
                ["æ— "] + list(preprocessor.BASELINE_ALGORITHMS.keys()),
                key="baseline_method"
            )
            baseline_params = {}
            
            if baseline_method == "å¤šé¡¹å¼æ‹Ÿåˆ":
                polyorder = st.slider("å¤šé¡¹å¼é˜¶æ•°", 1, 10, 3, key="polyorder")
                baseline_params["polyorder"] = polyorder
            elif baseline_method == "ModPoly":
                k = st.slider("è¿­ä»£æ¬¡æ•°", 1, 20, 5, key="modpoly_k")
                baseline_params["k"] = k
            elif baseline_method == "I-ModPoly":
                polyorder = st.slider("å¤šé¡¹å¼é˜¶æ•°", 1, 10, 3, key="imodpoly_order")
                max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 10, 500, 100, key="imodpoly_iter")
                tolerance = st.slider("æ”¶æ•›å®¹å·®", 0.001, 0.01, 0.005, 0.001, key="imodpoly_tol")
                baseline_params["polyorder"] = polyorder
                baseline_params["max_iter"] = max_iter
                baseline_params["tolerance"] = tolerance
            elif baseline_method == "PLS":
                lam = st.slider("å¹³æ»‘ç³»æ•° (1e4-1e9)", 1e4, 1e9, 1e5, key="pls_lam")
                baseline_params["lam"] = lam
            elif baseline_method == "AsLS":
                lam = st.slider("å¹³æ»‘ç³»æ•° (1e5-1e12)", 1e5, 1e12, 1e5, key="asls_lam")
                p = st.slider("éå¯¹ç§°ç³»æ•° (0.001-0.1)", 0.001, 0.1, 0.001, key="asls_p")
                baseline_params["lam"] = lam
                baseline_params["p"] = p
            elif baseline_method == "airPLS":
                lam = st.slider("å¹³æ»‘ç³»æ•° (1e5-1e12)", 1e5, 1e12, 1e5, key="airpls_lam")
                max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 5, 50, 15, key="airpls_iter")
                baseline_params["lam"] = lam
                baseline_params["max_iter"] = max_iter

            st.subheader("æŒ¤å‹ç®—æ³•")
            squashing_method = st.selectbox(
                "é€‰æ‹©æŒ¤å‹æ–¹æ³•",
                ["æ— "] + list(preprocessor.SQUASHING_ALGORITHMS.keys()),
                key="squashing_method"
            )
            squashing_params = {}
            
            if squashing_method == "æ”¹è¿›çš„SigmoidæŒ¤å‹":
                maxn = st.slider("åˆ†æ®µæ•°", 5, 20, 10, key="sigmoid_maxn")
                squashing_params["maxn"] = maxn
            elif squashing_method == "DTWæŒ¤å‹":
                l = st.slider("çª—å£å¤§å°", 1, 10, 1, key="dtw_l")
                k1 = st.radio("å¯ç”¨æ–œç‡é™åˆ¶", ["T", "F"], key="dtw_k1")
                k2 = st.radio("å¯ç”¨çª—å£å¹³æ»‘", ["T", "F"], key="dtw_k2")
                squashing_params["l"] = l
                squashing_params["k1"] = k1
                squashing_params["k2"] = k2

            st.subheader("æ»¤æ³¢ç®—æ³•")
            filtering_method = st.selectbox(
                "é€‰æ‹©æ»¤æ³¢æ–¹æ³•",
                ["æ— "] + list(preprocessor.FILTERING_ALGORITHMS.keys()),
                key="filtering_method"
            )
            filtering_params = {}
            
            if filtering_method in ["Savitzky-Golay", "sgolayfiltæ»¤æ³¢å™¨"]:
                window_length = st.slider("çª—å£é•¿åº¦ï¼ˆå¥‡æ•°ï¼‰", 3, 21, 5, 2, key="sg_window")
                polyorder = st.slider("å¤šé¡¹å¼é˜¶æ•°", 1, 5, 2, key="sg_order")
                filtering_params["window_length"] = window_length
                filtering_params["polyorder"] = polyorder
            elif filtering_method == "ä¸­å€¼æ»¤æ³¢(MF)":
                k = st.slider("å‚æ•°k", 1, 10, 2, key="mf_k")
                w = st.slider("çª—å£å¤§å°ï¼ˆå¥‡æ•°ï¼‰", 3, 21, 5, 2, key="mf_window")
                filtering_params["k"] = k
                filtering_params["w"] = w
            elif filtering_method in ["ç§»åŠ¨å¹³å‡(MAF)", "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰"]:
                k = st.slider("å‚æ•°k", 1, 10, 2, key="ma_k")
                w = st.slider("çª—å£å¤§å°", 3, 21, 5, key="ma_window")
                filtering_params["k"] = k
                filtering_params["w"] = w
                if filtering_method == "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰":
                    it = st.slider("è¿­ä»£æ¬¡æ•°", 1, 5, 1, key="mwa_it")
                    filtering_params["it"] = it
            elif filtering_method == "MWMï¼ˆç§»åŠ¨çª—å£ä¸­å€¼ï¼‰":
                n = st.slider("çª—å£å¤§å°ï¼ˆå¥‡æ•°ï¼‰", 3, 21, 7, 2, key="mwm_n")
                it = st.slider("è¿­ä»£æ¬¡æ•°", 1, 5, 1, key="mwm_it")
                filtering_params["n"] = n
                filtering_params["it"] = it
            elif filtering_method == "å¡å°”æ›¼æ»¤æ³¢":
                R = st.slider("æµ‹é‡å™ªå£°æ–¹å·®", 0.01, 1.0, 0.1, key="kalman_R")
                filtering_params["R"] = R
            elif filtering_method == "Lowess":
                frac = st.slider("å¹³æ»‘ç³»æ•°", 0.01, 0.5, 0.1, key="lowess_frac")
                filtering_params["frac"] = frac
            elif filtering_method == "FFT":
                cutoff = st.slider("æˆªæ­¢é¢‘ç‡", 0.01, 0.5, 0.1, key="fft_cutoff")
                filtering_params["cutoff"] = cutoff
            elif filtering_method == "Smfftå‚…é‡Œå¶æ»¤æ³¢":
                row_e = st.slider("ä¿ç•™ä½é¢‘åˆ†é‡æ•°", 10, 100, 51, key="smfft_row_e")
                filtering_params["row_e"] = row_e
            elif filtering_method == "å°æ³¢å˜æ¢(DWT)":
                threshold = st.slider("é˜ˆå€¼", 0.01, 1.0, 0.3, key="dwt_threshold")
                filtering_params["threshold"] = threshold
            elif filtering_method == "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª":
                threshold = st.slider("é˜ˆå€¼", 0.01, 1.0, 0.3, key="wavelet_threshold")
                filtering_params["threshold"] = threshold

            st.subheader("ç¼©æ”¾ç®—æ³•")
            scaling_method = st.selectbox(
                "é€‰æ‹©ç¼©æ”¾æ–¹æ³•",
                ["æ— "] + list(preprocessor.SCALING_ALGORITHMS.keys()),
                key="scaling_method"
            )
            scaling_params = {}
            
            if scaling_method == "L-èŒƒæ•°":
                p = st.selectbox(
                    "èŒƒæ•°é˜¶æ•°",
                    ["1", "2", "æ— ç©·å¤§"],
                    key="lp_p"
                )
                scaling_params["p"] = p

            st.session_state.current_algorithms = {
                'baseline': baseline_method,
                'baseline_params': baseline_params,
                'scaling': scaling_method,
                'scaling_params': scaling_params,
                'filtering': filtering_method,
                'filtering_params': filtering_params,
                'squashing': squashing_method,
                'squashing_params': squashing_params
            }

            st.subheader("ç®—æ³•é¡ºåº")
            algorithm_order = st.multiselect(
                "é€‰æ‹©é¢„å¤„ç†æ­¥éª¤é¡ºåºï¼ˆæœ€å¤š4æ­¥ï¼‰",
                [1, 2, 3, 4],
                format_func=lambda x: {
                    1: "1. åŸºçº¿æ ¡å‡†",
                    2: "2. ç¼©æ”¾",
                    3: "3. æ»¤æ³¢",
                    4: "4. æŒ¤å‹"
                }[x],
                key="algorithm_order"
            )

            if st.button("ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„é¢„å¤„ç†æ’åˆ—", key="generate_perms"):
                try:
                    perms = generate_permutations(st.session_state.current_algorithms)
                    st.session_state.algorithm_permutations = perms
                    st.session_state.filtered_perms = perms
                    st.success(f"å·²ç”Ÿæˆ {len(perms)} ç§é¢„å¤„ç†æ’åˆ—æ–¹æ¡ˆ")
                    st.session_state.show_arrangements = True
                except Exception as e:
                    st.error(f"ç”Ÿæˆæ’åˆ—å¤±è´¥: {str(e)}")

            if st.session_state.algorithm_permutations:
                first_step_filter = st.selectbox(
                    "æŒ‰ç¬¬ä¸€æ­¥ç­›é€‰",
                    ["å…¨éƒ¨"] + list(set(p.get("first_step_type", "æœªçŸ¥") for p in st.session_state.algorithm_permutations)),
                    key="first_step_filter"
                )
                
                if first_step_filter != "å…¨éƒ¨":
                    st.session_state.filtered_perms = [
                        p for p in st.session_state.algorithm_permutations 
                        if p.get("first_step_type", "æœªçŸ¥") == first_step_filter
                    ]
                else:
                    st.session_state.filtered_perms = st.session_state.algorithm_permutations
                
                st.write(f"ç­›é€‰å: {len(st.session_state.filtered_perms)} ç§æ–¹æ¡ˆ")

        # KNNåˆ†ç±»å‚æ•°
        with st.expander("ğŸ” KNNåˆ†ç±»å‚æ•°", expanded=True):
            st.slider("Kå€¼ï¼ˆè¿‘é‚»æ•°é‡ï¼‰", 1, 20, 5, key="k_value")
            
            if st.button("è¿è¡ŒKNNåˆ†ç±»", key="run_knn") and st.session_state.raw_data is not None:
                if st.session_state.labels is None:
                    st.error("è¯·è¾“å…¥æ ·æœ¬æ ‡ç­¾")
                else:
                    try:
                        wavenumbers, raw_spectra = st.session_state.raw_data
                        current_algos = st.session_state.current_algorithms
                        
                        processed_spectra, _ = preprocessor.process(
                            wavenumbers,
                            raw_spectra,
                            baseline_method=current_algos['baseline'],
                            baseline_params=current_algos['baseline_params'],
                            squashing_method=current_algos['squashing'],
                            squashing_params=current_algos['squashing_params'],
                            filtering_method=current_algos['filtering'],
                            filtering_params=current_algos['filtering_params'],
                            scaling_method=current_algos['scaling'],
                            scaling_params=current_algos['scaling_params'],
                            algorithm_order=algorithm_order
                        )
                        
                        train_data = processed_spectra[:, st.session_state.train_indices]
                        test_data = processed_spectra[:, st.session_state.test_indices]
                        train_labels = st.session_state.labels[st.session_state.train_indices]
                        test_labels = st.session_state.labels[st.session_state.test_indices]
                        
                        predictions = knn_classify(train_data, train_labels, test_data, k=st.session_state.k_value)
                        
                        accuracy = accuracy_score(test_labels, predictions)
                        kappa = cohen_kappa_score(test_labels, predictions)
                        cm = confusion_matrix(test_labels, predictions)
                        
                        st.session_state.test_results = {
                            'predictions': predictions,
                            'test_labels': test_labels,
                            'accuracy': accuracy,
                            'kappa': kappa,
                            'cm': cm
                        }
                        
                        st.success(f"KNNåˆ†ç±»å®Œæˆï¼å‡†ç¡®ç‡: {accuracy:.4f}, Kappaç³»æ•°: {kappa:.4f}")
                    except Exception as e:
                        st.error(f"åˆ†ç±»å¤±è´¥: {str(e)}")

    # ===== å³ä¾§ï¼šä¸»è¦å†…å®¹åŒº =====
    with col_right:
        st.subheader("ğŸ“Š å…‰è°±å¯è§†åŒ–")
        
        # ç´§å‡‘çš„å››å›¾å¸ƒå±€
        col1, col2 = st.columns(2)
        col3, col4 = st.columns(2)
        
        has_data = st.session_state.raw_data is not None
        has_processed_data = st.session_state.processed_data is not None
        has_test_results = st.session_state.test_results is not None
        
        # 1. åŸå§‹å…‰è°±åŒºåŸŸ
        with col1:
            st.markdown("**1. åŸå§‹å…‰è°±**")
            # æ›´ç´§å‡‘çš„å›¾è¡¨å°ºå¯¸
            fig1, ax1 = plt.subplots(figsize=(4.5, 2.5))
            
            if has_data:
                wavenumbers, raw_spectra = st.session_state.raw_data
                num_to_plot = min(10, raw_spectra.shape[1])
                ax1.plot(wavenumbers, raw_spectra[:, :num_to_plot])
                ax1.set_xlabel('æ³¢æ•°', fontsize=8)
                ax1.set_ylabel('å¼ºåº¦', fontsize=8)
                ax1.set_title(f'åŸå§‹å…‰è°±ï¼ˆå‰{num_to_plot}æ¡ï¼‰', fontsize=9)
                ax1.tick_params(axis='both', which='major', labelsize=7)
                plt.tight_layout()
            else:
                ax1.text(0.5, 0.5, 'æœªå¯¼å…¥æ•°æ®', ha='center', va='center', transform=ax1.transAxes, color='gray')
                ax1.set_xticks([])
                ax1.set_yticks([])
            
            st.pyplot(fig1)
        
        # 2. é¢„å¤„ç†åå…‰è°±åŒºåŸŸ
        with col2:
            st.markdown("**2. é¢„å¤„ç†åå…‰è°±**")
            fig2, ax2 = plt.subplots(figsize=(4.5, 2.5))
            
            if has_processed_data:
                wavenumbers, _ = st.session_state.raw_data
                processed_spectra = st.session_state.processed_data
                num_to_plot = min(10, processed_spectra.shape[1])
                ax2.plot(wavenumbers, processed_spectra[:, :num_to_plot])
                ax2.set_xlabel('æ³¢æ•°', fontsize=8)
                ax2.set_ylabel('å¼ºåº¦', fontsize=8)
                ax2.set_title(f'é¢„å¤„ç†åå…‰è°±ï¼ˆå‰{num_to_plot}æ¡ï¼‰', fontsize=9)
                ax2.tick_params(axis='both', which='major', labelsize=7)
                plt.tight_layout()
            else:
                ax2.text(0.5, 0.5, 'æœªè¿›è¡Œé¢„å¤„ç†', ha='center', va='center', transform=ax2.transAxes, color='gray')
                ax2.set_xticks([])
                ax2.set_yticks([])
            
            st.pyplot(fig2)
        
        # 3. Kå€¼æ›²çº¿åŒºåŸŸ
        with col3:
            st.markdown("**3. Kå€¼æ›²çº¿**")
            fig3, ax3 = plt.subplots(figsize=(4.5, 2.5))
            
            if has_test_results and has_data:
                k_values = range(1, 21)
                accuracies = []
                
                wavenumbers, raw_spectra = st.session_state.raw_data
                current_algos = st.session_state.current_algorithms
                
                processed_spectra, _ = preprocessor.process(
                    wavenumbers,
                    raw_spectra,
                    baseline_method=current_algos['baseline'],
                    baseline_params=current_algos['baseline_params'],
                    squashing_method=current_algos['squashing'],
                    squashing_params=current_algos['squashing_params'],
                    filtering_method=current_algos['filtering'],
                    filtering_params=current_algos['filtering_params'],
                    scaling_method=current_algos['scaling'],
                    scaling_params=current_algos['scaling_params'],
                    algorithm_order=algorithm_order
                )
                
                train_data = processed_spectra[:, st.session_state.train_indices]
                test_data = processed_spectra[:, st.session_state.test_indices]
                train_labels = st.session_state.labels[st.session_state.train_indices]
                test_labels = st.session_state.labels[st.session_state.test_indices]
                
                for k in k_values:
                    predictions = knn_classify(train_data, train_labels, test_data, k=k)
                    accuracies.append(accuracy_score(test_labels, predictions))
                
                ax3.plot(k_values, accuracies, 'o-', markersize=3, linewidth=1)
                ax3.set_xlabel('Kå€¼', fontsize=8)
                ax3.set_ylabel('å‡†ç¡®ç‡', fontsize=8)
                ax3.set_title('Kå€¼ä¸å‡†ç¡®ç‡å…³ç³»', fontsize=9)
                ax3.grid(True, linestyle='--', alpha=0.7)
                ax3.tick_params(axis='both', which='major', labelsize=7)
                plt.tight_layout()
            else:
                ax3.text(0.5, 0.5, 'æœªè¿›è¡Œåˆ†ç±»æµ‹è¯•', ha='center', va='center', transform=ax3.transAxes, color='gray')
                ax3.set_xticks([])
                ax3.set_yticks([])
            
            st.pyplot(fig3)
        
        # 4. æ··æ·†çŸ©é˜µåŒºåŸŸ
        with col4:
            st.markdown("**4. æ··æ·†çŸ©é˜µ**")
            fig4, ax4 = plt.subplots(figsize=(4.5, 2.5))
            
            if has_test_results:
                cm = st.session_state.test_results['cm']
                classes = np.unique(st.session_state.test_results['test_labels'])
                
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4, 
                           xticklabels=classes, yticklabels=classes, annot_kws={"size": 8})
                ax4.set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=8)
                ax4.set_ylabel('çœŸå®æ ‡ç­¾', fontsize=8)
                ax4.set_title('æ··æ·†çŸ©é˜µ', fontsize=9)
                ax4.tick_params(axis='both', which='major', labelsize=7)
                plt.tight_layout()
            else:
                ax4.text(0.5, 0.5, 'æœªè¿›è¡Œåˆ†ç±»æµ‹è¯•', ha='center', va='center', transform=ax4.transAxes, color='gray')
                ax4.set_xticks([])
                ax4.set_yticks([])
            
            st.pyplot(fig4)

        # é¢„å¤„ç†æ‰§è¡ŒåŒºåŸŸ
        with st.expander("â–¶ï¸ æ‰§è¡Œé¢„å¤„ç†", expanded=True):
            if st.button("è¿è¡Œå½“å‰é¢„å¤„ç†", key="run_preprocessing") and st.session_state.raw_data is not None:
                try:
                    wavenumbers, raw_spectra = st.session_state.raw_data
                    current_algos = st.session_state.current_algorithms
                    
                    processed_spectra, method_names = preprocessor.process(
                        wavenumbers,
                        raw_spectra,
                        baseline_method=current_algos['baseline'],
                        baseline_params=current_algos['baseline_params'],
                        squashing_method=current_algos['squashing'],
                        squashing_params=current_algos['squashing_params'],
                        filtering_method=current_algos['filtering'],
                        filtering_params=current_algos['filtering_params'],
                        scaling_method=current_algos['scaling'],
                        scaling_params=current_algos['scaling_params'],
                        algorithm_order=algorithm_order
                    )
                    
                    st.session_state.processed_data = processed_spectra
                    st.success(f"é¢„å¤„ç†å®Œæˆï¼æ­¥éª¤: {', '.join(method_names)}")
                except Exception as e:
                    st.error(f"é¢„å¤„ç†å¤±è´¥: {str(e)}")

        # æ’åˆ—ç»“æœå±•ç¤ºåŒºåŸŸ
        if st.session_state.show_arrangements and st.session_state.filtered_perms:
            with st.expander("ğŸ“‹ é¢„å¤„ç†æ’åˆ—ç»“æœ", expanded=True):
                perm_names = [p["name"] for p in st.session_state.filtered_perms]
                selected_perm_idx = st.selectbox(
                    "é€‰æ‹©é¢„å¤„ç†æ’åˆ—æ–¹æ¡ˆ",
                    range(len(perm_names)),
                    format_func=lambda i: f"{i+1}. {perm_names[i]}",
                    key="selected_perm"
                )
                st.session_state.selected_perm_idx = selected_perm_idx
                
                selected_perm = st.session_state.filtered_perms[selected_perm_idx]
                st.write(f"**é€‰ä¸­æ–¹æ¡ˆ**: {selected_perm['name']}")
                st.write(f"**æ­¥éª¤æ•°é‡**: {selected_perm['count']}")
                
                if st.button("æ‰§è¡Œé€‰ä¸­çš„æ’åˆ—æ–¹æ¡ˆ", key="run_selected_perm") and st.session_state.raw_data is not None:
                    try:
                        wavenumbers, raw_spectra = st.session_state.raw_data
                        current_algos = st.session_state.current_algorithms
                        
                        processed_spectra, method_names = preprocessor.process(
                            wavenumbers,
                            raw_spectra,
                            baseline_method=current_algos['baseline'],
                            baseline_params=current_algos['baseline_params'],
                            squashing_method=current_algos['squashing'],
                            squashing_params=current_algos['squashing_params'],
                            filtering_method=current_algos['filtering'],
                            filtering_params=current_algos['filtering_params'],
                            scaling_method=current_algos['scaling'],
                            scaling_params=current_algos['scaling_params'],
                            algorithm_order=selected_perm["order"]
                        )
                        
                        st.session_state.processed_data = processed_spectra
                        st.session_state.selected_arrangement = selected_perm
                        st.success(f"æ’åˆ—é¢„å¤„ç†å®Œæˆï¼æ­¥éª¤: {', '.join(method_names)}")
                    except Exception as e:
                        st.error(f"æ’åˆ—é¢„å¤„ç†å¤±è´¥: {str(e)}")

        # ç»“æœåˆ†æåŒºåŸŸ
        with st.expander("ğŸ“ˆ ç»“æœåˆ†æ", expanded=True):
            if st.session_state.test_results:
                results = st.session_state.test_results
                st.write(f"**å‡†ç¡®ç‡**: {results['accuracy']:.4f}")
                st.write(f"**Kappaç³»æ•°**: {results['kappa']:.4f}")
                
                comparison = pd.DataFrame({
                    'çœŸå®æ ‡ç­¾': results['test_labels'],
                    'é¢„æµ‹æ ‡ç­¾': results['predictions']
                })
                st.write("**é¢„æµ‹ç»“æœå¯¹æ¯”**:")
                st.dataframe(comparison)
            else:
                st.info("è¯·å…ˆè¿è¡ŒKNNåˆ†ç±»ä»¥æŸ¥çœ‹ç»“æœåˆ†æ")

if __name__ == "__main__":
    main()
    
