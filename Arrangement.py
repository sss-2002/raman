import streamlit as st
import numpy as np
import pandas as pd
import re
import itertools
import matplotlib.pyplot as plt
import math
import zipfile
import os
from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix
import seaborn as sns
from scipy import sparse
from scipy.sparse.linalg import spsolve
from scipy.signal import savgol_filter, medfilt
from scipy.fft import fft, ifft
from scipy.fftpack import fft as fftpack_fft, ifft as fftpack_ifft
import copy
from statsmodels.nonparametric.smoothers_lowess import lowess
import pywt
from sklearn.linear_model import LinearRegression  # ç”¨äºMSC
import scipy.signal as signal  # å¯¼å…¥scipy.signalç”¨äºMWMå‡½æ•°
import csv
from sklearn.linear_model import Perceptron
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import itertools

cloud_storage_dir = "/mnt/data/processed_spectra"  # ä¸´æ—¶ç›®å½•ï¼Œç”¨äºå­˜å‚¨æ–‡ä»¶


# ===== ç®—æ³•å®ç° =====
def polynomial_fit(wavenumbers, spectra, polyorder):
    """å¤šé¡¹å¼æ‹ŸåˆåŸºçº¿æ ¡æ­£"""
    baseline = np.zeros_like(spectra)
    for i in range(spectra.shape[1]):
        coeffs = np.polyfit(wavenumbers, spectra[:, i], deg=polyorder)
        baseline[:, i] = np.polyval(coeffs, wavenumbers)
    return spectra - baseline  # æ‰£é™¤åŸºçº¿


def modpoly(wavenumbers, spectra, k):
    """Modified Polynomial (ModPoly) åŸºçº¿æ ¡æ­£"""


    # ç¡®ä¿ spectra æ˜¯äºŒç»´æ•°ç»„
    if spectra.ndim == 1:
        spectra = spectra.reshape(1, -1)  # å°†å…¶å˜ä¸º 1 Ã— 20 çš„æ•°ç»„

    baseline = np.zeros_like(spectra)
    n_points = len(wavenumbers)

    # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
    # st.write(f"[CHECK] n_points: {n_points}, spectra shape: {spectra.shape}")

    # éå†æ¯ä¸ªæ ·æœ¬çš„å…‰è°±
    for i in range(spectra.shape[0]):  # spectra.shape[0] ä¸ºæ ·æœ¬æ•°é‡
        y = spectra[i, :].copy()  # æ¯ä¸ªæ ·æœ¬çš„å…‰è°±

        # è¾“å‡ºå½“å‰å…‰è°±ä¿¡æ¯
        # st.write(f"[CHECK] Processing spectrum {i+1}, shape: {y.shape}")

        # å¯¹æ¯ä¸ªå…‰è°±åº”ç”¨å¤šé¡¹å¼æ‹Ÿåˆ
        for _ in range(k):
            coeffs = np.polyfit(wavenumbers, y, deg=5)
            fitted = np.polyval(coeffs, wavenumbers)

            # è¾“å‡ºæ‹Ÿåˆç»“æœ
            # st.write(f"[CHECK] Fitted values: {fitted[:2]}")  # åªæ˜¾ç¤ºå‰5ä¸ªå€¼
            mask = y < fitted
            y[~mask] = fitted[~mask]

        # å°†ä¿®æ­£åçš„å…‰è°±æ·»åŠ åˆ°åŸºçº¿çŸ©é˜µ
        baseline[i, :] = y

    return spectra - baseline

def pls(spectra, lam):
    """Penalized Least Squares (PLS) åŸºçº¿æ ¡æ­£"""
    n_points = spectra.shape[0]
    baseline = np.zeros_like(spectra)
    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(n_points, n_points - 2))
    D = lam * D.dot(D.transpose())
    for i in range(spectra.shape[1]):
        y = spectra[:, i]
        A = sparse.eye(n_points) + D
        baseline[:, i] = spsolve(A, y)
    return spectra - baseline


def airpls(spectra, lam, max_iter=15, threshold=0.001):
    """Adaptive Iteratively Reweighted Penalized Least Squares (airPLS) åŸºçº¿æ ¡æ­£"""
    n_points = spectra.shape[0]
    baseline = np.zeros_like(spectra)
    D = sparse.diags([1, -2, 1], [0, -1, -2], shape=(n_points, n_points - 2))
    D = lam * D.dot(D.transpose())
    for i in range(spectra.shape[1]):
        y = spectra[:, i]
        w = np.ones(n_points)
        baseline_i = np.zeros(n_points)
        for j in range(max_iter):
            W = sparse.diags(w, 0)
            Z = W + D
            b = spsolve(Z, W * y)
            d = y - b
            neg_mask = d < 0
            w[neg_mask] = np.exp(j * np.abs(d[neg_mask]) / np.std(d[neg_mask]))
            w[~neg_mask] = 0
            if j > 0:
                diff = np.sum(np.abs(b - baseline_i)) / np.sum(np.abs(baseline_i)) if np.sum(
                    np.abs(baseline_i)) > 0 else 0
                if diff < threshold:
                    break
            baseline_i = b
        baseline[:, i] = baseline_i
    return spectra - baseline


def dtw_squashing(x, l, k1, k2):
    """åŠ¨æ€æ—¶é—´è§„æ•´(DTW)æŒ¤å‹ç®—æ³•"""
    n_samples, n_features = x.shape
    result = np.zeros_like(x)
    reference = np.mean(x, axis=1)  # ä½¿ç”¨å¹³å‡å…‰è°±ä½œä¸ºå‚è€ƒ
    dtw = DTW()

    for i in range(n_features):
        spectrum = x[:, i]
        path, cost = dtw(reference, spectrum)
        squashed = np.zeros_like(spectrum)
        for ref_idx, spec_idx in path:
            squashed[ref_idx] += spectrum[spec_idx]
        unique_ref_indices = np.unique([p[0] for p in path])
        for idx in unique_ref_indices:
            count = sum(1 for p in path if p[0] == idx)
            squashed[idx] /= count
        if k1 == "T":
            max_slope = l
            for j in range(1, len(path)):
                ref_diff = path[j][0] - path[j - 1][0]
                spec_diff = path[j][1] - path[j - 1][1]
                if ref_diff != 0:
                    slope = abs(spec_diff / ref_diff)
                    if slope > max_slope:
                        squashed[path[j][0]] = (squashed[path[j][0]] + squashed[path[j - 1][0]]) / 2
        if k2 == "T":
            ref_map_count = {}
            for ref_idx, _ in path:
                ref_map_count[ref_idx] = ref_map_count.get(ref_idx, 0) + 1
                for ref_idx, count in ref_map_count.items():
                    if count > l:
                        window = min(l, len(spectrum))
                        start = max(0, ref_idx - window // 2)
                        end = min(n_samples, ref_idx + window // 2 + 1)
                        squashed[ref_idx] = np.mean(spectrum[start:end])
        if l > 1:
            for j in range(n_samples):
                start = max(0, j - l)
                end = min(n_samples, j + l + 1)
                squashed[j] = np.mean(squashed[start:end])
        result[:, i] = squashed
    return result


# ===== åˆ†ç±»ç®—æ³•å®ç° =====
def knn_classify(train_data, train_labels, test_data, k=5):
    """Kè¿‘é‚»åˆ†ç±»ç®—æ³•å®ç°"""
    # è½¬ç½®æ•°æ®ä»¥é€‚åº”æ ·æœ¬æ•°Ã—ç‰¹å¾æ•°çš„æ ¼å¼
    train_data = train_data.T
    test_data = test_data.T

    predictions = []
    for test_sample in test_data:
        # è®¡ç®—ä¸æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„æ¬§æ°è·ç¦»
        distances = np.sqrt(np.sum((train_data - test_sample) ** 2, axis=1))
        # è·å–æœ€è¿‘çš„kä¸ªæ ·æœ¬çš„ç´¢å¼•
        k_indices = np.argsort(distances)[:k]
        # è·å–è¿™äº›æ ·æœ¬çš„æ ‡ç­¾
        k_nearest_labels = [train_labels[i] for i in k_indices]
        # å¤šæ•°æŠ•ç¥¨å†³å®šé¢„æµ‹æ ‡ç­¾
        most_common = np.bincount(k_nearest_labels).argmax()
        predictions.append(most_common)
    return np.array(predictions)


# ===== é¢„å¤„ç†ç±» =====
class Preprocessor:
    def __init__(self):
        self.BASELINE_ALGORITHMS = {
            "SD": self._sd_baseline,
            "FD": self._fd_baseline,
            "å¤šé¡¹å¼æ‹Ÿåˆ": polynomial_fit,
            "ModPoly": modpoly,
            "I-ModPoly": IModPoly,  # é›†æˆIModPolyç®—æ³•
            "PLS": pls,
            "AsLS": baseline_als,  # ä½¿ç”¨æ”¹è¿›çš„AsLSç®—æ³•
            "airPLS": airpls,
            "äºŒé˜¶å·®åˆ†(D2)": self.d2  # å°†äºŒé˜¶å·®åˆ†å½’ç±»åˆ°åŸºçº¿æ ¡å‡†ä¸­
        }
        self.FILTERING_ALGORITHMS = {
            "Savitzky-Golay": self.savitzky_golay,
            "sgolayfiltæ»¤æ³¢å™¨": self.sgolay_filter_custom,  # æ·»åŠ è‡ªå®šä¹‰SGæ»¤æ³¢å™¨
            "ä¸­å€¼æ»¤æ³¢(MF)": self.median_filter,
            "ç§»åŠ¨å¹³å‡(MAF)": self.moving_average,
            "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰": self.mwa_filter,  # æ·»åŠ MWAç®—æ³•
            "MWMï¼ˆç§»åŠ¨çª—å£ä¸­å€¼ï¼‰": self.mwm_filter,  # MWMæ»¤æ³¢ç®—æ³•
            "å¡å°”æ›¼æ»¤æ³¢": self.kalman_filter,  # æ·»åŠ å¡å°”æ›¼æ»¤æ³¢ç®—æ³•
            "Lowess": self.lowess_filter,
            "FFT": self.fft_filter,
            "Smfftå‚…é‡Œå¶æ»¤æ³¢": self.smfft_filter,  # æ·»åŠ Smfftå‚…é‡Œå¶æ»¤æ³¢
            "å°æ³¢å˜æ¢(DWT)": self.wavelet_filter,
            "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª": self.wavelet_linear  # æ–°å¢ï¼šå°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª
        }

        self.SCALING_ALGORITHMS = {
            "Peak-Norm": self.peak_norm,
            "SNV": self.snv,
            "MSC": self.msc,  # ä½¿ç”¨æ–°çš„MSCå®ç°
            "M-M-Norm": self.mm_norm,
            "L-èŒƒæ•°": self.l_norm,  # ä½¿ç”¨LPnormå‡½æ•°å®ç°
            "Ma-Minorm": self.ma_minorm,  # æ·»åŠ Ma-Minormå½’ä¸€åŒ–
            "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)": self.standardize  # æ·»åŠ æ ‡å‡†åŒ–ç®—æ³•
        }

        self.SQUASHING_ALGORITHMS = {
            "SigmoidæŒ¤å‹": sigmoid,  # ä½¿ç”¨sigmoidå‡½æ•°
            "æ”¹è¿›çš„SigmoidæŒ¤å‹": i_sigmoid,  # ä½¿ç”¨æ”¹è¿›çš„i_sigmoidå‡½æ•°
            "é€»è¾‘å‡½æ•°": squashing_legacy,  # ä¿ç•™åŸé€»è¾‘å‡½æ•°ä»¥ä¾¿å¯¹æ¯”
            "ä½™å¼¦æŒ¤å‹(squashing)": squashing,  # æ–°å¢ï¼šåŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢
            "æ”¹è¿›çš„é€»è¾‘å‡½æ•°": i_squashing,  # ä½¿ç”¨i_squashingå‡½æ•°
            "DTWæŒ¤å‹": dtw_squashing
        }

    def process(self, wavenumbers, data,
                baseline_method="æ— ", baseline_params=None,
                squashing_method="æ— ", squashing_params=None,
                filtering_method="æ— ", filtering_params=None,
                scaling_method="æ— ", scaling_params=None,
                algorithm_order=None):
        """æ‰§è¡Œé¢„å¤„ç†æµç¨‹ï¼Œæ”¯æŒæŒ‡å®šç®—æ³•é¡ºåºï¼Œç©ºé¡ºåºè¡¨ç¤ºè¿”å›åŸå§‹æ•°æ®"""

        if baseline_params is None: baseline_params = {}
        if squashing_params is None: squashing_params = {}
        if filtering_params is None: filtering_params = {}
        if scaling_params is None: scaling_params = {}

        # å¦‚æœç®—æ³•é¡ºåºä¸ºç©ºï¼ˆæ— é¢„å¤„ç†ï¼‰ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
        if algorithm_order is not None and len(algorithm_order) == 0:
            return data.copy(), ["æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"]

        y_processed = data.copy()
        method_name = []

        # ç¡®ä¿æ¯ä¸ªç®—æ³•é¡ºåºéƒ½æ˜¯æœ‰æ•ˆçš„
        valid_orders = [1, 2, 3, 4]  # ä»…æ”¯æŒ 1-4
        if algorithm_order is not None:
            invalid_orders = [order for order in algorithm_order if order not in valid_orders]
            if invalid_orders:
                raise ValueError(f"æ— æ•ˆçš„ç®—æ³•æ­¥éª¤ç¼–å·: {invalid_orders}")

        # å¦‚æœæŒ‡å®šäº†ç®—æ³•é¡ºåºï¼Œåˆ™æŒ‰é¡ºåºæ‰§è¡Œ
        if algorithm_order is not None and len(algorithm_order) > 0:
            # æ ¹æ®ç®—æ³•ç¼–å·æ˜ å°„åˆ°å¯¹åº”çš„å¤„ç†æ­¥éª¤
            step_mapping = {
                1: ("baseline", baseline_method, baseline_params),
                2: ("scaling", scaling_method, scaling_params),
                3: ("filtering", filtering_method, filtering_params),
                4: ("squashing", squashing_method, squashing_params)
            }
            # æŒ‰æŒ‡å®šé¡ºåºåˆ›å»ºæ­¥éª¤åˆ—è¡¨
            steps = [step_mapping[order] for order in algorithm_order]
            # for step in steps:
            #     st.write(f"[CHECK] step: {step}")  # ä½¿ç”¨ st.write è¾“å‡ºæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯
        else:
            # é»˜è®¤é¡ºåºï¼šåŸºçº¿ â†’ æŒ¤å‹ â†’ æ»¤æ³¢ â†’ ç¼©æ”¾ï¼ˆåªæ‰§è¡Œå·²é€‰æ‹©çš„æ–¹æ³•ï¼‰
            steps = []
            if baseline_method != "æ— ":
                steps.append(("baseline", baseline_method, baseline_params))
            if squashing_method != "æ— ":
                steps.append(("squashing", squashing_method, squashing_params))
            if filtering_method != "æ— ":
                steps.append(("filtering", filtering_method, filtering_params))
            if scaling_method != "æ— ":
                steps.append(("scaling", scaling_method, scaling_params))

        # è°ƒè¯•è¾“å‡ºå‚æ•°
        for step_type, method, params in steps:
            print(f"[CHECK] {step_type} æ–¹æ³•: {method}, å‚æ•°: {params}")

        # æŒ‰é¡ºåºæ‰§è¡Œé¢„å¤„ç†æ­¥éª¤
        for step_type, method, params in steps:
            if method == "æ— ":
                continue

            try:
                if step_type == "baseline":
                    algorithm_func = self.BASELINE_ALGORITHMS[method]
                    print(f"[CHECK] æ‰§è¡ŒåŸºçº¿æ ¡æ­£æ–¹æ³•: {method}, å‚æ•°: {params}")  # è¾“å‡ºè°ƒè¯•ä¿¡æ¯

                    if method in ["å¤šé¡¹å¼æ‹Ÿåˆ", "ModPoly", "I-ModPoly"]:
                        # st.write(f"[CHECK] params for {method}: {params}")  # è¾“å‡ºparamså†…å®¹
                        y_processed = algorithm_func(wavenumbers, y_processed, **params)
                    elif method in ["PLS"]:
                        y_processed = algorithm_func(y_processed, **params)
                    elif method == "AsLS":
                        # é€‚é…æ”¹è¿›çš„AsLSç®—æ³•å‚æ•°
                        y_processed = algorithm_func(y_processed, **params)
                    elif method == "airPLS":
                        y_processed = algorithm_func(y_processed, **params)
                    elif method == "äºŒé˜¶å·®åˆ†(D2)":  # å¤„ç†äºŒé˜¶å·®åˆ†
                        y_processed = algorithm_func(y_processed)
                    else:  # SDã€FD æ— é¢å¤–å‚æ•°
                        y_processed = algorithm_func(y_processed)
                    method_name.append(f"{method}({', '.join([f'{k}={v}' for k, v in params.items()])})")

                elif step_type == "squashing":
                    algorithm_func = self.SQUASHING_ALGORITHMS[method]
                    print(f"[CHECK] æ‰§è¡ŒæŒ¤å‹æ–¹æ³•: {method}, å‚æ•°: {params}")  # è¾“å‡ºè°ƒè¯•ä¿¡æ¯

                    if method == "æ”¹è¿›çš„SigmoidæŒ¤å‹":
                        # ä½¿ç”¨æ”¹è¿›çš„i_sigmoidå‡½æ•°ï¼Œæ”¯æŒmaxnå‚æ•°
                        maxn = params.get("maxn", 10)
                        y_processed = algorithm_func(y_processed, maxn=maxn)
                        method_name.append(f"{method}(maxn={maxn})")
                    elif method == "æ”¹è¿›çš„é€»è¾‘å‡½æ•°":
                        # i_squashingå‡½æ•°ä¸éœ€è¦é¢å¤–å‚æ•°
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    elif method == "DTWæŒ¤å‹":
                        l = params.get("l", 1)
                        k1 = params.get("k1", "T")
                        k2 = params.get("k2", "T")
                        y_processed = algorithm_func(y_processed, l=l, k1=k1, k2=k2)
                        method_name.append(f"DTWæŒ¤å‹(l={l}, k1={k1}, k2={k2})")
                    elif method == "SigmoidæŒ¤å‹":
                        # ä½¿ç”¨sigmoidå‡½æ•°
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    elif method == "ä½™å¼¦æŒ¤å‹(squashing)":
                        # ä½¿ç”¨æ–°æ·»åŠ çš„squashingå‡½æ•°
                        y_processed = algorithm_func(y_processed)
                        method_name.append(f"{method}")
                    else:
                        y_processed = algorithm_func(y_processed)
                        method_name.append(method)

                elif step_type == "filtering":
                    algorithm_func = self.FILTERING_ALGORITHMS[method]
                    print(f"[CHECK] æ‰§è¡Œæ»¤æ³¢æ–¹æ³•: {method}, å‚æ•°: {params}")  # è¾“å‡ºè°ƒè¯•ä¿¡æ¯

                    y_processed = algorithm_func(y_processed, **params)
                    params_str = ', '.join([f'{k}={v}' for k, v in params.items()])
                    method_name.append(f"{method}({params_str})")

                    # ç‰¹æ®Šå¤„ç†å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ªçš„å‚æ•°
                    if method == "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª":
                        threshold = params.get("threshold", 0.3)
                        method_name[-1] = f"{method}(threshold={threshold})"

                elif step_type == "scaling":
                    algorithm_func = self.SCALING_ALGORITHMS[method]
                    print(f"[CHECK] æ‰§è¡Œç¼©æ”¾æ–¹æ³•: {method}, å‚æ•°: {params}")  # è¾“å‡ºè°ƒè¯•ä¿¡æ¯

                    y_processed = algorithm_func(y_processed, **params)
                    params_str = ', '.join([f'{k}={v}' for k, v in params.items()])
                    method_name.append(f"{method}({params_str})")

            except Exception as e:
                raise ValueError(f"{step_type}å¤„ç†å¤±è´¥: {str(e)}")

        return y_processed, method_name

    def _sd_baseline(self, spectra):
        return spectra - np.min(spectra, axis=0)

    def _fd_baseline(self, spectra):
        return spectra - np.percentile(spectra, 5, axis=0)

    # ===== æ»¤æ³¢ç®—æ³•å®ç° =====
    def savitzky_golay(self, spectra, window_length, polyorder):
        return savgol_filter(spectra, window_length, polyorder, axis=0)

    # è‡ªå®šä¹‰sgolayfiltæ»¤æ³¢å™¨çš„å°è£…
    def sgolay_filter_custom(self, spectra, window_length, polyorder):
        # ç¡®ä¿è¾“å…¥æ•°æ®å½¢çŠ¶ä¸SGfilterè¦æ±‚ä¸€è‡´
        if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
            filtered = savgol_filter(spectra.T, window_length, polyorder, axis=0)
            return filtered.T  # è½¬å›åŸå§‹å½¢çŠ¶
        else:
            return savgol_filter(spectra, window_length, polyorder, axis=0)

    def median_filter(self, spectra, k, w):
        return medfilt(spectra, kernel_size=(w, 1))

    def moving_average(self, spectra, k, w):
        kernel = np.ones(w) / w
        return np.apply_along_axis(lambda x: np.convolve(x, kernel, mode='same'), 0, spectra)

    # æ·»åŠ MWAæ»¤æ³¢æ–¹æ³•çš„å°è£…
    def mwa_filter(self, spectra, n=6, it=1, mode="full"):
        return MWA(spectra, n=n, it=it, mode=mode)

    # MWMæ»¤æ³¢æ–¹æ³•çš„å°è£…
    def mwm_filter(self, spectra, n=7, it=1):
        """ä½¿ç”¨MWMå‡½æ•°è¿›è¡Œç§»åŠ¨çª—å£ä¸­å€¼æ»¤æ³¢"""
        # ç¡®ä¿è¾“å…¥æ•°æ®å½¢çŠ¶ä¸MWMè¦æ±‚ä¸€è‡´
        if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
            filtered = MWM(spectra.T, n=n, it=it)
            return filtered.T  # è½¬å›åŸå§‹å½¢çŠ¶
        else:
            return MWM(spectra, n=n, it=it)

    # æ·»åŠ å¡å°”æ›¼æ»¤æ³¢æ–¹æ³•çš„å°è£…
    def kalman_filter(self, spectra, R=0.1):
        return KalmanF(spectra, R)

    def lowess_filter(self, spectra, frac):
        result = np.zeros_like(spectra)
        for i in range(spectra.shape[1]):
            smoothed = lowess(spectra[:, i], np.arange(len(spectra)), frac=frac, it=0)
            result[:, i] = smoothed[:, 1]
        return result

    def fft_filter(self, spectra, cutoff):
        fft_result = fft(spectra, axis=0)
        frequencies = np.fft.fftfreq(spectra.shape[0])
        filter_mask = np.abs(frequencies) < cutoff
        fft_result[~filter_mask, :] = 0
        return np.real(ifft(fft_result, axis=0))

    # æ·»åŠ Smfftå‚…é‡Œå¶æ»¤æ³¢æ–¹æ³•çš„å°è£…
    def smfft_filter(self, spectra, row_e=51):
        """ä½¿ç”¨Smfftå‡½æ•°è¿›è¡Œå‚…é‡Œå¶æ»¤æ³¢"""
        # ç¡®ä¿è¾“å…¥æ•°æ®å½¢çŠ¶ä¸Smfftè¦æ±‚ä¸€è‡´
        if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
            filtered = Smfft(spectra.T, row_e=row_e)
            return filtered.T  # è½¬å›åŸå§‹å½¢çŠ¶
        else:
            return Smfft(spectra, row_e=row_e)

    def wavelet_filter(self, spectra, threshold):
        coeffs = pywt.wavedec(spectra, 'db4', axis=0)
        coeffs[1:] = [pywt.threshold(c, threshold, mode='soft') for c in coeffs[1:]]
        return pywt.waverec(coeffs, 'db4', axis=0)

    # æ–°å¢ï¼šå°æ³¢çº¿æ€§é˜ˆå€¼å»å™ªæ–¹æ³•çš„å°è£…
    def wavelet_linear(self, spectra, threshold=0.3):
        """ä½¿ç”¨æ–°æ·»åŠ çš„waveletlinearå‡½æ•°è¿›è¡Œå°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª"""
        # ç¡®ä¿è¾“å…¥æ•°æ®å½¢çŠ¶ä¸waveletlinearè¦æ±‚ä¸€è‡´
        if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
            filtered = waveletlinear(spectra.T, threshold=threshold)
            return filtered.T  # è½¬å›åŸå§‹å½¢çŠ¶
        else:
            return waveletlinear(spectra, threshold=threshold)

    # ===== ç¼©æ”¾ç®—æ³•å®ç° =====
    def peak_norm(self, spectra):
        return spectra / np.max(spectra, axis=0)

    def snv(self, spectra):
        mean = np.mean(spectra, axis=0)
        std = np.std(spectra, axis=0)
        return (spectra - mean) / std

    def msc(self, spectra):
        """ä½¿ç”¨æ–°çš„MSCå‡½æ•°å®ç°å¤šå…ƒæ•£å°„æ ¡æ­£"""
        # æ³¨æ„ï¼šè¾“å…¥æ•°æ®å½¢çŠ¶éœ€è¦ä¸MSCå‡½æ•°è¦æ±‚ä¸€è‡´ (n_samples, n_features)
        # å¦‚æœå½“å‰æ•°æ®å½¢çŠ¶ä¸º(n_features, n_samples)ï¼Œéœ€è¦å…ˆè½¬ç½®
        if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œè¯´æ˜éœ€è¦è½¬ç½®
            corrected = MSC(spectra.T)  # è½¬ç½®åå¤„ç†
            return corrected.T  # è½¬å›åŸå§‹å½¢çŠ¶
        else:
            return MSC(spectra)

    def mm_norm(self, spectra):
        min_vals = np.min(spectra, axis=0)
        max_vals = np.max(spectra, axis=0)
        return (spectra - min_vals) / (max_vals - min_vals)

    def l_norm(self, spectra, p):
        """ä½¿ç”¨LPnormå‡½æ•°å®ç°L-èŒƒæ•°å½’ä¸€åŒ–"""
        if p == "æ— ç©·å¤§":
            return LPnorm(spectra, np.inf)
        else:
            p_val = float(p)
            return LPnorm(spectra, p_val)

    def ma_minorm(self, spectra):
        """ä½¿ç”¨MaMinormå‡½æ•°å®ç°å½’ä¸€åŒ–"""
        return MaMinorm(spectra)

    # æ ‡å‡†åŒ–ç®—æ³•å®ç°ï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰
    def standardize(self, spectra):
        """ä½¿ç”¨plotstå‡½æ•°å®ç°æ ‡å‡†åŒ–å¤„ç†"""
        # å¤„ç†æ•°æ®å½¢çŠ¶é€‚é…
        if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
            standardized = plotst(spectra.T)  # è½¬ç½®åå¤„ç†
            return standardized.T  # è½¬å›åŸå§‹å½¢çŠ¶
        else:
            return plotst(spectra)

    # äºŒé˜¶å·®åˆ†æ–¹æ³•çš„å°è£…ï¼ˆå½’ç±»åˆ°åŸºçº¿æ ¡å‡†ï¼‰
    def d2(self, spectra):
        """ä½¿ç”¨D2å‡½æ•°å®ç°äºŒé˜¶å·®åˆ†è®¡ç®—"""
        # å¤„ç†æ•°æ®å½¢çŠ¶é€‚é…
        if spectra.shape[0] < spectra.shape[1]:  # ç‰¹å¾æ•° < æ ·æœ¬æ•°ï¼Œéœ€è¦è½¬ç½®
            diff_result = D2(spectra.T)  # è½¬ç½®åå¤„ç†
            return diff_result.T  # è½¬å›åŸå§‹å½¢çŠ¶
        else:
            return D2(spectra)


# ===== æ–‡ä»¶å¤„ç†ç±» =====
class FileHandler:
    def load_data_from_zip(self, zip_file):
        """ä»å‹ç¼©åŒ…ä¸­åŠ è½½æ³¢æ•°å’Œå…‰è°±æ•°æ®ï¼Œè‡ªåŠ¨è¯†åˆ«æ•°æ®ç»´åº¦"""
        with zipfile.ZipFile(zip_file, 'r') as zf:
            # åˆ—å‡ºå‹ç¼©åŒ…ä¸­çš„æ‰€æœ‰æ–‡ä»¶
            file_list = zf.namelist()

            # å°è¯•è¯†åˆ«æ³¢æ•°æ–‡ä»¶å’Œå…‰è°±æ•°æ®æ–‡ä»¶
            wavenumber_files = [f for f in file_list if 'wave' in f.lower() or 'wn' in f.lower() or 'æ³¢æ•°' in f]
            data_files = [f for f in file_list if 'spec' in f.lower() or 'data' in f.lower() or 'å…‰è°±' in f]

            if not wavenumber_files:
                raise ValueError("å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°æ³¢æ•°æ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«'wave'ã€'wn'æˆ–'æ³¢æ•°'ï¼‰")
            if not data_files:
                raise ValueError("å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°å…‰è°±æ•°æ®æ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«'spec'ã€'data'æˆ–'å…‰è°±'ï¼‰")

            # å–ç¬¬ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶
            wn_file = wavenumber_files[0]
            data_file = data_files[0]

            # è¯»å–æ³¢æ•°æ–‡ä»¶
            with zf.open(wn_file) as f:
                wavenumbers = np.loadtxt(f).ravel()

            # è¯»å–å…‰è°±æ•°æ®æ–‡ä»¶
            with zf.open(data_file) as f:
                content = f.read().decode("utf-8")
                data = self._parse_data(content)

            return wavenumbers, data.T

    def _parse_data(self, content):
        """è§£æå…‰è°±æ•°æ®å†…å®¹ï¼Œè‡ªåŠ¨è¯†åˆ«æ•°æ®ç»´åº¦"""
        numb = re.compile(r"-?\d+(?:\.\d+)?")
        lines_list = content.splitlines()

        # æå–æ‰€æœ‰æ•°å­—
        all_numbers = []
        for line in lines_list:
            all_numbers.extend(numb.findall(line))

        # å°è¯•ç¡®å®šæ•°æ®å½¢çŠ¶
        # å‡è®¾æ³¢æ•°é•¿åº¦ä¸ºæ•°æ®ç‚¹æ•°
        # å…‰è°±æ¡æ•° = æ€»æ•°æ®ç‚¹ / æ•°æ®ç‚¹æ•°
        # è¿™é‡Œå…ˆç®€å•å¤„ç†ä¸ºäºŒç»´æ•°ç»„
        data = np.array([float(num) for num in all_numbers])

        # å°è¯•åˆç†çš„å½¢çŠ¶ï¼ˆå‡è®¾æ¯è¡Œæ•°æ®ç‚¹å¤§è‡´ç›¸ç­‰ï¼‰
        # å…ˆæŒ‰è¡Œæ•°åˆ’åˆ†
        n_rows = len(lines_list)
        n_cols = len(data) // n_rows if n_rows > 0 else 0

        if n_cols * n_rows != len(data):
            # å¦‚æœæ— æ³•å®Œç¾åˆ’åˆ†ï¼Œè°ƒæ•´æœ€åä¸€è¡Œ
            n_cols = len(data) // n_rows + 1
            data = data[:n_rows * n_cols]  # æˆªæ–­å¤šä½™æ•°æ®

        return data.reshape(n_rows, n_cols)

    def export_data(self, filename, data):
        with open(filename, "w") as f:
            for line in data.T:  # è½¬ç½®å›åŸå§‹æ ¼å¼
                f.write("\t".join(map(str, line)) + "\n")


# æ–°å¢ï¼šsquashingå‡½æ•°ï¼ˆåŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢ï¼‰
def squashing(Data):
    row = Data.shape[0]
    col = Data.shape[1]
    sqData = np.zeros((row, col))
    for i in range(row):
        for j in range(col):
            sqData[i][j] = (1 - math.cos(Data[i][j] * math.pi)) / 2
    return sqData


# æ–°å¢ï¼šå°æ³¢çº¿æ€§é˜ˆå€¼å»å™ªå‡½æ•°
def waveletlinear(arr, threshold=0.3):
    row = arr.shape[0]
    col = arr.shape[1]
    datarec = np.zeros((row, col))
    w = pywt.Wavelet('db8')
    for i in range(row):
        maxlev = pywt.dwt_max_level(col, w.dec_len)
        coeffs = pywt.wavedec(arr[i], 'db8', level=maxlev)
        for j in range(0, len(coeffs)):
            coeffs[j] = pywt.threshold(coeffs[j], threshold * max(coeffs[j]))
        datarec[i] = pywt.waverec(coeffs, 'db8')
    return datarec


# ç§»åŠ¨çª—å£ä¸­å€¼æ»¤æ³¢(MWM)å‡½æ•°
def MWM(arr, n=7, it=1):
    row = arr.shape[0]
    col = arr.shape[1]
    median = np.zeros((row, col))
    ns = []
    for _ in range(it):
        ns.append(n)
        n -= 2
    for i in range(row):
        median[i] = arr[i].copy()
        nn = ns.copy()
        for _ in range(it):
            n = nn.pop()
            if n > 1:
                tmp = signal.medfilt(median[i], n)
                median[i] = tmp
    return median


# sigmoidå‡½æ•°
def sigmoid(X):
    row = X.shape[0]
    col = X.shape[1]
    s = np.zeros((row, col))
    for i in range(row):
        for j in range(col):
            m = 1 + np.exp(-float(X[i, j]))
            s[i, j] = (1.0 / m)
    return s


# æ”¹è¿›çš„i_sigmoidæŒ¤å‹å‡½æ•°
def i_sigmoid(X, maxn=10):
    row = X.shape[0]
    col = X.shape[1]
    s = np.zeros((row, col))
    for i in range(row):
        mi = np.min(X[i])
        diff = (np.max(X[i]) - mi) / maxn
        for j in range(col):
            t = (X[i, j] - mi) / diff - maxn / 2
            m = 1 + np.exp(-float(t))
            t = 1.0 / m
            s[i, j] = t * diff * maxn + mi
    return s


# i_squashingæŒ¤å‹å‡½æ•°ï¼ˆåŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢ï¼Œä¿ç•™åŸå®ç°ä»¥ä¾¿å¯¹æ¯”ï¼‰
def i_squashing(Data):
    row = Data.shape[0]
    col = Data.shape[1]
    sqData = np.zeros((row, col))
    for i in range(row):
        mi = np.min(Data[i])  # æ¯è¡Œçš„æœ€å°å€¼
        diff = np.max(Data[i]) - mi  # æ¯è¡Œçš„æœ€å¤§å€¼ä¸æœ€å°å€¼ä¹‹å·®
        for j in range(col):
            # å°†æ•°æ®å½’ä¸€åŒ–åˆ°[0, 1]èŒƒå›´
            t = (Data[i, j] - mi) / diff if diff != 0 else 0
            # åº”ç”¨åŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢ï¼š(1 - cos(t * Ï€)) / 2
            m = (1 - math.cos(t * math.pi)) / 2
            # å°†ç»“æœæ˜ å°„å›åŸå§‹æ•°æ®èŒƒå›´
            sqData[i][j] = m * diff + mi
    return sqData


# äºŒé˜¶å·®åˆ†(D2)å‡½æ•°
def D2(sdata):
    """
    è®¡ç®—äºŒé˜¶å·®åˆ†ï¼Œä¿æŒè¾“å‡ºå°ºå¯¸ä¸è¾“å…¥ç›¸åŒ
    å‚æ•°:
        sdata: è¾“å…¥å…‰è°±æ•°æ® (n_samples, n_features)
    è¿”å›:
        äºŒé˜¶å·®åˆ†ç»“æœï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = sdata.shape[0]
    col = sdata.shape[1]
    D2_result = np.zeros((row, col))
    for i in range(row):
        tem = np.diff(sdata[i], 2)
        temp = tem.tolist()
        # å¡«å……æœ€åä¸¤ä¸ªå…ƒç´ ä»¥ä¿æŒä¸è¾“å…¥ç›¸åŒçš„å°ºå¯¸
        temp.append(temp[-1])
        temp.append(temp[-1])
        D2_result[i] = temp
    return D2_result


# LPèŒƒæ•°å½’ä¸€åŒ–å‡½æ•°
def LPnorm(arr, ord):
    """
    å¯¹æ•°ç»„è¿›è¡ŒLpèŒƒæ•°å½’ä¸€åŒ–

    å‚æ•°:
        arr: è¾“å…¥æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(row, col)
        ord: èŒƒæ•°é˜¶æ•°

    è¿”å›:
        å½’ä¸€åŒ–åçš„æ•°ç»„ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = arr.shape[0]
    col = arr.shape[1]
    Lpdata = np.zeros((row, col))
    for i in range(row):
        Lp = np.linalg.norm(arr[i, :], ord)
        if Lp != 0:
            Lpdata[i, :] = arr[i, :] / Lp
        else:
            Lpdata[i, :] = arr[i, :]
    return Lpdata


# MaMinormå½’ä¸€åŒ–å‡½æ•°
def MaMinorm(Oarr):
    """
    å¯¹æ•°ç»„è¿›è¡ŒMa-Minormå½’ä¸€åŒ–å¤„ç†
    å°†æ•°æ®æ ‡å‡†åŒ–åˆ°[-5, 5]èŒƒå›´

    å‚æ•°:
        Oarr: è¾“å…¥æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(row, col)

    è¿”å›:
        å½’ä¸€åŒ–åçš„æ•°ç»„ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = Oarr.shape[0]
    col = Oarr.shape[1]
    MMarr = np.zeros((row, col))
    permax = np.ones((1, col))
    for i in range(row):
        diff = np.max(Oarr[i]) - np.min(Oarr[i])
        if diff != 0:
            MMarr[i] = ((Oarr[i] - permax * np.min(Oarr[i])) / diff) * 10 - 5
        else:
            MMarr[i] = Oarr[i] - permax * np.min(Oarr[i])
    return MMarr


# æ ‡å‡†åŒ–å‡½æ•°ï¼ˆå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰
def standardization(Datamat):
    """
    å°†æ•°æ®æ ‡å‡†åŒ–ï¼Œå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1

    å‚æ•°:
        Datamat: è¾“å…¥æ•°æ®

    è¿”å›:
        æ ‡å‡†åŒ–åçš„æ•°æ®
    """
    mu = np.average(Datamat)
    sigma = np.std(Datamat)
    if sigma != 0:
        normDatamat = (Datamat - mu) / sigma
    else:
        normDatamat = Datamat - mu
    return normDatamat


def plotst(Data):
    """
    å¯¹æ•°æ®çš„æ¯ä¸€è¡Œè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†

    å‚æ•°:
        Data: è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º(row, col)

    è¿”å›:
        æ ‡å‡†åŒ–åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = Data.shape[0]
    col = Data.shape[1]
    st_Data = np.zeros((row, col))
    for i in range(row):
        st_Data[i] = standardization(Data[i])
    return st_Data


# Smfftå‚…é‡Œå¶æ»¤æ³¢å‡½æ•°
def Smfft(arr, row_e=51):
    """
    ä¿¡å·è¿›è¡Œå‚…é‡Œå¶å˜æ¢ï¼Œä½¿é«˜é¢‘ä¿¡å·çš„ç³»æ•°ä¸ºé›¶ï¼Œå†è¿›è¡Œå‚…é‡Œå¶é€†å˜æ¢
    è½¬æ¢å›æ—¶åŸŸä¸Šçš„ä¿¡å·ä¾¿æ˜¯æ»¤æ³¢åçš„æ•ˆæœã€‚

    å‚æ•°:
        arr: è¾“å…¥æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(row, col)
        row_e: ä¿ç•™çš„ä½é¢‘åˆ†é‡æ•°é‡ï¼Œé»˜è®¤51

    è¿”å›:
        æ»¤æ³¢åçš„æ•°ç»„ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = arr.shape[0]
    col = arr.shape[1]
    fftresult = np.zeros((row, col))
    for i in range(row):
        sfft = fftpack_fft(arr[i])  # ä½¿ç”¨scipy.fftpackçš„fft
        row_s = len(arr[i])  # è‡ªé€‚åº”è¾“å…¥ä¿¡å·é•¿åº¦
        sfftn = copy.deepcopy(sfft)
        # å°†é«˜é¢‘åˆ†é‡è®¾ä¸ºé›¶
        sfftn[row_e:row_s - row_e] = 0
        result = fftpack_ifft(sfftn)  # ä½¿ç”¨scipy.fftpackçš„ifft
        real_r = np.real(result)  # å–å®éƒ¨
        fftresult[i] = real_r
    return fftresult


# MSCï¼ˆå¤šå…ƒæ•£å°„æ ¡æ­£ï¼‰å‡½æ•°
def MSC(sdata):
    """
    å¤šå…ƒæ•£å°„æ ¡æ­£(MSC)ç®—æ³•å®ç°

    å‚æ•°:
        sdata: è¾“å…¥å…‰è°±æ•°æ®ï¼Œå½¢çŠ¶ä¸º(n_samples, n_features)

    è¿”å›:
        æ ¡æ­£åçš„å…‰è°±æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    n = sdata.shape[0]  # æ ·æœ¬æ•°é‡
    k = np.zeros(sdata.shape[0])  # æ–œç‡
    b = np.zeros(sdata.shape[0])  # æˆªè·

    # è®¡ç®—å¹³å‡å…‰è°±ä½œä¸ºå‚è€ƒ
    M = np.mean(sdata, axis=0)

    # å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œçº¿æ€§å›å½’ï¼Œè®¡ç®—æ–œç‡å’Œæˆªè·
    for i in range(n):
        y = sdata[i, :].reshape(-1, 1)  # å½“å‰æ ·æœ¬å…‰è°±
        M_reshaped = M.reshape(-1, 1)  # å¹³å‡å…‰è°±ï¼Œé‡å¡‘ä¸ºäºŒç»´æ•°ç»„
        model = LinearRegression()
        model.fit(M_reshaped, y)
        k[i] = model.coef_  # æ–œç‡
        b[i] = model.intercept_  # æˆªè·

    # åº”ç”¨MSCæ ¡æ­£
    spec_msc = np.zeros_like(sdata)
    for i in range(n):
        # å°†æ–œç‡å’Œæˆªè·æ‰©å±•åˆ°ä¸å…‰è°±é•¿åº¦åŒ¹é…
        bb = np.repeat(b[i], sdata.shape[1])
        kk = np.repeat(k[i], sdata.shape[1])
        # åº”ç”¨æ ¡æ­£å…¬å¼ï¼š(åŸå§‹å…‰è°± - æˆªè·) / æ–œç‡
        spec_msc[i, :] = (sdata[i, :] - bb) / kk

    return spec_msc


# å¡å°”æ›¼æ»¤æ³¢ç®—æ³•å®ç°
def Kalman(z, R):
    """
    å•å˜é‡å¡å°”æ›¼æ»¤æ³¢

    å‚æ•°:
        z: è¾“å…¥ä¿¡å·
        R: æµ‹é‡å™ªå£°æ–¹å·®

    è¿”å›:
        æ»¤æ³¢åçš„ä¿¡å·
    """
    n_iter = len(z)
    sz = (n_iter,)  # æ•°ç»„å¤§å°

    Q = 1e-5  # è¿‡ç¨‹æ–¹å·®

    # åˆ†é…æ•°ç»„ç©ºé—´
    xhat = np.zeros(sz)  # åéªŒä¼°è®¡
    P = np.zeros(sz)  # åéªŒè¯¯å·®ä¼°è®¡
    xhatminus = np.zeros(sz)  # å…ˆéªŒä¼°è®¡
    Pminus = np.zeros(sz)  # å…ˆéªŒè¯¯å·®ä¼°è®¡
    K = np.zeros(sz)  # å¡å°”æ›¼å¢ç›Š

    # åˆå§‹çŒœæµ‹
    xhat[0] = 0.0
    P[0] = 1.0

    for k in range(1, n_iter):
        # æ—¶é—´æ›´æ–°
        xhatminus[k] = xhat[k - 1]  # X(k|k-1) = AX(k-1|k-1) + BU(k) + W(k), A=1, BU(k)=0
        Pminus[k] = P[k - 1] + Q  # P(k|k-1) = AP(k-1|k-1)A' + Q(k), A=1

        # æµ‹é‡æ›´æ–°
        K[k] = Pminus[k] / (Pminus[k] + R)  # Kg(k) = P(k|k-1)H'/[HP(k|k-1)H' + R], H=1
        xhat[k] = xhatminus[k] + K[k] * (z[k] - xhatminus[k])  # X(k|k)æ›´æ–°
        P[k] = (1 - K[k]) * Pminus[k]  # P(k|k)æ›´æ–°

    return xhat


def KalmanF(xd, R):
    """
    å¯¹å¤šç»´æ•°æ®åº”ç”¨å¡å°”æ›¼æ»¤æ³¢

    å‚æ•°:
        xd: è¾“å…¥æ•°æ®ï¼Œå½¢çŠ¶ä¸º(n_samples, n_points)
        R: æµ‹é‡å™ªå£°æ–¹å·®

    è¿”å›:
        æ»¤æ³¢åçš„æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    row = xd.shape[0]
    col = xd.shape[1]
    Fxd = np.zeros((row, col))
    for i in range(row):
        Fxd[i] = Kalman(xd[i], R)
    return Fxd


# IModPoly: improved modified multi-polynomial fit method
def IModPoly(wavenumbers, originalRaman, polyorder, max_iter=100, tolerance=0.005):
    """
    æ”¹è¿›çš„å¤šé¡¹å¼æ‹ŸåˆåŸºçº¿æ ¡æ­£ï¼ˆè‡ªé€‚é…è¾“å…¥å½¢çŠ¶ï¼‰
    å…¥å‚:
        wavenumbers: ä¸€ç»´æ³¢æ•°æ•°ç»„ï¼Œé•¿åº¦ = n_points
        originalRaman: å…‰è°±çŸ©é˜µ (n_points, n_samples) æˆ– (n_samples, n_points)
        polyorder: å¤šé¡¹å¼é˜¶æ•°
        max_iter, tolerance: è¿­ä»£ä¸æ”¶æ•›é˜ˆå€¼
    è¿”å›:
        ä¸ originalRaman å½¢çŠ¶ä¸€è‡´çš„æ ¡æ­£ç»“æœ
    """
    import numpy as np

    # --- è§„èŒƒåŒ–è¾“å…¥ ---
    x = np.asarray(wavenumbers).ravel()
    Y = np.asarray(originalRaman, dtype=float)

    if Y.ndim != 2:
        raise ValueError(f"originalRaman å¿…é¡»æ˜¯äºŒç»´çŸ©é˜µï¼Œå½“å‰ ndim={Y.ndim}")

    # è¯†åˆ«å¹¶ç»Ÿä¸€åˆ°å†…éƒ¨å½¢çŠ¶ (n_samples, n_points)
    transposed_back = False
    if Y.shape[0] == x.size and Y.shape[1] != x.size:  # (n_points, n_samples)
        Y = Y.T
        transposed_back = True
    elif Y.shape[1] == x.size:
        pass  # å·²æ˜¯ (n_samples, n_points)
    else:
        raise ValueError(
            f"è¾“å…¥ç»´åº¦ä¸æ³¢æ•°ä¸åŒ¹é…ï¼šwavenumbers(len={x.size}), originalRaman{originalRaman.shape}"
        )

    n_samples, n_points = Y.shape

    # å» NaN/Inf å¹¶æŒ‰ x æ’åºï¼ˆx ä¸æ¯æ¡ y ç”¨åŒä¸€æ©ç /é¡ºåºï¼‰
    finite_mask = np.isfinite(x)
    if not np.all(finite_mask):
        x = x[finite_mask]
    sort_idx = np.argsort(x)
    x_sorted = x[sort_idx]

    # é¢„å…ˆä¸ºæ¯æ¡è°±å‡†å¤‡åŒæ ·çš„æ©ç /æ’åº
    corrected = np.zeros_like(Y)

    for j in range(n_samples):
        y_full = Y[j]
        # ä¸ x åŒæ­¥æ¸…ç†
        if not np.all(finite_mask):
            y = y_full[finite_mask]
        else:
            y = y_full

        # è‹¥ y ä¸ x ä»ä¸ç­‰é•¿ï¼Œè¯´æ˜è¯¥æ¡è°±è‡ªèº«æœ‰ NaN/Infï¼›å†åšä¸€æ¬¡è¡Œå†…æ©ç 
        row_mask = np.isfinite(y)
        x_row = x_sorted if row_mask.all() else x_sorted[row_mask]
        y_row = y[sort_idx] if row_mask.all() else y[sort_idx][row_mask]

        if x_row.size != y_row.size:
            raise ValueError(
                f"æ ·æœ¬ {j}ï¼šæ¸…ç†å x ä¸ y é•¿åº¦ä»ä¸ç­‰ (len(x)={x_row.size}, len(y)={y_row.size})"
            )

        # è¿­ä»£æ‹Ÿåˆ
        prev_spectrum = y_row.copy()
        curr_spectrum = prev_spectrum.copy()
        prev_std = 0.0
        converged = False
        iteration = 1

        while not converged and iteration <= max_iter:
            # å¤šé¡¹å¼æ‹Ÿåˆä¸æ®‹å·®
            coeffs = np.polyfit(x_row, curr_spectrum, polyorder)
            fitted = np.polyval(coeffs, x_row)
            residual = curr_spectrum - fitted
            curr_std = np.std(residual)

            # å…‰è°±ä¿®æ­£
            if iteration == 1:
                mask = prev_spectrum > (fitted + curr_std)
                curr_spectrum[mask] = fitted[mask] + curr_std
            else:
                mask = prev_spectrum < (fitted + curr_std)
                curr_spectrum = np.where(mask, prev_spectrum, fitted + curr_std)

            # æ”¶æ•›åˆ¤å®š
            relative_change = abs((curr_std - prev_std) / curr_std) if curr_std != 0 else 0.0
            converged = (relative_change < tolerance)
            prev_spectrum = curr_spectrum
            prev_std = curr_std
            iteration += 1

        # å°†æ ¡æ­£ç»“æœè¿˜åŸåˆ°ä¸ y_full åŒé•¿åº¦ï¼ˆæ’å›è¢«æ©æ‰çš„ç‚¹ï¼‰
        # ç›®æ ‡ï¼šoriginal - baseline(fitted)
        baseline_row = np.polyval(np.polyfit(x_row, curr_spectrum, polyorder), x_row)

        # æ„é€ å®Œæ•´é•¿åº¦ baseline_full
        baseline_full = np.zeros_like(y_full)
        if not np.all(finite_mask):
            # å…ˆå‡†å¤‡ x_full çš„æ’åºæ˜ å°„
            x_full = np.asarray(wavenumbers).ravel()
            order_full = np.argsort(x_full[finite_mask])
            # æ”¾å›æœ‰é™ä½ç½®
            tmp = np.zeros_like(x_row)
            tmp[order_full] = baseline_row  # baseline_row å·²ä¸ x_row åŒæ’åº
            baseline_full[finite_mask] = tmp
            # å¯¹äºéæœ‰é™ä½ç½®ï¼Œä¿ç•™åŸå€¼çš„å·®ä¸º 0ï¼ˆç­‰ä»·äºä¸æ ¡æ­£ï¼‰
            baseline_full[~finite_mask] = 0.0
        else:
            # x å…¨æœ‰é™
            baseline_full[np.argsort(np.asarray(wavenumbers).ravel())] = baseline_row

        corrected[j] = y_full - baseline_full

    # è¿”å›åˆ°åŸå§‹å½¢çŠ¶
    return corrected.T if transposed_back else corrected


# ç§»åŠ¨çª—å£å¹³å‡ï¼ˆMWAï¼‰æ»¤æ³¢ç®—æ³•
def MWA(arr, n=6, it=1, mode="full"):
    row = arr.shape[0]
    col = arr.shape[1]
    average = np.zeros((row, col))
    ns = []
    for _ in range(it):
        ns.append(n)
        n -= 2
    for i in range(row):
        average[i] = arr[i].copy()
        nn = ns.copy()
        for _ in range(it):
            n = nn.pop()
            if n > 1:
                tmp = np.convolve(average[i], np.ones((n,)) / n, mode=mode)
                for j in range(1, n):
                    tmp[j - 1] = tmp[j - 1] * n / j
                    tmp[-j] = tmp[-j] * n / j
                j = int(n / 2)
                k = n - j - 1
                average[i] = tmp[j:-k]
    return average


# æ”¹è¿›çš„éå¯¹ç§°åŠ æƒæƒ©ç½šæœ€å°äºŒä¹˜åŸºçº¿æ ¡å‡†ç®—æ³•
def baseline_als(y, lam, p, niter=10, tol=1e-6):
    """
    æ”¹è¿›çš„AsLSç®—æ³•

    å‚æ•°:
        y: è¾“å…¥å…‰è°± (n_samples, n_points)
        lam: å¹³æ»‘ç³»æ•° (å…¸å‹å€¼1e5-1e12)
        p: éå¯¹ç§°ç³»æ•° (0-1, å…¸å‹å€¼0.001-0.1)
        niter: æœ€å¤§è¿­ä»£æ¬¡æ•°
        tol: æ”¶æ•›é˜ˆå€¼

    è¿”å›:
        åŸºçº¿æ ¡æ­£åçš„å…‰è°±
    """
    if np.any(np.isnan(y)):
        raise ValueError("è¾“å…¥æ•°æ®åŒ…å«NaNå€¼")

    y = np.asarray(y, dtype=np.float64)
    L = y.shape[1]
    D = sparse.csc_matrix(np.diff(np.eye(L), 2))
    result = np.zeros_like(y)

    for j in range(y.shape[0]):
        w = np.ones(L)
        y_curr = y[j].copy()

        for _ in range(niter):
            W = sparse.spdiags(w, 0, L, L)
            Z = W + lam * D.dot(D.transpose())
            z = spsolve(Z, w * y_curr)

            # æ£€æŸ¥æ”¶æ•›
            if np.max(np.abs(z - y_curr)) < tol:
                break

            w = p * (y[j] > z) + (1 - p) * (y[j] < z)
            y_curr = z

        result[j] = y[j] - z

    return result


# åŠ¨æ€æ—¶é—´è§„æ•´(DTW)ç®—æ³•
class DTW:
    def __init__(self, dist_method='euclidean'):
        self.dist_method = dist_method

    def distance(self, x, y):
        if self.dist_method == 'euclidean':
            return np.linalg.norm(x - y)
        elif self.dist_method == 'manhattan':
            return np.sum(np.abs(x - y))
        else:
            return np.linalg.norm(x - y)

    def __call__(self, reference, query):
        n = len(reference)
        m = len(query)
        dtw_matrix = np.zeros((n + 1, m + 1))
        dtw_matrix[:, :] = np.inf
        dtw_matrix[0, 0] = 0

        for i in range(1, n + 1):
            for j in range(1, m + 1):
                cost = self.distance(reference[i - 1], query[j - 1])
                dtw_matrix[i, j] = cost + min(
                    dtw_matrix[i - 1, j],  # æ’å…¥
                    dtw_matrix[i, j - 1],  # åˆ é™¤
                    dtw_matrix[i - 1, j - 1]  # åŒ¹é…
                )

        # å›æº¯è·¯å¾„
        i, j = n, m
        path = []
        while i > 0 or j > 0:
            path.append((i - 1, j - 1))
            if i == 0:
                j -= 1
            elif j == 0:
                i -= 1
            else:
                min_val = min(dtw_matrix[i - 1, j], dtw_matrix[i, j - 1], dtw_matrix[i - 1, j - 1])
                if min_val == dtw_matrix[i - 1, j - 1]:
                    i -= 1
                    j -= 1
                elif min_val == dtw_matrix[i - 1, j]:
                    i -= 1
                else:
                    j -= 1

        return path[::-1], dtw_matrix[n, m]


# æŒ¤å‹ç›¸å…³å‡½æ•°ï¼ˆå·²åŒ…å«æ–°çš„squashingå‡½æ•°ï¼‰
def squashing_legacy(x):
    return 1 / (1 + np.exp(-x))


# sgolayfiltæ»¤æ³¢å™¨å®ç°
def SGfilter(Intensity, window_length, polyorder):  # è¾“å…¥å‡ä¸ºè¡Œ
    """
    Savitzky-Golayæ»¤æ³¢å™¨å®ç°

    å‚æ•°:
        Intensity: è¾“å…¥å…‰è°±æ•°æ® (n_samples, n_features)
        point: çª—å£å¤§å°
        degree: å¤šé¡¹å¼é˜¶æ•°

    è¿”å›:
        æ»¤æ³¢åçš„å…‰è°±æ•°æ®ï¼Œå½¢çŠ¶ä¸è¾“å…¥ç›¸åŒ
    """
    Row = Intensity.shape[0]
    col = Intensity.shape[1]
    sgsmooth = np.zeros((Row, col))
    for i in range(Row):
        sgsmooth[i] = savgol_filter(Intensity[i], point, degree)
    return sgsmooth


# ç”Ÿæˆæ’åˆ—æ—¶ä¸åŒ…å«ç¼–å· - æå‰å®šä¹‰æ­¤å‡½æ•°ä»¥é¿å…å¼•ç”¨é”™è¯¯


def generate_permutations(algorithms):
    """ç”Ÿæˆå®Œæ•´çš„ç®—æ³•æ’åˆ—ç»„åˆï¼Œæ’åˆ—åç§°ä¸åŒ…å«ç¼–å·"""

    # ä¸ºå››ç§é¢„å¤„ç†ç®—æ³•åˆ†é…ç¼–å·1-4
    algorithm_list = [
        (1, "åŸºçº¿æ ¡å‡†", algorithms['baseline']['method'], algorithms['baseline']['params']),
        (2, "ç¼©æ”¾", algorithms['scaling']['method'], algorithms['scaling']['params']),
        (3, "æ»¤æ³¢", algorithms['filtering']['method'], algorithms['filtering']['params']),
        (4, "æŒ¤å‹", algorithms['squashing']['method'], algorithms['squashing']['params'])
    ]

    all_permutations = []

    # 1. ç”Ÿæˆä½¿ç”¨1ç§ç®—æ³•çš„æ’åˆ—ï¼ˆåŒ…æ‹¬â€œæ— é¢„å¤„ç†â€é€‰é¡¹ï¼‰
    for algo in algorithm_list:
        all_permutations.append([algo])  # ç”Ÿæˆæ¯ç§é¢„å¤„ç†çš„å•ç‹¬æ’åˆ—

    # 2. ç”Ÿæˆä½¿ç”¨2ç§ç®—æ³•çš„æ’åˆ—
    for comb in itertools.combinations(algorithm_list, 2):
        for perm in itertools.permutations(comb):  # ç”Ÿæˆæ’åˆ—
            all_permutations.append(list(perm))

    # 3. ç”Ÿæˆä½¿ç”¨3ç§ç®—æ³•çš„æ’åˆ—
    for comb in itertools.combinations(algorithm_list, 3):
        for perm in itertools.permutations(comb):  # ç”Ÿæˆæ’åˆ—
            all_permutations.append(list(perm))

    # 4. ç”Ÿæˆä½¿ç”¨4ç§ç®—æ³•çš„æ’åˆ—
    for comb in itertools.combinations(algorithm_list, 4):
        for perm in itertools.permutations(comb):  # ç”Ÿæˆæ’åˆ—
            all_permutations.append(list(perm))

    # 5. åŠ å…¥â€œæ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰â€é€‰é¡¹
    all_permutations.append([])  # ç©ºåˆ—è¡¨è¡¨ç¤ºæ— é¢„å¤„ç†

    # æ ¼å¼åŒ–æ’åˆ—ç»„åˆ
    formatted_perms = []
    for i, perm in enumerate(all_permutations):
        perm_dict = {
            "name": "",
            "order": [step[0] for step in perm],  # æ­£ç¡®ç”Ÿæˆorder
            "details": perm,
            "count": len(perm),
            "first_step_type": "æœªçŸ¥"
        }

        if not perm:  # æ— é¢„å¤„ç†æƒ…å†µ
            perm_dict["name"] = "æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰"
            perm_dict["first_step_type"] = "æ— é¢„å¤„ç†"
        else:
            first_step_type = perm[0][1] if perm and len(perm) > 0 else "æœªçŸ¥"
            perm_dict["first_step_type"] = first_step_type

            perm_details = []
            for step in perm:
                perm_details.append(f"{step[1]}({step[2]})")
            perm_dict["name"] = " â†’ ".join(perm_details)

        formatted_perms.append(perm_dict)

    # è¾“å‡ºæ’åˆ—æ•°é‡ä»¥éªŒè¯
    print(f"ç”Ÿæˆçš„æ’åˆ—æ•°é‡: {len(formatted_perms)}")

    return formatted_perms
def main():
    # æœ€ä¼˜å…ˆåˆå§‹åŒ–session state
    if 'show_arrangements' not in st.session_state:
        st.session_state.show_arrangements = False

    # åˆå§‹åŒ–æµ‹è¯•ç›¸å…³çš„sessionçŠ¶æ€å˜é‡
    test_states = {
        'k_value': 5,  # é»˜è®¤kå€¼
        'test_results': None,  # å­˜å‚¨æµ‹è¯•ç»“æœ
        'labels': None,  # å­˜å‚¨æ ·æœ¬æ ‡ç­¾
        'train_indices': None,  # è®­ç»ƒé›†ç´¢å¼•
        'test_indices': None  # æµ‹è¯•é›†ç´¢å¼•
    }
    file_handler = FileHandler()
    preprocessor = Preprocessor()
    # åˆå§‹åŒ– current_algorithms å­—å…¸
    current_algorithms = {
        'baseline': 'æ— ',  # é»˜è®¤åŸºçº¿æ ¡æ­£æ–¹æ³•
        'baseline_params': {},
        'scaling': 'æ— ',  # é»˜è®¤ç¼©æ”¾æ–¹æ³•
        'scaling_params': {},
        'filtering': 'æ— ',  # é»˜è®¤æ»¤æ³¢æ–¹æ³•
        'filtering_params': {},
        'squashing': 'æ— ',  # é»˜è®¤æŒ¤å‹æ–¹æ³•
        'squashing_params': {}
    }

    # å°† current_algorithms å­˜å‚¨åˆ° session_state ä¸­ï¼Œä»¥ä¾¿å…¨å±€è®¿é—®
    st.session_state.setdefault('current_algorithms', current_algorithms)
    # åˆå§‹åŒ–å…¶ä»–å¿…è¦çš„sessionçŠ¶æ€å˜é‡
    other_states = {
        'raw_data': None,
        'processed_data': None,
        'peaks': None,
        'train_test_split_ratio': 0.8,
        'arrangement_results': [],
        'selected_arrangement': None,
        'arrangement_details': {},
        'algorithm_permutations': [],  # å­˜å‚¨ç®—æ³•æ’åˆ—ç»„åˆ
        'current_algorithms': {},  # å­˜å‚¨å½“å‰é€‰æ‹©çš„ç®—æ³•
        'filtered_perms': [],  # å­˜å‚¨ç­›é€‰åçš„æ’åˆ—æ–¹æ¡ˆ
        'selected_perm_idx': 0  # å­˜å‚¨å½“å‰é€‰ä¸­çš„æ’åˆ—ç´¢å¼•
    }

    # åˆå¹¶æ‰€æœ‰çŠ¶æ€å˜é‡å¹¶åˆå§‹åŒ–
    all_states = {**test_states, **other_states}
    for key, value in all_states.items():
        if key not in st.session_state:
            st.session_state[key] = value
    st.session_state['current_algorithms'] = current_algorithms
    # è®¾ç½®é¡µé¢ï¼šç´§å‡‘å¸ƒå±€
    st.set_page_config(layout="wide", page_icon="ğŸ”¬", page_title="æ’åˆ—é¢„å¤„ç†æ¨¡å‹")
    # å…¨å±€æ ·å¼è°ƒæ•´ï¼šæ›´ç´§å‡‘çš„å­—ä½“å’Œé—´è·ï¼Œç¡®ä¿é¢„å¤„ç†è®¾ç½®åœ¨ä¸€è¡Œæ˜¾ç¤º
    st.markdown("""
        <style>
        /* å…¨å±€å­—ä½“ç¼©å°ï¼Œç¡®ä¿é¢„å¤„ç†è®¾ç½®åœ¨ä¸€è¡Œæ˜¾ç¤º */
        body {font-size: 0.75rem !important;}
        .css-1v0mbdj {padding: 0.3rem 0.5rem !important;} /* å®¹å™¨å†…è¾¹è· */
        .css-1d391kg {padding: 0.2rem 0 !important;} /* æ ‡é¢˜é—´è· */
        .css-1x8cf1d {line-height: 1.1 !important;} /* æ–‡æœ¬è¡Œé«˜ */
        .css-12ttj6m {margin-bottom: 0.3rem !important;} /* ç»„ä»¶åº•éƒ¨é—´è· */
        .css-16huue1 {padding: 0.2rem 0.5rem !important; font-size: 0.7rem !important;} /* æŒ‰é’®å†…è¾¹è·å’Œå­—ä½“ */
        h3 {font-size: 1rem !important; margin: 0.3rem 0 !important;} /* å­æ ‡é¢˜ */
        .css-1b3298e {gap: 0.3rem !important;} /* åˆ—é—´è· */
        .stSlider, .stSelectbox, .stTextInput {margin-bottom: 0.3rem !important;} /* è¾“å…¥ç»„ä»¶é—´è· */
        .stCaption {font-size: 0.65rem !important; margin-top: -0.2rem !important;} /* è¯´æ˜æ–‡å­— */
        .css-1544g2n {padding: 0.2rem 0.5rem !important;} /* å±•å¼€é¢æ¿å†…è¾¹è· */
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸŒŒ æ’åˆ—é¢„å¤„ç†æ¨¡å‹")

    # é¡µé¢æ•´ä½“å¸ƒå±€ï¼šå·¦ä¾§æ•°æ®ç®¡ç†ï¼Œå³ä¾§ä¸»è¦å†…å®¹åŒº
    col_left, col_right = st.columns([1.2, 3.9])

    # ===== å·¦ä¾§ï¼šæ•°æ®ç®¡ç†æ¨¡å—ï¼ˆç§»é™¤å…‰è°±æ¡æ•°å’Œæ•°æ®ç‚¹æ•°ï¼‰=====
    with col_left:
        with st.expander("ğŸ“ æ•°æ®ç®¡ç†", expanded=True):
            # 1. æå‰åˆå§‹åŒ–train_test_ratio
            train_test_ratio = st.session_state.get('train_test_split_ratio', 0.8)

            # 2. ä¸Šä¼ å‹ç¼©åŒ…
            zip_file = st.file_uploader("ä¸Šä¼ åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®çš„å‹ç¼©åŒ…", type=['zip'], key="zip_file")
            st.caption("å‹ç¼©åŒ…(.zip)éœ€åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®æ–‡ä»¶")

            # æ•°æ®åŠ è½½é€»è¾‘ï¼ˆå‹ç¼©åŒ…ä¸Šä¼ åã€æ ·æœ¬æ ‡ç­¾å‰ï¼‰
            if zip_file:
                try:
                    st.session_state.raw_data = file_handler.load_data_from_zip(zip_file)

                    if st.session_state.get('labels') is not None:
                        st.success(
                            f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{st.session_state.raw_data[1].shape[1]}æ¡å…‰è°±ï¼Œ{len(np.unique(st.session_state.labels))}ç±»")
                    else:
                        st.success(
                            f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{st.session_state.raw_data[1].shape[1]}æ¡å…‰è°±ï¼Œ{st.session_state.raw_data[1].shape[0]}ä¸ªç‚¹")
                        st.warning("âš ï¸ è¯·è¾“å…¥æ ·æœ¬æ ‡ç­¾ä»¥è¿›è¡Œåˆ†ç±»æµ‹è¯•")

                    # ã€è°ƒæ•´1ï¼šæ•°æ®ç»´åº¦æç¤ºç§»è‡³æ•°æ®åŠ è½½æˆåŠŸæç¤ºä¸‹æ–¹ã€‘
                    if st.session_state.get('raw_data'):
                        wavenumbers, y = st.session_state.raw_data
                        st.info(f"ğŸ“Š æ•°æ®ç»´åº¦: {y.shape[1]}æ¡ Ã— {y.shape[0]}ç‚¹")

                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")

            # 3. æ ·æœ¬æ ‡ç­¾åŒºåŸŸï¼ˆæ•°æ®ç»´åº¦æç¤ºä¸‹æ–¹ï¼‰
            st.subheader("æ ·æœ¬æ ‡ç­¾")
            num_classes = st.number_input("ç±»åˆ«æ•°é‡", min_value=1, value=2, step=1, key="num_cls")

            # å®šä¹‰æ ‡ç­¾è¾“å…¥
            labels_input = st.text_input(
                "æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼Œä¸å…‰è°±é¡ºåºä¸€è‡´ï¼‰",
                placeholder="ä¾‹ï¼š0,0,1,1",
                key="labels_in"
            )

            # æ ‡ç­¾éªŒè¯é€»è¾‘
            if labels_input and st.session_state.get('raw_data'):
                try:
                    labels = np.array([int(l.strip()) for l in labels_input.split(',')])
                    if len(labels) == st.session_state.raw_data[1].shape[1]:
                        st.session_state.labels = labels
                        n_samples = len(labels)
                        train_size = int(n_samples * train_test_ratio)
                        indices = np.random.permutation(n_samples)
                        st.session_state.train_indices = indices[:train_size]
                        st.session_state.test_indices = indices[train_size:]
                    else:
                        st.warning(f"âš ï¸ æ ‡ç­¾æ•°({len(labels)})â‰ å…‰è°±æ•°({st.session_state.raw_data[1].shape[1]})")
                        st.session_state.labels = None
                except Exception as e:
                    st.warning(f"âš ï¸ æ ‡ç­¾æ ¼å¼é”™è¯¯: {str(e)}")
                    st.session_state.labels = None

            # ã€è°ƒæ•´2ï¼šç±»åˆ«åˆ†å¸ƒæç¤ºç§»è‡³åŸæ•°æ®ç»´åº¦ä½ç½®ï¼ˆæ ·æœ¬æ ‡ç­¾åŒºåŸŸæœ«å°¾ï¼‰ã€‘
            if st.session_state.get('raw_data') and st.session_state.get('labels') is not None:
                class_counts = np.bincount(st.session_state.labels)
                st.info(
                    f"ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ: {', '.join([f'ç±»{i}:{count}ä¸ª' for i, count in enumerate(class_counts) if count > 0])}")

            # 4. è®­ç»ƒæµ‹è¯•åˆ’åˆ†åŒºåŸŸ
            st.subheader("è®­ç»ƒæµ‹è¯•åˆ’åˆ†")
            train_test_ratio = st.slider(
                "è®­ç»ƒé›†æ¯”ä¾‹",
                min_value=0.1,
                max_value=0.9,
                value=train_test_ratio,
                step=0.1,
                format="%.1f",
                key="train_ratio"
            )
            st.session_state.train_test_split_ratio = train_test_ratio

            # è®­ç»ƒé›†:æµ‹è¯•é›†æç¤º
            st.info(f"ğŸ”¢ è®­ç»ƒé›†:{train_test_ratio:.1f} | æµ‹è¯•é›†:{1 - train_test_ratio:.1f}")

        # å¤„ç†æµç¨‹æç¤º
        if st.session_state.get('process_method'):
            st.success(f"ğŸ› ï¸ å¤„ç†æµç¨‹: {st.session_state.process_method}")

        # ä½¿ç”¨è¯´æ˜
        with st.expander("â„¹ï¸ ä½¿ç”¨æŒ‡å—", expanded=False):
            st.markdown("""
            1. ä¸Šä¼ åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®çš„å‹ç¼©åŒ…  
            2. è®¾ç½®æ ‡ç­¾å’Œè®­ç»ƒæµ‹è¯•æ¯”ä¾‹  
            3. å³ä¾§ä¸Šæ–¹é€‰æ‹©é¢„å¤„ç†æ–¹æ³•  
            4. ç‚¹å‡»"æ˜¾ç¤ºæ’åˆ—"ç”Ÿæˆæ–¹æ¡ˆ  
            5. é€‰æ‹©kå€¼åç‚¹å‡»"æµ‹è¯•"  
            6. æŸ¥çœ‹ç»“æœå¹¶å¯¼å‡º
            """)

    # ===== å³ä¾§ï¼šé¢„å¤„ç†è®¾ç½®å’Œå…‰è°±å¯è§†åŒ– =====
    with col_right:
        # ===== é¢„å¤„ç†è®¾ç½®ï¼ˆæ¨ªå‘æ’åˆ—åœ¨å…‰è°±å¯è§†åŒ–ä¸Šæ–¹ï¼Œä¸å››ç§ç®—æ³•åœ¨åŒä¸€è¡Œï¼‰=====
        st.subheader("âš™ï¸ é¢„å¤„ç†è®¾ç½®", divider="gray")

        # å¸ƒå±€åˆ—æ•°ä¿æŒ10åˆ—
        preprocess_cols = st.columns([1, 1, 1, 1, 1.2, 1.2, 1.2, 1.2, 1.2, 1.2], gap="small")

        # 1. åŸºçº¿æ ¡å‡†ï¼ˆç¬¬ä¸€åˆ—ï¼Œä¸å˜ï¼‰
        with preprocess_cols[0]:
            st.subheader("åŸºçº¿æ ¡å‡†")
            baseline_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "SD", "FD", "å¤šé¡¹å¼æ‹Ÿåˆ", "ModPoly", "I-ModPoly", "PLS", "AsLS", "airPLS", "äºŒé˜¶å·®åˆ†(D2)"],
                key="baseline_method",
                label_visibility="collapsed"
            )

            # åŸºçº¿å‚æ•°ï¼ˆä¸å˜ï¼‰
            baseline_params = {}
            if baseline_method != "æ— ":
                if baseline_method == "å¤šé¡¹å¼æ‹Ÿåˆ":
                    polyorder = st.slider("é˜¶æ•°k", 3, 6, 5, key="polyorder", label_visibility="collapsed")
                    baseline_params["polyorder"] = polyorder
                    st.caption(f"é˜¶æ•°: {polyorder}")
                elif baseline_method == "ModPoly":
                    k = st.slider("å‚æ•°k", 4, 10, 10, key="k_mod", label_visibility="collapsed")
                    baseline_params["k"] = k
                    st.caption(f"k: {k}")
                elif baseline_method == "I-ModPoly":  # IModPolyå‚æ•°è®¾ç½®
                    polyorder = st.slider("å¤šé¡¹å¼é˜¶æ•°", 3, 7, 5, key="imod_polyorder", label_visibility="collapsed")
                    max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 50, 200, 100, key="imod_maxiter", label_visibility="collapsed")
                    tolerance = st.slider("æ”¶æ•›å®¹å·®", 0.001, 0.01, 0.005, key="imod_tol", label_visibility="collapsed")
                    baseline_params["polyorder"] = polyorder
                    baseline_params["max_iter"] = max_iter
                    baseline_params["tolerance"] = tolerance
                    st.caption(f"é˜¶æ•°: {polyorder}, è¿­ä»£: {max_iter}, å®¹å·®: {tolerance}")
                elif baseline_method == "PLS":
                    lam = st.selectbox("Î»", [10 ** 10, 10 ** 8, 10 ** 7], key="lam_pls", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    st.caption(f"Î»: {lam}")
                elif baseline_method == "AsLS":
                    p = st.selectbox("éå¯¹ç§°ç³»æ•°p", [0.001, 0.01, 0.1], key="p_asls", label_visibility="collapsed")
                    lam = st.selectbox("å¹³æ»‘ç³»æ•°Î»", [10 ** 5, 10 ** 7, 10 ** 9], key="lam_asls",
                                       label_visibility="collapsed")
                    niter = st.selectbox("è¿­ä»£æ¬¡æ•°", [5, 10, 15], key="niter_asls", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    baseline_params["p"] = p
                    baseline_params["niter"] = niter
                    st.caption(f"p: {p}, Î»: {lam}, è¿­ä»£æ¬¡æ•°: {niter}")
                elif baseline_method == "airPLS":
                    lam = st.selectbox("Î»", [10 ** 7, 10 ** 4, 10 ** 2], key="lam_air", label_visibility="collapsed")
                    baseline_params["lam"] = lam
                    st.caption(f"Î»: {lam}")
                elif baseline_method == "äºŒé˜¶å·®åˆ†(D2)":  # äºŒé˜¶å·®åˆ†å‚æ•°è¯´æ˜
                    st.caption("äºŒé˜¶å·®åˆ†å¯å¢å¼ºå…‰è°±ç‰¹å¾ï¼ŒæŠ‘åˆ¶åŸºçº¿æ¼‚ç§»")

        # 2. ç¼©æ”¾å¤„ç†ï¼ˆç¬¬äºŒåˆ—ï¼Œä¸å˜ï¼‰
        with preprocess_cols[1]:
            st.subheader("ğŸ“ ç¼©æ”¾")
            scaling_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "Peak-Norm", "SNV", "MSC", "M-M-Norm", "L-èŒƒæ•°", "Ma-Minorm", "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)"],
                key="scaling_method",
                label_visibility="collapsed"
            )

            # ç¼©æ”¾å‚æ•°ï¼ˆä¸å˜ï¼‰
            scaling_params = {}
            if scaling_method == "L-èŒƒæ•°":
                p = st.selectbox("p", ["æ— ç©·å¤§", "4", "10"], key="p_scale", label_visibility="collapsed")
                scaling_params["p"] = p
                st.caption(f"p: {p}")
            elif scaling_method == "æ ‡å‡†åŒ–(å‡å€¼0ï¼Œæ–¹å·®1)":
                st.caption("å°†æ•°æ®æ ‡å‡†åŒ–åˆ°å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1")

        # 3. æ»¤æ³¢å¤„ç†ï¼ˆç¬¬ä¸‰åˆ—ï¼Œä¸å˜ï¼‰
        with preprocess_cols[2]:
            st.subheader("ğŸ“¶ æ»¤æ³¢")
            filtering_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "Savitzky-Golay", "sgolayfiltæ»¤æ³¢å™¨", "ä¸­å€¼æ»¤æ³¢(MF)", "ç§»åŠ¨å¹³å‡(MAF)",
                 "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰", "MWMï¼ˆç§»åŠ¨çª—å£ä¸­å€¼ï¼‰", "å¡å°”æ›¼æ»¤æ³¢", "Lowess", "FFT",
                 "Smfftå‚…é‡Œå¶æ»¤æ³¢", "å°æ³¢å˜æ¢(DWT)", "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª"],
                key="filtering_method",
                label_visibility="collapsed"
            )

            # æ»¤æ³¢å‚æ•°ï¼ˆä¸å˜ï¼‰
            filtering_params = {}
            if filtering_method != "æ— ":
                if filtering_method in ["Savitzky-Golay", "sgolayfiltæ»¤æ³¢å™¨"]:
                    k = st.selectbox("å¤šé¡¹å¼é˜¶æ•°", [3, 7], key="k_sg", label_visibility="collapsed")
                    w = st.selectbox("çª—å£å¤§å°", [11, 31, 51], key="w_sg", label_visibility="collapsed")
                    filtering_params["window_length"] = w
                    filtering_params["polyorder"] = k
                    st.caption(f"é˜¶æ•°: {k}, çª—å£: {w}")
                elif filtering_method in ["ä¸­å€¼æ»¤æ³¢(MF)", "ç§»åŠ¨å¹³å‡(MAF)"]:
                    k = st.selectbox("k", [1, 3], key="k_mf", label_visibility="collapsed")
                    w = st.selectbox("w", [7, 11], key="w_mf", label_visibility="collapsed")
                    filtering_params["k"] = k
                    filtering_params["w"] = w
                    st.caption(f"k: {k}, w: {w}")
                elif filtering_method == "MWAï¼ˆç§»åŠ¨çª—å£å¹³å‡ï¼‰":
                    n = st.selectbox("çª—å£å¤§å°n", [4, 6, 8], key="n_mwa", label_visibility="collapsed")
                    it = st.selectbox("è¿­ä»£æ¬¡æ•°it", [1, 2, 3], key="it_mwa", label_visibility="collapsed")
                    filtering_params["n"] = n
                    filtering_params["it"] = it
                    filtering_params["mode"] = "full"
                    st.caption(f"çª—å£å¤§å°: {n}, è¿­ä»£æ¬¡æ•°: {it}")
                elif filtering_method == "MWMï¼ˆç§»åŠ¨çª—å£ä¸­å€¼ï¼‰":
                    n = st.selectbox("çª—å£å¤§å°n", [5, 7, 9], key="n_mwm", label_visibility="collapsed")
                    it = st.selectbox("è¿­ä»£æ¬¡æ•°it", [1, 2, 3], key="it_mwm", label_visibility="collapsed")
                    filtering_params["n"] = n
                    filtering_params["it"] = it
                    st.caption(f"çª—å£å¤§å°: {n}, è¿­ä»£æ¬¡æ•°: {it}")
                elif filtering_method == "å¡å°”æ›¼æ»¤æ³¢":
                    R = st.selectbox("æµ‹é‡å™ªå£°æ–¹å·®R", [0.01, 0.1, 0.5], key="r_kalman", label_visibility="collapsed")
                    filtering_params["R"] = R
                    st.caption(f"æµ‹é‡å™ªå£°æ–¹å·®: {R}")
                elif filtering_method == "Lowess":
                    frac = st.selectbox("ç³»æ•°", [0.01, 0.03], key="frac_low", label_visibility="collapsed")
                    filtering_params["frac"] = frac
                    st.caption(f"ç³»æ•°: {frac}")
                elif filtering_method == "FFT":
                    cutoff = st.selectbox("é¢‘ç‡", [30, 50, 90], key="cutoff_fft", label_visibility="collapsed")
                    filtering_params["cutoff"] = cutoff
                    st.caption(f"é¢‘ç‡: {cutoff}")
                elif filtering_method == "Smfftå‚…é‡Œå¶æ»¤æ³¢":
                    row_e = st.selectbox("ä¿ç•™ä½é¢‘åˆ†é‡æ•°", [31, 51, 71], key="row_e_smfft",
                                         label_visibility="collapsed")
                    filtering_params["row_e"] = row_e
                    st.caption(f"ä¿ç•™ä½é¢‘åˆ†é‡æ•°: {row_e}")
                elif filtering_method == "å°æ³¢å˜æ¢(DWT)":
                    threshold = st.selectbox("é˜ˆå€¼", [0.1, 0.3, 0.5], key="thresh_dwt", label_visibility="collapsed")
                    filtering_params["threshold"] = threshold
                    st.caption(f"é˜ˆå€¼: {threshold}")
                elif filtering_method == "å°æ³¢çº¿æ€§é˜ˆå€¼å»å™ª":
                    threshold = st.selectbox("é˜ˆå€¼", [0.1, 0.3, 0.5], key="thresh_wavelet_linear",
                                             label_visibility="collapsed")
                    filtering_params["threshold"] = threshold
                    st.caption(f"é˜ˆå€¼: {threshold}")

        # 4. æŒ¤å‹å¤„ç†ï¼ˆç¬¬å››åˆ—ï¼Œä¸å˜ï¼‰
        with preprocess_cols[3]:
            st.subheader("ğŸ§ª æŒ¤å‹")
            squashing_method = st.selectbox(
                "æ–¹æ³•",
                ["æ— ", "SigmoidæŒ¤å‹", "æ”¹è¿›çš„SigmoidæŒ¤å‹", "é€»è¾‘å‡½æ•°", "ä½™å¼¦æŒ¤å‹(squashing)", "æ”¹è¿›çš„é€»è¾‘å‡½æ•°",
                 "DTWæŒ¤å‹"],
                key="squashing_method",
                label_visibility="collapsed"
            )

            # æŒ¤å‹å‚æ•°ï¼ˆä¸å˜ï¼‰
            squashing_params = {}
            if squashing_method != "æ— ":
                if squashing_method == "æ”¹è¿›çš„é€»è¾‘å‡½æ•°":
                    st.caption("åŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢ï¼Œæ— é¢å¤–å‚æ•°")
                elif squashing_method == "æ”¹è¿›çš„SigmoidæŒ¤å‹":
                    maxn = st.selectbox("maxn", [5, 10, 15], key="maxn_isigmoid", label_visibility="collapsed")
                    squashing_params["maxn"] = maxn
                    st.caption(f"maxn: {maxn}")
                elif squashing_method == "DTWæŒ¤å‹":
                    l = st.selectbox("l", [1, 5], key="l_dtw", label_visibility="collapsed")
                    k1 = st.selectbox("k1", ["T", "F"], key="k1_dtw", label_visibility="collapsed")
                    k2 = st.selectbox("k2", ["T", "F"], key="k2_dtw", label_visibility="collapsed")

                    squashing_params["l"] = l
                    squashing_params["k1"] = k1
                    squashing_params["k2"] = k2
                    st.caption(f"l: {l}, k1: {k1}, k2: {k2}")
                elif squashing_method == "SigmoidæŒ¤å‹":
                    st.caption("ä½¿ç”¨æ ‡å‡†Sigmoidå‡½æ•°ï¼Œæ— é¢å¤–å‚æ•°")
                elif squashing_method == "ä½™å¼¦æŒ¤å‹(squashing)":
                    st.caption("ä½¿ç”¨åŸºäºä½™å¼¦çš„æŒ¤å‹å˜æ¢ï¼Œæ— é¢å¤–å‚æ•°")
                elif squashing_method == "é€»è¾‘å‡½æ•°":
                    st.caption("æ— é¢å¤–å‚æ•°")

        # 5-10åˆ—ï¼šæ“ä½œç›¸å…³å†…å®¹
        # åŸæ“ä½œ2 â†’ æ–°æ“ä½œ1ï¼šæ˜¾ç¤ºæ’åˆ—ä¸ç­›é€‰ï¼ˆç¬¬4åˆ—ï¼Œä¸å˜ï¼‰
        with preprocess_cols[4]:
            st.subheader("æ“ä½œ1")
            # åº”ç”¨å¤„ç†æŒ‰é’®ï¼ˆç§»é™¤äº†æ¨èåº”ç”¨æŒ‰é’®ï¼‰
            if st.button("ğŸš€ åº”ç”¨å¤„ç†", type="primary", use_container_width=True, key="apply_btn"):
                if st.session_state.raw_data is None:
                    st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                else:
                    try:
                        wavenumbers, y = st.session_state.raw_data
                        processed_data, method_name = preprocessor.process(
                            wavenumbers, y,
                            baseline_method=baseline_method,
                            baseline_params=baseline_params,
                            squashing_method=squashing_method,
                            squashing_params=squashing_params,
                            filtering_method=filtering_method,
                            filtering_params=filtering_params,
                            scaling_method=scaling_method,
                            scaling_params=scaling_params
                        )

                        arr_name = f"æ’åˆ—_{len(st.session_state.arrangement_results) + 1}"
                        st.session_state.arrangement_results.append(arr_name)
                        st.session_state.arrangement_details[arr_name] = {
                            'data': processed_data,
                            'method': " â†’ ".join(method_name),
                            'params': current_algorithms
                        }
                        st.session_state.selected_arrangement = arr_name
                        st.session_state.processed_data = (wavenumbers, processed_data)
                        st.session_state.process_method = " â†’ ".join(method_name)
                        st.success(f"âœ… å¤„ç†å®Œæˆ")

                    except Exception as e:
                        st.error(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")

        with preprocess_cols[4]:
            st.subheader("æ“ä½œ1")

            # æ˜¾ç¤ºæ’åˆ—æŒ‰é’®ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
            if st.button("ğŸ” æ˜¾ç¤ºæ’åˆ—", type="secondary", use_container_width=True, key="show_perm_btn"):
                st.session_state.show_arrangements = not st.session_state.show_arrangements

                if st.session_state.show_arrangements:
                    # åŠ¨æ€æ„å»º selected_algorithms å­—å…¸
                    selected_algorithms = {
                        'baseline': {
                            'method': baseline_method,  # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ç®—æ³•
                            'params': baseline_params if baseline_method != 'æ— ' else {}  # æ ¹æ®ç”¨æˆ·é€‰æ‹©ä¼ é€’å‚æ•°
                        },
                        'scaling': {
                            'method': scaling_method,  # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ç®—æ³•
                            'params': scaling_params if scaling_method != 'æ— ' else {}
                        },
                        'filtering': {
                            'method': filtering_method,  # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ç®—æ³•
                            'params': filtering_params if filtering_method != 'æ— ' else {}
                        },
                        'squashing': {
                            'method': squashing_method,  # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ç®—æ³•
                            'params': squashing_params if squashing_method != 'æ— ' else {}
                        }
                    }

                    # st.write("selected_algorithms: ", selected_algorithms)
                    # ç”Ÿæˆæ’åˆ—ç»„åˆå¹¶å­˜å‚¨ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
                    st.session_state.algorithm_permutations = generate_permutations(selected_algorithms)

                    st.session_state.filtered_perms = st.session_state.algorithm_permutations
                    # st.success(f"âœ… ç”Ÿæˆäº† {len(st.session_state.algorithm_permutations)} ç§æ’åˆ—ç»„åˆ")
                    # st.write("ç”Ÿæˆçš„æ’åˆ—ç»„åˆ: ", st.session_state.algorithm_permutations)

                    # è·å–ç”¨æˆ·è¾“å…¥çš„æ ‡ç­¾ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
                    if 'labels' not in st.session_state or st.session_state.labels is None:
                        st.error("âŒ æ ‡ç­¾å°šæœªè®¾ç½®ï¼è¯·å…ˆé€šè¿‡ä¸»å‡½æ•°è·å–å¹¶éªŒè¯æ ‡ç­¾ã€‚")
                        return

                    labels = st.session_state.labels  # è·å–å·²å­˜å‚¨çš„æ ‡ç­¾
                    # st.write("æ ‡ç­¾å·²åŠ è½½ï¼š", labels)

                    # è·å–åŸå§‹å…‰è°±æ•°æ®å¹¶è¿›è¡Œå¤„ç†ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
                    if st.session_state.get('raw_data'):
                        wavenumbers, y = st.session_state.raw_data
                        S = len(labels)
                        P = len(st.session_state.algorithm_permutations)
                        N = len(wavenumbers)
                        # st.write("[CHECK] S, P, N =", S, P, N)
                        # st.write("[CHECK] raw_data shapes -> y:", np.asarray(y).shape, "; wavenumbers:",len(wavenumbers))
                        # --- 1) æ„å»º (S, P, N) çš„ä¸‰ç»´ç«‹æ–¹ä½“ ---
                        processed_cube = np.empty((S, P, N), dtype=np.float32)

                        y_arr = np.asarray(y)

                        def get_spectrum_j(j_idx: int) -> np.ndarray:
                            if y_arr.ndim == 2:
                                if y_arr.shape[0] == N and y_arr.shape[1] == S:  # NÃ—S
                                    return y_arr[:, j_idx]
                                elif y_arr.shape[0] == S and y_arr.shape[1] == N:  # SÃ—N
                                    return y_arr[j_idx, :]
                                else:
                                    raise ValueError(
                                        f"åŸå§‹å…‰è°±çŸ©é˜µç»´åº¦ä¸åŒ¹é…ï¼ŒæœŸæœ›å«æœ‰ N={N} ä¸ S={S} ä¹‹ä¸€çš„ç»´åº¦ï¼Œå½“å‰å½¢çŠ¶={y_arr.shape}")
                            elif y_arr.ndim == 1:
                                raise ValueError("åŸå§‹å…‰è°±åªæœ‰ 1 æ¡ï¼Œæ— æ³•æ„å»º (S,P,N) ç«‹æ–¹ä½“ã€‚")
                            else:
                                raise ValueError(f"ä¸æ”¯æŒçš„åŸå§‹å…‰è°±ç»´åº¦ï¼š{y_arr.ndim}")

                        # st.write(f"[CHECK] algorithm_permutations:", st.session_state.algorithm_permutations)

                        #éå†å¡«å……ç«‹æ–¹ä½“ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
                        for j in range(S):
                            spec_j = get_spectrum_j(j).astype(np.float32)
                            # st.write(f"[CHECK] ç¬¬ {j + 1} æ¡å…‰è°±æ•°æ®ï¼š", spec_j)  # è¾“å‡ºå½“å‰å…‰è°±æ•°æ®
                            if spec_j.shape[0] != N:
                                raise ValueError(f"ç¬¬ {j + 1} æ¡å…‰è°±é•¿åº¦ {spec_j.shape[0]} ä¸æ³¢æ•°é•¿åº¦ N={N} ä¸ä¸€è‡´ã€‚")

                            for i, perm in enumerate(st.session_state.algorithm_permutations):
                                # st.write(f"[CHECK] perm {i}: {perm}")
                                algorithm_order = perm.get('order', [])  # è·å–é¡ºåº
                                # st.write(f"[CHECK] algorithm_order: {algorithm_order}")
                                # st.write(f"[CHECK] perm['details']: {perm['details']}")

                                # ä» details ä¸­è·å–æ¯ä¸ªç®—æ³•çš„å‚æ•°
                                bm = next((step[2] for step in perm['details'] if step[1] == 'åŸºçº¿æ ¡å‡†'), 'æ— ')
                                sm = next((step[2] for step in perm['details'] if step[1] == 'ç¼©æ”¾'), 'æ— ')
                                fm = next((step[2] for step in perm['details'] if step[1] == 'æ»¤æ³¢'), 'æ— ')
                                qm = next((step[2] for step in perm['details'] if step[1] == 'æŒ¤å‹'), 'æ— ')

                                # è·å–å‚æ•°ï¼Œå¹¶ç¡®ä¿å®ƒä»¬æ˜¯å­—å…¸æ ¼å¼
                                baseline_params = next(
                                    (step[3] if isinstance(step[3], dict) else {'k': step[3]} for step in
                                     perm['details'] if step[1] == 'åŸºçº¿æ ¡å‡†'), {'k': 8})
                                scaling_params = next(
                                    (step[3] if isinstance(step[3], dict) else {} for step in perm['details'] if
                                     step[1] == 'ç¼©æ”¾'), {})
                                filtering_params = next(
                                    (step[3] if isinstance(step[3], dict) else {} for step in perm['details'] if
                                     step[1] == 'æ»¤æ³¢'), {})
                                squashing_params = next(
                                    (step[3] if isinstance(step[3], dict) else {} for step in perm['details'] if
                                     step[1] == 'æŒ¤å‹'), {})


                                processed_data, _method_name = preprocessor.process(
                                    wavenumbers, spec_j,
                                    baseline_method=bm, baseline_params=baseline_params,
                                    squashing_method=qm, squashing_params=squashing_params,
                                    filtering_method=fm, filtering_params=filtering_params,
                                    scaling_method=sm, scaling_params=scaling_params,
                                    algorithm_order=algorithm_order
                                )

                                # è¾“å‡ºå¤„ç†åçš„æ•°æ®
                                st.write(f"[CHECK] å¤„ç†åçš„æ•°æ® (æ’åˆ— {i + 1}): {processed_data}")

                                arr = np.asarray(processed_data, dtype=np.float32).reshape(-1)
                                #
                                # st.write(f"[CHECK] å­˜å…¥ processed_cube[{j}, {i}, :] çš„æ•°æ®: {arr}")

                        # st.write("[CHECK] processed_cube.shape =", processed_cube.shape)
                        # st.write("[CHECK] processed_cube[0, 0, :5] =", processed_cube[0, 0, :5].tolist())
                        # # --- 2) å…ƒä¿¡æ¯å†™å…¥ ---
                        # st.session_state.wavenumbers = np.asarray(wavenumbers)
                        # st.session_state.labels = np.asarray(labels, dtype=int)
                        # st.session_state.perm_info = [
                        #     {
                        #         "name": perm.get("name", f"æ–¹æ¡ˆ{i + 1}"),
                        #         "order": perm.get("order", []),
                        #         "params": perm.get("params", {})
                        #     }
                        #     for i, perm in enumerate(st.session_state.algorithm_permutations)
                        # ]
                        # st.session_state.processed_cube = processed_cube
                        # #--- 3) PCA+LDAè¯„ä¼°ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
                        # from sklearn.decomposition import PCA
                        # from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
                        #
                        # X_labels = st.session_state.labels
                        # pca_pred_matrix = np.empty((P, S), dtype=int)
                        # pca_acc = np.empty(P, dtype=np.float32)
                        #
                        # for p in range(P):
                        #     X_p = processed_cube[:, p, :]
                        #     n_components = min(max(1, S - 1), X_p.shape[1])
                        #     pca = PCA(n_components=n_components, svd_solver="auto", random_state=0)
                        #     Z = pca.fit_transform(X_p)
                        #
                        #     if np.unique(X_labels).size < 2:
                        #         y_hat = np.full(S, int(X_labels[0]), dtype=int)
                        #     else:
                        #         clf = LDA(solver="lsqr")
                        #         clf.fit(Z, X_labels)
                        #         y_hat = clf.predict(Z)
                        #
                        #     pca_pred_matrix[p, :] = y_hat
                        #     pca_acc[p] = (y_hat == X_labels).mean().astype(np.float32)
                        #
                        # #æ’åºä¸æŠ•ç¥¨ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
                        # st.session_state.pca_pred_matrix = pca_pred_matrix
                        # st.session_state.pca_acc = pca_acc
                        #
                        # sorted_idx = np.argsort(-st.session_state.pca_acc, kind="mergesort")
                        # st.session_state.pca_sorted_perm_indices = sorted_idx
                        # st.session_state.pca_sorted_acc = st.session_state.pca_acc[sorted_idx]
                        # st.session_state.pca_sorted_pred_matrix = st.session_state.pca_pred_matrix[sorted_idx]
                        #
                        # st.write("[CHECK] pca_pred_matrix.shape =", st.session_state.pca_pred_matrix.shape)
                        # st.write("[CHECK] pca_acc.shape =", st.session_state.pca_acc.shape)
                        # st.write("[CHECK] top-5 acc =", st.session_state.pca_sorted_acc[:5].round(3).tolist())
                        # st.write("[CHECK] top-1 preds =", st.session_state.pca_sorted_pred_matrix[0].tolist())
                        #
                        # from scipy.stats import mode
                        # P2, S2 = st.session_state.pca_sorted_pred_matrix.shape
                        # vote_pred_matrix_by_k = np.empty((P2, S2), dtype=int)
                        #
                        # for k in range(1, P2 + 1):
                        #     topk = st.session_state.pca_sorted_pred_matrix[:k, :]
                        #     voted = mode(topk, axis=0, keepdims=False).mode
                        #     vote_pred_matrix_by_k[k - 1, :] = voted
                        #
                        # st.session_state.vote_pred_matrix_by_k = vote_pred_matrix_by_k
                        # vote_acc_by_k = (vote_pred_matrix_by_k == st.session_state.labels.reshape(1, S2)).mean(
                        #     axis=1).astype(np.float32)
                        # st.session_state.vote_acc_by_k = vote_acc_by_k
                        #
                        # st.write("[CHECK] vote_pred_matrix_by_k.shape =", st.session_state.vote_pred_matrix_by_k.shape)
                        # st.write("[CHECK] vote_acc_by_k[:5] =", st.session_state.vote_acc_by_k[:5].round(3).tolist())
                        # st.write("[CHECK] k=5 voted preds =",st.session_state.vote_pred_matrix_by_k[4].tolist() if P2 >= 5 else "P<5")
                        # k_vals = np.arange(1, st.session_state.vote_acc_by_k.shape[0] + 1)
                        # best_k = int(k_vals[np.argmax(st.session_state.vote_acc_by_k)])
                        # best_acc = float(st.session_state.vote_acc_by_k.max())
                        #
                        # import matplotlib.pyplot as plt
                        # fig, ax = plt.subplots()
                        # ax.plot(k_vals, st.session_state.vote_acc_by_k, marker='o')
                        # ax.set_xlabel('kï¼ˆå‰kä¸ªæ–¹æ¡ˆæŠ•ç¥¨ï¼‰')
                        # ax.set_ylabel('Accuracy')
                        # ax.set_title(f'kå€¼æ›²çº¿ï¼ˆæœ€ä½³k={best_k}, acc={best_acc:.3f}ï¼‰')
                        # ax.set_xlim(1, k_vals[-1])
                        # ax.set_ylim(0, 1)
                        # ax.grid(True, linestyle='--', alpha=0.4)
                        # st.pyplot(fig)
                        #
                        # st.write("[CHECK] best k =", best_k, "; preds =",
                        #          st.session_state.vote_pred_matrix_by_k[best_k - 1].tolist())
                        # st.success(
                        #     f"âœ… å·²æ„å»ºç«‹æ–¹ä½“ processed_cube å½¢çŠ¶ = {processed_cube.shape}ï¼Œå¹¶å®Œæˆ {P} ä¸ªæ–¹æ¡ˆçš„ PCA è¯„ä¼°ã€‚")

                    else:
                        st.error("âŒ è¯·å…ˆä¸Šä¼ åŸå§‹å…‰è°±æ•°æ®")
            else:
                st.session_state.filtered_perms = []

        # åŸæ“ä½œ3 â†’ æ–°æ“ä½œ2ï¼šæ’åˆ—é€‰æ‹©ä¸åº”ç”¨ï¼ˆç¬¬5åˆ—ï¼Œä¸å˜ï¼‰
        with preprocess_cols[5]:
            st.subheader("æ“ä½œ2")
            # æ’åˆ—ä¸‹æ‹‰æ¡†ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
            if st.session_state.show_arrangements and st.session_state.filtered_perms:
                st.session_state.selected_perm_idx = st.selectbox(
                    f"é€‰æ‹©æ–¹æ¡ˆï¼ˆå…±{len(st.session_state.filtered_perms)}ç§ï¼‰",
                    range(len(st.session_state.filtered_perms)),
                    format_func=lambda x: st.session_state.filtered_perms[x].get("name", f"æ–¹æ¡ˆ{x + 1}"),
                    key="perm_select",
                    label_visibility="collapsed",
                    help="é€‰æ‹©é¢„å¤„ç†ç®—æ³•é¡ºåº"
                )

                # åº”ç”¨æ’åˆ—æŒ‰é’®ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
                try:
                    selected_perm = st.session_state.filtered_perms[st.session_state.selected_perm_idx]
                    st.caption(f"å½“å‰: {selected_perm.get('name', 'æœªçŸ¥')}")

                    if st.button("âœ… åº”ç”¨æ–¹æ¡ˆ", type="primary", use_container_width=True, key="apply_perm_btn"):
                        if st.session_state.raw_data is None:
                            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                        else:
                            try:
                                algos = {
                                    'baseline': baseline_method,
                                    'baseline_params': baseline_params,
                                    'squashing': squashing_method,
                                    'squashing_params': squashing_params,
                                    'filtering': filtering_method,
                                    'filtering_params': filtering_params,
                                    'scaling': scaling_method,
                                    'scaling_params': scaling_params,
                                }
                                wavenumbers, y = st.session_state.raw_data
                                processed_data, method_name = preprocessor.process(
                                    wavenumbers, y,
                                    baseline_method=baseline_method,
                                    baseline_params=baseline_params,
                                    squashing_method=squashing_method,
                                    squashing_params=squashing_params,
                                    filtering_method=filtering_method,
                                    filtering_params=filtering_params,
                                    scaling_method=scaling_method,
                                    scaling_params=scaling_params,
                                    algorithm_order=selected_perm.get('order', [])
                                )

                                arr_name = f"æ’åˆ—_{len(st.session_state.arrangement_results) + 1}"
                                st.session_state.arrangement_results.append(arr_name)
                                st.session_state.arrangement_details[arr_name] = {
                                    'data': processed_data,
                                    'method': " â†’ ".join(method_name),
                                    'order': selected_perm.get('order', []),
                                    'params': algos
                                }
                                st.session_state.selected_arrangement = arr_name
                                st.session_state.processed_data = (wavenumbers, processed_data)
                                st.session_state.process_method = " â†’ ".join(method_name)
                                st.success(f"âœ… æ–¹æ¡ˆåº”ç”¨å®Œæˆ")
                            except Exception as e:
                                st.error(f"âŒ åº”ç”¨å¤±è´¥: {str(e)}")
                except Exception as e:
                    st.error(f"âŒ æ–¹æ¡ˆå¤„ç†é”™è¯¯: {str(e)}")
            else:
                if st.session_state.show_arrangements:
                    st.info("â„¹ï¸ æ— ç¬¦åˆæ¡ä»¶çš„æ–¹æ¡ˆ")

        # ã€ä¿®æ”¹ã€‘æ“ä½œ3ï¼šä»…ä¿ç•™è®¡ç®—kå€¼æŒ‰é’®ï¼ˆç¬¬6åˆ—ï¼‰
        with preprocess_cols[6]:
            st.subheader("æ“ä½œ3")
            # åªä¿ç•™è®¡ç®—kå€¼æŒ‰é’®ï¼Œç§»é™¤ç»“æœæ˜¾ç¤ºç›¸å…³å…ƒç´ 
            if st.button("ğŸ”¢ è®¡ç®—kå€¼", type="secondary", use_container_width=True, key="calc_k_btn"):
                # æš‚å­˜è®¡ç®—ç»“æœï¼ˆé€»è¾‘åç»­è¡¥å……ï¼‰
                st.session_state.calc_k_result = 5  # ç¤ºä¾‹é»˜è®¤å€¼
                st.success("âœ… kå€¼è®¡ç®—å®Œæˆ")

        # ã€ä¿®æ”¹ã€‘æ“ä½œ4ï¼šæ˜¾ç¤ºkå€¼ç»“æœï¼ˆç¬¬7åˆ—ï¼‰
        with preprocess_cols[7]:
            st.subheader("kå€¼ç»“æœä¸º")  # æ–‡æœ¬æ”¹ä¸º"kå€¼ç»“æœä¸º"
            # ç§»é™¤kå€¼è®¾ç½®è¾“å…¥æ¡†å’Œç¡®å®šæŒ‰é’®ï¼Œä»…æ˜¾ç¤ºè®¡ç®—åçš„kå€¼
            calc_k_result = st.session_state.get('calc_k_result', "æœªè®¡ç®—")
            st.info(f" {calc_k_result}")

        # ã€æ–°å¢ã€‘æ“ä½œ5ï¼šé€‰æ‹©kå€¼ï¼ˆç¬¬8åˆ—ï¼Œä¸å˜ï¼‰
        with preprocess_cols[8]:
            st.subheader("æ“ä½œ5")
            # é€‰æ‹©kå€¼æŒ‰é’®
            if st.button("ğŸ“Œ é€‰æ‹©kå€¼", type="secondary", use_container_width=True, key="select_k_btn"):
                # æš‚å­˜é€‰æ‹©çŠ¶æ€
                st.session_state.selected_k = st.session_state.get('calc_k_result', "æœªé€‰æ‹©")
                st.success(f"âœ… å·²é€‰æ‹©kå€¼ï¼š{st.session_state.selected_k}")
            # æ˜¾ç¤ºå½“å‰é€‰æ‹©çš„kå€¼
            selected_k = st.session_state.get('selected_k', "æœªé€‰æ‹©")
            st.caption(f"å½“å‰é€‰æ‹©ï¼š{selected_k}")

        # åŸæ“ä½œ5 â†’ æ–°æ“ä½œ6ï¼šæµ‹è¯•æŒ‰é’®ï¼ˆç¬¬9åˆ—ï¼Œä¸å˜ï¼‰
        with preprocess_cols[9]:
            st.subheader("æ“ä½œ6")
            # æµ‹è¯•æŒ‰é’®ï¼ˆåŸé€»è¾‘ä¸å˜ï¼‰
            if st.button("æµ‹è¯•", type="primary", use_container_width=True, key="test_btn"):
                if st.session_state.raw_data is None:
                    st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
                elif st.session_state.selected_arrangement is None:
                    st.warning("âš ï¸ è¯·å…ˆåº”ç”¨æ’åˆ—æ–¹æ¡ˆ")
                elif st.session_state.labels is None:
                    st.warning("âš ï¸ è¯·å…ˆè¾“å…¥æ ‡ç­¾")
                elif st.session_state.train_indices is None:
                    st.warning("âš ï¸ æ— æ³•åˆ’åˆ†è®­ç»ƒé›†")
                else:
                    try:
                        selected_arr = st.session_state.selected_arrangement
                        processed_data = st.session_state.arrangement_details[selected_arr]['data']
                        train_idx = st.session_state.train_indices
                        test_idx = st.session_state.test_indices

                        train_data = processed_data[:, train_idx]
                        test_data = processed_data[:, test_idx]
                        train_labels = st.session_state.labels[train_idx]
                        test_labels = st.session_state.labels[test_idx]

                        with st.spinner("æµ‹è¯•ä¸­..."):
                            # ä½¿ç”¨é€‰æ‹©çš„kå€¼è¿›è¡Œæµ‹è¯•
                            predictions = knn_classify(
                                train_data,
                                train_labels,
                                test_data,
                                k=st.session_state.get('selected_k', 1)  # ä¼˜å…ˆä½¿ç”¨é€‰æ‹©çš„kå€¼
                            )

                        accuracy = accuracy_score(test_labels, predictions)
                        kappa = cohen_kappa_score(test_labels, predictions)
                        cm = confusion_matrix(test_labels, predictions)

                        st.session_state.test_results = {
                            'accuracy': accuracy,
                            'kappa': kappa,
                            'confusion_matrix': cm,
                            'predictions': predictions,
                            'test_labels': test_labels
                        }

                        st.success("âœ… æµ‹è¯•å®Œæˆï¼ç»“æœåœ¨ä¸‹æ–¹")

                    except Exception as e:
                        st.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")

        # ä¿å­˜å½“å‰é€‰æ‹©çš„ç®—æ³•ï¼ˆä¸å˜ï¼‰
        current_algorithms = {
            'baseline': baseline_method,
            'baseline_params': baseline_params,
            'scaling': scaling_method,
            'scaling_params': scaling_params,
            'filtering': filtering_method,
            'filtering_params': filtering_params,
            'squashing': squashing_method,
            'squashing_params': squashing_params
        }
        st.session_state.current_algorithms = current_algorithms

        # ===== å…‰è°±å¯è§†åŒ–ä¸ç»“æœå¯¼å‡ºï¼ˆåœ¨é¢„å¤„ç†è®¾ç½®ä¸‹æ–¹ï¼‰=====
        st.subheader("ğŸ“ˆ å…‰è°±å¯è§†åŒ–", divider="gray")

        # åˆ›å»ºå››ä¸ªå›ºå®šåŒºåŸŸçš„å¸ƒå±€ï¼šåŸå§‹å…‰è°±ã€é¢„å¤„ç†åå…‰è°±ã€kå€¼æ›²çº¿ã€æ··æ·†çŸ©é˜µ
        # ç¬¬ä¸€è¡Œï¼šåŸå§‹å…‰è°±å’Œé¢„å¤„ç†åå…‰è°±
        viz_row1 = st.columns(2, gap="medium")

        # ç¬¬äºŒè¡Œï¼škå€¼æ›²çº¿å’Œæ··æ·†çŸ©é˜µ
        viz_row2 = st.columns(2, gap="medium")

        # 1. åŸå§‹å…‰è°±åŒºåŸŸï¼ˆç¬¬ä¸€è¡Œç¬¬ä¸€åˆ—ï¼‰- éšæœºæ˜¾ç¤ºä¸€ä¸ªåŸå§‹å…‰è°±
        with viz_row1[0]:
            st.subheader("åŸå§‹å…‰è°±", divider="gray")
            if st.session_state.get('raw_data'):
                wavenumbers, y = st.session_state.raw_data
                # ç¡®ä¿yæ˜¯äºŒç»´æ•°ç»„ï¼ˆNÃ—Sï¼‰ï¼Œå–éšæœºåˆ—ç´¢å¼•
                num_samples = y.shape[1] if y.ndim == 2 else 1
                random_idx = np.random.randint(0, num_samples)  # éšæœºé€‰æ‹©ä¸€ä¸ªå…‰è°±
                # æ˜¾ç¤ºéšæœºé€‰æ‹©çš„åŸå§‹å…‰è°±
                raw_data = pd.DataFrame({f"åŸå§‹å…‰è°±ï¼ˆéšæœºï¼‰": y[:, random_idx]}, index=wavenumbers)
                st.line_chart(raw_data, height=250)
                st.caption(f"éšæœºå±•ç¤ºç¬¬ {random_idx + 1}/{num_samples} æ¡åŸå§‹å…‰è°±")
            else:
                st.markdown(
                    '<div style="border:1px dashed #ccc; height:250px; display:flex; align-items:center; justify-content:center;">ç­‰å¾…åŠ è½½åŸå§‹æ•°æ®</div>',
                    unsafe_allow_html=True)

        # 2. é¢„å¤„ç†åå…‰è°±åŒºåŸŸï¼ˆç¬¬ä¸€è¡Œç¬¬äºŒåˆ—ï¼‰
        with viz_row1[1]:
            st.subheader("é¢„å¤„ç†åçš„å…‰è°±", divider="gray")
            if st.session_state.get('selected_arrangement'):
                selected_arr = st.session_state.selected_arrangement
                arr_data = st.session_state.arrangement_details[selected_arr]['data']
                arr_method = st.session_state.arrangement_details[selected_arr]['method']
                st.caption(f"å¤„ç†æ–¹æ³•: {arr_method}")

                idx1 = 0 if arr_data.shape[1] > 0 else 0
                proc_data1 = pd.DataFrame({"é¢„å¤„ç†å1": arr_data[:, idx1]}, index=wavenumbers)
                st.line_chart(proc_data1, height=250)

                # æ˜¾ç¤ºæ›´å¤šé¢„å¤„ç†åå…‰è°±ï¼ˆä¸ä½¿ç”¨åµŒå¥—åˆ—ï¼‰
                if arr_data.shape[1] > 1:
                    with st.expander("æŸ¥çœ‹æ›´å¤šé¢„å¤„ç†åå…‰è°±", expanded=False):
                        for i in range(1, min(arr_data.shape[1], 5)):
                            st.subheader(f"é¢„å¤„ç†å{i + 1}", divider="gray")
                            data = pd.DataFrame({f"é¢„å¤„ç†å{i + 1}": arr_data[:, i]}, index=wavenumbers)
                            st.line_chart(data, height=150)
            else:
                st.markdown(
                    '<div style="border:1px dashed #ccc; height:250px; display:flex; align-items:center; justify-content:center;">è¯·å…ˆåº”ç”¨é¢„å¤„ç†æ–¹æ¡ˆ</div>',
                    unsafe_allow_html=True)

        # 3. kå€¼æ›²çº¿åŒºåŸŸï¼ˆç¬¬äºŒè¡Œç¬¬ä¸€åˆ—ï¼‰
        with viz_row2[0]:
            st.subheader("kå€¼æ›²çº¿", divider="gray")
            with st.container():
                if st.session_state.get('selected_arrangement'):
                    selected_arr = st.session_state.selected_arrangement
                    arr_data = st.session_state.arrangement_details[selected_arr]['data']
                    wavenumbers, y = st.session_state.raw_data
                    arr_order = st.session_state.arrangement_details[selected_arr].get('order', [])

                    if arr_order:  # åªæœ‰åº”ç”¨äº†é¢„å¤„ç†æ‰æœ‰kå€¼æ›²çº¿
                        idx1 = 0 if arr_data.shape[1] > 0 else 0
                        k_vals1 = np.abs(arr_data[:, 0] / (y[:, 0] + 1e-8)) if y.shape[1] > 0 else np.array([])
                        k_data1 = pd.DataFrame({"kå€¼1": k_vals1}, index=wavenumbers)
                        st.line_chart(k_data1)

                        # æ˜¾ç¤ºæ›´å¤škå€¼æ›²çº¿ï¼ˆæŠ˜å é¢æ¿ï¼‰
                        if y.shape[1] > 1:
                            with st.expander("æŸ¥çœ‹æ›´å¤škå€¼æ›²çº¿", expanded=False):
                                for i in range(1, min(y.shape[1], 5)):
                                    st.subheader(f"kå€¼{i + 1}", divider="gray")
                                    k_vals = np.abs(arr_data[:, i] / (y[:, i] + 1e-8))
                                    data = pd.DataFrame({f"kå€¼{i + 1}": k_vals}, index=wavenumbers)
                                    st.line_chart(data, height=150)
                    else:
                        st.info("â„¹ï¸ æ— é¢„å¤„ç†ï¼ˆåŸå§‹å…‰è°±ï¼‰ï¼Œä¸æ˜¾ç¤ºkå€¼æ›²çº¿")
                else:
                    st.markdown(
                        '<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">è¯·å…ˆåº”ç”¨é¢„å¤„ç†æ–¹æ¡ˆ</div>',
                        unsafe_allow_html=True)

        # 4. æ··æ·†çŸ©é˜µåŒºåŸŸï¼ˆç¬¬äºŒè¡Œç¬¬äºŒåˆ—ï¼‰
        with viz_row2[1]:
            st.subheader("æ··æ·†çŸ©é˜µ", divider="gray")
            st.markdown("""
                <style>
                [data-testid="stHorizontalBlock"] > [data-testid="stVerticalBlock"] {
                    height: 100% !important;
                }
                [data-testid="stMatplotlibChart"] {
                    margin: 0 !important;
                    padding: 0 !important;
                }
                </style>
            """, unsafe_allow_html=True)

            if st.session_state.get('test_results') is not None:
                results = st.session_state.test_results

                fig, ax = plt.subplots(figsize=(2.5, 1.5))
                sns.heatmap(
                    results['confusion_matrix'],
                    annot=True,
                    fmt='d',
                    cmap='Blues',
                    ax=ax,
                    annot_kws={"size": 4},
                    cbar_kws={"shrink": 0.9}
                )
                ax.set_xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=2, labelpad=2)
                ax.set_ylabel('çœŸå®æ ‡ç­¾', fontsize=2, labelpad=2)
                ax.set_title('æ··æ·†çŸ©é˜µ', fontsize=4, pad=4)
                plt.xticks(fontsize=3, rotation=0)
                plt.yticks(fontsize=3, rotation=0)
                plt.tight_layout(pad=0.1)
                st.pyplot(fig, use_container_width=True)
            else:
                st.markdown(
                    '<div style="border:1px dashed #ccc; height:200px; display:flex; align-items:center; justify-content:center;">è¯·å…ˆè¿›è¡Œåˆ†ç±»æµ‹è¯•</div>',
                    unsafe_allow_html=True)
        # ç»“æœå¯¼å‡º
        if st.session_state.arrangement_results or st.session_state.get('processed_data'):
            st.subheader("ğŸ’¾ ç»“æœå¯¼å‡º", divider="gray")
            export_cols = st.columns([3, 1], gap="small")
            with export_cols[0]:
                export_name = st.text_input("å¯¼å‡ºæ–‡ä»¶å", "processed_spectra.txt", key="export_name")
            with export_cols[1]:
                st.markdown("<br>", unsafe_allow_html=True)  # å‚ç›´å¯¹é½
                if st.button("å¯¼å‡º", type="secondary", key="export_btn"):
                    try:
                        if st.session_state.selected_arrangement:
                            arr_data = st.session_state.arrangement_details[st.session_state.selected_arrangement][
                                'data']
                            file_handler.export_data(export_name, arr_data)
                        else:
                            wavenumbers, y_processed = st.session_state.processed_data
                            file_handler.export_data(export_name, y_processed)
                        st.success(f"âœ… å·²å¯¼å‡ºåˆ° {export_name}")
                    except Exception as e:
                        st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")
        else:
            st.markdown(
                '<div style="border:1px dashed #ccc; height:80px; display:flex; align-items:center; justify-content:center;">å¤„ç†å®Œæˆåå¯å¯¼å‡ºç»“æœ</div>',
                unsafe_allow_html=True)


if __name__ == "__main__":
    main()
