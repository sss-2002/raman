import streamlit as st

class FileHandler:
    def load_data_from_zip(self, zip_file):
        """ä»å‹ç¼©åŒ…ä¸­åŠ è½½æ³¢æ•°å’Œå…‰è°±æ•°æ®ï¼Œè‡ªåŠ¨è¯†åˆ«æ•°æ®ç»´åº¦"""
        with zipfile.ZipFile(zip_file, 'r') as zf:
            # åˆ—å‡ºå‹ç¼©åŒ…ä¸­çš„æ‰€æœ‰æ–‡ä»¶
            file_list = zf.namelist()

            # å°è¯•è¯†åˆ«æ³¢æ•°æ–‡ä»¶å’Œå…‰è°±æ•°æ®æ–‡ä»¶
            wavenumber_files = [f for f in file_list if 'wave' in f.lower() or 'wn' in f.lower() or 'æ³¢æ•°' in f]
            data_files = [f for f in file_list if 'spec' in f.lower() or 'data' in f.lower() or 'å…‰è°±' in f]

            if not wavenumber_files:
                raise ValueError("å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°æ³¢æ•°æ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«'wave'ã€'wn'æˆ–'æ³¢æ•°'ï¼‰")
            if not data_files:
                raise ValueError("å‹ç¼©åŒ…ä¸­æœªæ‰¾åˆ°å…‰è°±æ•°æ®æ–‡ä»¶ï¼ˆé€šå¸¸åŒ…å«'spec'ã€'data'æˆ–'å…‰è°±'ï¼‰")

            # å–ç¬¬ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶
            wn_file = wavenumber_files[0]
            data_file = data_files[0]

            # è¯»å–æ³¢æ•°æ–‡ä»¶
            with zf.open(wn_file) as f:
                wavenumbers = np.loadtxt(f).ravel()

            # è¯»å–å…‰è°±æ•°æ®æ–‡ä»¶
            with zf.open(data_file) as f:
                content = f.read().decode("utf-8")
                data = self._parse_data(content)

            return wavenumbers, data.T

    def _parse_data(self, content):
        """è§£æå…‰è°±æ•°æ®å†…å®¹ï¼Œè‡ªåŠ¨è¯†åˆ«æ•°æ®ç»´åº¦"""
        numb = re.compile(r"-?\d+(?:\.\d+)?")
        lines_list = content.splitlines()

        # æå–æ‰€æœ‰æ•°å­—
        all_numbers = []
        for line in lines_list:
            all_numbers.extend(numb.findall(line))

        # å°è¯•ç¡®å®šæ•°æ®å½¢çŠ¶
        # å‡è®¾æ³¢æ•°é•¿åº¦ä¸ºæ•°æ®ç‚¹æ•°
        # å…‰è°±æ¡æ•° = æ€»æ•°æ®ç‚¹ / æ•°æ®ç‚¹æ•°
        # è¿™é‡Œå…ˆç®€å•å¤„ç†ä¸ºäºŒç»´æ•°ç»„
        data = np.array([float(num) for num in all_numbers])

        # å°è¯•åˆç†çš„å½¢çŠ¶ï¼ˆå‡è®¾æ¯è¡Œæ•°æ®ç‚¹å¤§è‡´ç›¸ç­‰ï¼‰
        # å…ˆæŒ‰è¡Œæ•°åˆ’åˆ†
        n_rows = len(lines_list)
        n_cols = len(data) // n_rows if n_rows > 0 else 0

        if n_cols * n_rows != len(data):
            # å¦‚æœæ— æ³•å®Œç¾åˆ’åˆ†ï¼Œè°ƒæ•´æœ€åä¸€è¡Œ
            n_cols = len(data) // n_rows + 1
            data = data[:n_rows * n_cols]  # æˆªæ–­å¤šä½™æ•°æ®

        return data.reshape(n_rows, n_cols)

    def export_data(self, filename, data):
        with open(filename, "w") as f:
            for line in data.T:  # è½¬ç½®å›åŸå§‹æ ¼å¼
                f.write("\t".join(map(str, line)) + "\n")

# ä½¿ç”¨ st.write æ˜¾ç¤ºæ–‡æœ¬
st.write("è¿™æ˜¯åœ¨Streamlitä¸Šæ˜¾ç¤ºçš„ä¸€æ®µè¯ã€‚")

# æˆ–è€…ä½¿ç”¨ st.text æ˜¾ç¤ºæ–‡æœ¬
st.text("è¿™æ˜¯åœ¨Streamlitä¸Šæ˜¾ç¤ºçš„ä¸€æ®µè¯ã€‚")
def main():
    # æœ€ä¼˜å…ˆåˆå§‹åŒ–session state
    if 'show_arrangements' not in st.session_state:
        st.session_state.show_arrangements = False

    # åˆå§‹åŒ–æµ‹è¯•ç›¸å…³çš„sessionçŠ¶æ€å˜é‡
    test_states = {
        'k_value': 5,  # é»˜è®¤kå€¼
        'test_results': None,  # å­˜å‚¨æµ‹è¯•ç»“æœ
        'labels': None,  # å­˜å‚¨æ ·æœ¬æ ‡ç­¾
        'train_indices': None,  # è®­ç»ƒé›†ç´¢å¼•
        'test_indices': None  # æµ‹è¯•é›†ç´¢å¼•
    }
    file_handler = FileHandler()
    preprocessor = Preprocessor()
    # åˆå§‹åŒ– current_algorithms å­—å…¸
    current_algorithms = {
        'baseline': 'æ— ',  # é»˜è®¤åŸºçº¿æ ¡æ­£æ–¹æ³•
        'baseline_params': {},
        'scaling': 'æ— ',  # é»˜è®¤ç¼©æ”¾æ–¹æ³•
        'scaling_params': {},
        'filtering': 'æ— ',  # é»˜è®¤æ»¤æ³¢æ–¹æ³•
        'filtering_params': {},
        'squashing': 'æ— ',  # é»˜è®¤æŒ¤å‹æ–¹æ³•
        'squashing_params': {}
    }

    # å°† current_algorithms å­˜å‚¨åˆ° session_state ä¸­ï¼Œä»¥ä¾¿å…¨å±€è®¿é—®
    st.session_state.setdefault('current_algorithms', current_algorithms)
    # åˆå§‹åŒ–å…¶ä»–å¿…è¦çš„sessionçŠ¶æ€å˜é‡
    other_states = {
        'raw_data': None,
        'processed_data': None,
        'peaks': None,
        'train_test_split_ratio': 0.8,
        'arrangement_results': [],
        'selected_arrangement': None,
        'arrangement_details': {},
        'algorithm_permutations': [],  # å­˜å‚¨ç®—æ³•æ’åˆ—ç»„åˆ
        'current_algorithms': {},  # å­˜å‚¨å½“å‰é€‰æ‹©çš„ç®—æ³•
        'filtered_perms': [],  # å­˜å‚¨ç­›é€‰åçš„æ’åˆ—æ–¹æ¡ˆ
        'selected_perm_idx': 0  # å­˜å‚¨å½“å‰é€‰ä¸­çš„æ’åˆ—ç´¢å¼•
    }

    # åˆå¹¶æ‰€æœ‰çŠ¶æ€å˜é‡å¹¶åˆå§‹åŒ–
    all_states = {**test_states, **other_states}
    for key, value in all_states.items():
        if key not in st.session_state:
            st.session_state[key] = value
    st.session_state['current_algorithms'] = current_algorithms
    # è®¾ç½®é¡µé¢ï¼šç´§å‡‘å¸ƒå±€
    st.set_page_config(layout="wide", page_icon="ğŸ”¬", page_title="æ’åˆ—é¢„å¤„ç†æ¨¡å‹")
    # å…¨å±€æ ·å¼è°ƒæ•´ï¼šæ›´ç´§å‡‘çš„å­—ä½“å’Œé—´è·ï¼Œç¡®ä¿é¢„å¤„ç†è®¾ç½®åœ¨ä¸€è¡Œæ˜¾ç¤º
    st.markdown("""
        <style>
        /* å…¨å±€å­—ä½“ç¼©å°ï¼Œç¡®ä¿é¢„å¤„ç†è®¾ç½®åœ¨ä¸€è¡Œæ˜¾ç¤º */
        body {font-size: 0.75rem !important;}
        .css-1v0mbdj {padding: 0.3rem 0.5rem !important;} /* å®¹å™¨å†…è¾¹è· */
        .css-1d391kg {padding: 0.2rem 0 !important;} /* æ ‡é¢˜é—´è· */
        .css-1x8cf1d {line-height: 1.1 !important;} /* æ–‡æœ¬è¡Œé«˜ */
        .css-12ttj6m {margin-bottom: 0.3rem !important;} /* ç»„ä»¶åº•éƒ¨é—´è· */
        .css-16huue1 {padding: 0.2rem 0.5rem !important; font-size: 0.7rem !important;} /* æŒ‰é’®å†…è¾¹è·å’Œå­—ä½“ */
        h3 {font-size: 1rem !important; margin: 0.3rem 0 !important;} /* å­æ ‡é¢˜ */
        .css-1b3298e {gap: 0.3rem !important;} /* åˆ—é—´è· */
        .stSlider, .stSelectbox, .stTextInput {margin-bottom: 0.3rem !important;} /* è¾“å…¥ç»„ä»¶é—´è· */
        .stCaption {font-size: 0.65rem !important; margin-top: -0.2rem !important;} /* è¯´æ˜æ–‡å­— */
        .css-1544g2n {padding: 0.2rem 0.5rem !important;} /* å±•å¼€é¢æ¿å†…è¾¹è· */
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸŒŒ æ’åˆ—é¢„å¤„ç†æ¨¡å‹")

    # é¡µé¢æ•´ä½“å¸ƒå±€ï¼šå·¦ä¾§æ•°æ®ç®¡ç†ï¼Œå³ä¾§ä¸»è¦å†…å®¹åŒº
    col_left, col_right = st.columns([1.2, 3.9])

    # ===== å·¦ä¾§ï¼šæ•°æ®ç®¡ç†æ¨¡å—ï¼ˆç§»é™¤å…‰è°±æ¡æ•°å’Œæ•°æ®ç‚¹æ•°ï¼‰=====
    with col_left:
        with st.expander("ğŸ“ æ•°æ®ç®¡ç†", expanded=True):
            # ä¸Šä¼ æ–‡ä»¶å¤¹å‹ç¼©åŒ…
            zip_file = st.file_uploader("ä¸Šä¼ åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®çš„å‹ç¼©åŒ…", type=['zip'], key="zip_file")
            st.caption("å‹ç¼©åŒ…(.zip)éœ€åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®æ–‡ä»¶")

            # æ ‡ç­¾è¾“å…¥
            st.subheader("æ ·æœ¬æ ‡ç­¾")
            num_classes = st.number_input("ç±»åˆ«æ•°é‡", min_value=1, value=2, step=1, key="num_cls")
            labels_input = st.text_input(
                "æ ‡ç­¾ï¼ˆé€—å·åˆ†éš”ï¼Œä¸å…‰è°±é¡ºåºä¸€è‡´ï¼‰",
                placeholder="ä¾‹ï¼š0,0,1,1",
                key="labels_in"
            )

            # è®­ç»ƒæµ‹è¯•æ¯”ä¾‹
            st.subheader("è®­ç»ƒæµ‹è¯•åˆ’åˆ†")
            train_test_ratio = st.slider(
                "è®­ç»ƒé›†æ¯”ä¾‹",
                min_value=0.1,
                max_value=0.9,
                value=0.8,
                step=0.1,
                format="%.1f",
                key="train_ratio"
            )
            st.session_state.train_test_split_ratio = train_test_ratio

            # æ•°æ®åŠ è½½é€»è¾‘ï¼ˆä»å‹ç¼©åŒ…åŠ è½½ï¼‰
            if zip_file:
                try:
                    st.session_state.raw_data = file_handler.load_data_from_zip(
                        zip_file
                    )

                    # å¤„ç†æ ‡ç­¾
                    if labels_input:
                        try:
                            labels = np.array([int(l.strip()) for l in labels_input.split(',')])
                            if len(labels) == st.session_state.raw_data[1].shape[1]:
                                st.session_state.labels = labels
                                n_samples = len(labels)
                                train_size = int(n_samples * train_test_ratio)
                                indices = np.random.permutation(n_samples)
                                st.session_state.train_indices = indices[:train_size]
                                st.session_state.test_indices = indices[train_size:]
                                st.success(
                                    f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{st.session_state.raw_data[1].shape[1]}æ¡å…‰è°±ï¼Œ{len(np.unique(labels))}ç±»")
                            else:
                                st.warning(f"âš ï¸ æ ‡ç­¾æ•°({len(labels)})â‰ å…‰è°±æ•°({st.session_state.raw_data[1].shape[1]})")
                                st.session_state.labels = None
                        except Exception as e:
                            st.warning(f"âš ï¸ æ ‡ç­¾æ ¼å¼é”™è¯¯: {str(e)}")
                            st.session_state.labels = None
                    else:
                        st.success(
                            f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼š{st.session_state.raw_data[1].shape[1]}æ¡å…‰è°±ï¼Œ{st.session_state.raw_data[1].shape[0]}ä¸ªç‚¹")
                        st.warning("âš ï¸ è¯·è¾“å…¥æ ·æœ¬æ ‡ç­¾ä»¥è¿›è¡Œåˆ†ç±»æµ‹è¯•")
                except Exception as e:
                    st.error(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")

        # ç³»ç»Ÿä¿¡æ¯
        if st.session_state.get('raw_data'):
            wavenumbers, y = st.session_state.raw_data
            st.info(f"ğŸ“Š æ•°æ®ç»´åº¦: {y.shape[1]}æ¡ Ã— {y.shape[0]}ç‚¹")
            st.info(f"ğŸ”¢ è®­ç»ƒé›†:{train_test_ratio:.1f} | æµ‹è¯•é›†:{1 - train_test_ratio:.1f}")
            if st.session_state.get('labels') is not None:
                class_counts = np.bincount(st.session_state.labels)
                st.info(
                    f"ğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ: {', '.join([f'ç±»{i}:{count}ä¸ª' for i, count in enumerate(class_counts) if count > 0])}")
            if st.session_state.get('process_method'):
                st.success(f"ğŸ› ï¸ å¤„ç†æµç¨‹: {st.session_state.process_method}")

        # ä½¿ç”¨è¯´æ˜
        with st.expander("â„¹ï¸ ä½¿ç”¨æŒ‡å—", expanded=False):
            st.markdown("""
            1. ä¸Šä¼ åŒ…å«æ³¢æ•°å’Œå…‰è°±æ•°æ®çš„å‹ç¼©åŒ…  
            2. è®¾ç½®æ ‡ç­¾å’Œè®­ç»ƒæµ‹è¯•æ¯”ä¾‹  
            3. å³ä¾§ä¸Šæ–¹é€‰æ‹©é¢„å¤„ç†æ–¹æ³•  
            4. ç‚¹å‡»"æ˜¾ç¤ºæ’åˆ—"ç”Ÿæˆæ–¹æ¡ˆ  
            5. é€‰æ‹©kå€¼åç‚¹å‡»"æµ‹è¯•"  
            6. æŸ¥çœ‹ç»“æœå¹¶å¯¼å‡º
            """)
